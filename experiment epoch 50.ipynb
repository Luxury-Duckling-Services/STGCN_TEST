{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "858c41b1-bb8f-495b-bd4c-e688c1698eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configs: Namespace(Ks=3, Kt=3, act_func='glu', batch_size=32, dataset='metr-la', droprate=0.5, enable_bias=True, enable_cuda=True, epochs=50, gamma=0.95, graph_conv_type='cheb_graph_conv', gso_type='sym_norm_lap', lr=0.001, middle_layer=False, n_his=12, n_pred=3, opt='adam', patience=30, seed=42, stblock_num=2, step_size=10, time_intvl=5, weight_decay_rate=0.0005)\n",
      "Blocks:  [[1], [64, 16, 64], [64, 16, 64], [128, 128], [1]]\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00822724]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "Use iteration 19 instead with accuracy \n",
      "0.007941234546600588.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00794123]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "Modules:  [STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(1, 128, kernel_size=(3, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(3, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 128, kernel_size=(3, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(3, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")]\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 23.09it/s]\n",
      "Epoch: 001 | Lr: 0.00100000000000000002 |Train loss: 0.354609 | Val loss: 0.423299 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.59it/s]\n",
      "Epoch: 002 | Lr: 0.00100000000000000002 |Train loss: 0.283152 | Val loss: 0.359180 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.72it/s]\n",
      "Epoch: 003 | Lr: 0.00100000000000000002 |Train loss: 0.279153 | Val loss: 0.368855 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:37<00:00, 19.74it/s]\n",
      "Epoch: 004 | Lr: 0.00100000000000000002 |Train loss: 0.274582 | Val loss: 0.350910 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:37<00:00, 20.10it/s]\n",
      "Epoch: 005 | Lr: 0.00100000000000000002 |Train loss: 0.269762 | Val loss: 0.348955 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:37<00:00, 19.88it/s]\n",
      "Epoch: 006 | Lr: 0.00100000000000000002 |Train loss: 0.267530 | Val loss: 0.352743 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.36it/s]\n",
      "Epoch: 007 | Lr: 0.00100000000000000002 |Train loss: 0.287404 | Val loss: 0.316732 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.44it/s]\n",
      "Epoch: 008 | Lr: 0.00100000000000000002 |Train loss: 0.260873 | Val loss: 0.324497 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.54it/s]\n",
      "Epoch: 009 | Lr: 0.00100000000000000002 |Train loss: 0.261831 | Val loss: 0.346124 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.48it/s]\n",
      "Epoch: 010 | Lr: 0.00095000000000000000 |Train loss: 0.265838 | Val loss: 0.330523 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.73it/s]\n",
      "Epoch: 011 | Lr: 0.00095000000000000000 |Train loss: 0.259454 | Val loss: 0.326465 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:39<00:00, 19.04it/s]\n",
      "Epoch: 012 | Lr: 0.00095000000000000000 |Train loss: 0.262112 | Val loss: 0.327197 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.70it/s]\n",
      "Epoch: 013 | Lr: 0.00095000000000000000 |Train loss: 0.259673 | Val loss: 0.325604 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:37<00:00, 19.79it/s]\n",
      "Epoch: 014 | Lr: 0.00095000000000000000 |Train loss: 0.258731 | Val loss: 0.328648 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:39<00:00, 19.18it/s]\n",
      "Epoch: 015 | Lr: 0.00095000000000000000 |Train loss: 0.260065 | Val loss: 0.320261 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:37<00:00, 19.89it/s]\n",
      "Epoch: 016 | Lr: 0.00095000000000000000 |Train loss: 0.257963 | Val loss: 0.325739 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.52it/s]\n",
      "Epoch: 017 | Lr: 0.00095000000000000000 |Train loss: 0.262319 | Val loss: 0.311679 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.44it/s]\n",
      "Epoch: 018 | Lr: 0.00095000000000000000 |Train loss: 0.255394 | Val loss: 0.311473 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:39<00:00, 19.01it/s]\n",
      "Epoch: 019 | Lr: 0.00095000000000000000 |Train loss: 0.254612 | Val loss: 0.321429 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:37<00:00, 19.76it/s]\n",
      "Epoch: 020 | Lr: 0.00090249999999999998 |Train loss: 0.257757 | Val loss: 0.314274 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:39<00:00, 18.99it/s]\n",
      "Epoch: 021 | Lr: 0.00090249999999999998 |Train loss: 0.253416 | Val loss: 0.310434 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.34it/s]\n",
      "Epoch: 022 | Lr: 0.00090249999999999998 |Train loss: 0.253673 | Val loss: 0.309343 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.52it/s]\n",
      "Epoch: 023 | Lr: 0.00090249999999999998 |Train loss: 0.255564 | Val loss: 0.308020 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.67it/s]\n",
      "Epoch: 024 | Lr: 0.00090249999999999998 |Train loss: 0.252204 | Val loss: 0.311366 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.36it/s]\n",
      "Epoch: 025 | Lr: 0.00090249999999999998 |Train loss: 0.252471 | Val loss: 0.315416 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.60it/s]\n",
      "Epoch: 026 | Lr: 0.00090249999999999998 |Train loss: 0.259790 | Val loss: 0.305534 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.42it/s]\n",
      "Epoch: 027 | Lr: 0.00090249999999999998 |Train loss: 0.250973 | Val loss: 0.306035 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.63it/s]\n",
      "Epoch: 028 | Lr: 0.00090249999999999998 |Train loss: 0.251525 | Val loss: 0.307182 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:37<00:00, 19.74it/s]\n",
      "Epoch: 029 | Lr: 0.00090249999999999998 |Train loss: 0.252076 | Val loss: 0.316320 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.58it/s]\n",
      "Epoch: 030 | Lr: 0.00085737499999999996 |Train loss: 0.256395 | Val loss: 0.301183 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:35<00:00, 21.00it/s]\n",
      "Epoch: 031 | Lr: 0.00085737499999999996 |Train loss: 0.249495 | Val loss: 0.304113 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:37<00:00, 19.86it/s]\n",
      "Epoch: 032 | Lr: 0.00085737499999999996 |Train loss: 0.250171 | Val loss: 0.306001 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:35<00:00, 21.27it/s]\n",
      "Epoch: 033 | Lr: 0.00085737499999999996 |Train loss: 0.255492 | Val loss: 0.297186 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:36<00:00, 20.55it/s]\n",
      "Epoch: 034 | Lr: 0.00085737499999999996 |Train loss: 0.248624 | Val loss: 0.301441 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:37<00:00, 20.14it/s]\n",
      "Epoch: 035 | Lr: 0.00085737499999999996 |Train loss: 0.249659 | Val loss: 0.308269 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:35<00:00, 21.11it/s]\n",
      "Epoch: 036 | Lr: 0.00085737499999999996 |Train loss: 0.250486 | Val loss: 0.303491 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:36<00:00, 20.76it/s]\n",
      "Epoch: 037 | Lr: 0.00085737499999999996 |Train loss: 0.248884 | Val loss: 0.307934 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:35<00:00, 20.88it/s]\n",
      "Epoch: 038 | Lr: 0.00085737499999999996 |Train loss: 0.249943 | Val loss: 0.306178 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:34<00:00, 21.74it/s]\n",
      "Epoch: 039 | Lr: 0.00085737499999999996 |Train loss: 0.251013 | Val loss: 0.302395 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:36<00:00, 20.36it/s]\n",
      "Epoch: 040 | Lr: 0.00081450624999999987 |Train loss: 0.248069 | Val loss: 0.304812 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:36<00:00, 20.63it/s]\n",
      "Epoch: 041 | Lr: 0.00081450624999999987 |Train loss: 0.248275 | Val loss: 0.300968 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:36<00:00, 20.31it/s]\n",
      "Epoch: 042 | Lr: 0.00081450624999999987 |Train loss: 0.247705 | Val loss: 0.305374 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:36<00:00, 20.62it/s]\n",
      "Epoch: 043 | Lr: 0.00081450624999999987 |Train loss: 0.247416 | Val loss: 0.305266 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:33<00:00, 22.62it/s]\n",
      "Epoch: 044 | Lr: 0.00081450624999999987 |Train loss: 0.247979 | Val loss: 0.301444 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:40<00:00, 18.38it/s]\n",
      "Epoch: 045 | Lr: 0.00081450624999999987 |Train loss: 0.247004 | Val loss: 0.303998 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:35<00:00, 20.85it/s]\n",
      "Epoch: 046 | Lr: 0.00081450624999999987 |Train loss: 0.249239 | Val loss: 0.299733 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:36<00:00, 20.73it/s]\n",
      "Epoch: 047 | Lr: 0.00081450624999999987 |Train loss: 0.247028 | Val loss: 0.299729 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:35<00:00, 21.19it/s]\n",
      "Epoch: 048 | Lr: 0.00081450624999999987 |Train loss: 0.250266 | Val loss: 0.295393 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:34<00:00, 21.72it/s]\n",
      "Epoch: 049 | Lr: 0.00081450624999999987 |Train loss: 0.246150 | Val loss: 0.300495 | GPU occupy: 610.686976 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:36<00:00, 20.48it/s]\n",
      "Epoch: 050 | Lr: 0.00077378093749999979 |Train loss: 0.246673 | Val loss: 0.295485 | GPU occupy: 610.686976 MiB\n",
      "Dataset metr-la | Test loss 0.309025 | MAE 5.623551 | RMSE 10.096953 | WMAPE 0.11070229\n"
     ]
    }
   ],
   "source": [
    "# default\n",
    "\n",
    "!python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ff48eb2-86b3-4837-805b-78feba4e25cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configs: Namespace(Ks=2, Kt=2, act_func='glu', batch_size=32, dataset='metr-la', droprate=0.5, enable_bias=True, enable_cuda=True, epochs=50, gamma=0.95, graph_conv_type='cheb_graph_conv', gso_type='sym_norm_lap', lr=0.001, middle_layer=True, n_his=12, n_pred=3, opt='adam', patience=30, seed=42, stblock_num=1, step_size=10, time_intvl=5, weight_decay_rate=0.0005)\n",
      "Blocks:  [[1], [64, 16, 64], [128, 128], [1]]\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00822724]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "Use iteration 19 instead with accuracy \n",
      "0.007941234546600588.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00794123]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "Modules:  [STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(1, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")]\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.27it/s]\n",
      "Epoch: 001 | Lr: 0.00100000000000000002 |Train loss: 0.318501 | Val loss: 0.439343 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 23.16it/s]\n",
      "Epoch: 002 | Lr: 0.00100000000000000002 |Train loss: 0.294777 | Val loss: 0.345944 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 22.98it/s]\n",
      "Epoch: 003 | Lr: 0.00100000000000000002 |Train loss: 0.298778 | Val loss: 0.309495 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.62it/s]\n",
      "Epoch: 004 | Lr: 0.00100000000000000002 |Train loss: 0.261211 | Val loss: 0.330782 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 24.01it/s]\n",
      "Epoch: 005 | Lr: 0.00100000000000000002 |Train loss: 0.268692 | Val loss: 0.316793 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 22.95it/s]\n",
      "Epoch: 006 | Lr: 0.00100000000000000002 |Train loss: 0.259311 | Val loss: 0.315780 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.21it/s]\n",
      "Epoch: 007 | Lr: 0.00100000000000000002 |Train loss: 0.264682 | Val loss: 0.330965 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.60it/s]\n",
      "Epoch: 008 | Lr: 0.00100000000000000002 |Train loss: 0.260836 | Val loss: 0.313157 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.57it/s]\n",
      "Epoch: 009 | Lr: 0.00100000000000000002 |Train loss: 0.259882 | Val loss: 0.315586 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 22.93it/s]\n",
      "Epoch: 010 | Lr: 0.00095000000000000000 |Train loss: 0.259758 | Val loss: 0.308634 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.79it/s]\n",
      "Epoch: 011 | Lr: 0.00095000000000000000 |Train loss: 0.255451 | Val loss: 0.304783 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 22.97it/s]\n",
      "Epoch: 012 | Lr: 0.00095000000000000000 |Train loss: 0.255372 | Val loss: 0.313655 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.44it/s]\n",
      "Epoch: 013 | Lr: 0.00095000000000000000 |Train loss: 0.259888 | Val loss: 0.307516 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 23.26it/s]\n",
      "Epoch: 014 | Lr: 0.00095000000000000000 |Train loss: 0.252841 | Val loss: 0.302487 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.57it/s]\n",
      "Epoch: 015 | Lr: 0.00095000000000000000 |Train loss: 0.254963 | Val loss: 0.316551 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:33<00:00, 22.51it/s]\n",
      "Epoch: 016 | Lr: 0.00095000000000000000 |Train loss: 0.251712 | Val loss: 0.306671 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 23.07it/s]\n",
      "Epoch: 017 | Lr: 0.00095000000000000000 |Train loss: 0.258117 | Val loss: 0.296211 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 23.20it/s]\n",
      "Epoch: 018 | Lr: 0.00095000000000000000 |Train loss: 0.249443 | Val loss: 0.297253 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 23.15it/s]\n",
      "Epoch: 019 | Lr: 0.00095000000000000000 |Train loss: 0.250815 | Val loss: 0.308018 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:33<00:00, 22.57it/s]\n",
      "Epoch: 020 | Lr: 0.00090249999999999998 |Train loss: 0.251754 | Val loss: 0.298195 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:33<00:00, 22.45it/s]\n",
      "Epoch: 021 | Lr: 0.00090249999999999998 |Train loss: 0.248763 | Val loss: 0.295763 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 23.43it/s]\n",
      "Epoch: 022 | Lr: 0.00090249999999999998 |Train loss: 0.248861 | Val loss: 0.293823 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.70it/s]\n",
      "Epoch: 023 | Lr: 0.00090249999999999998 |Train loss: 0.250037 | Val loss: 0.295510 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 23.08it/s]\n",
      "Epoch: 024 | Lr: 0.00090249999999999998 |Train loss: 0.246345 | Val loss: 0.295572 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:33<00:00, 22.64it/s]\n",
      "Epoch: 025 | Lr: 0.00090249999999999998 |Train loss: 0.251003 | Val loss: 0.293116 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:33<00:00, 22.61it/s]\n",
      "Epoch: 026 | Lr: 0.00090249999999999998 |Train loss: 0.245711 | Val loss: 0.295535 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:33<00:00, 22.49it/s]\n",
      "Epoch: 027 | Lr: 0.00090249999999999998 |Train loss: 0.249766 | Val loss: 0.293031 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 23.35it/s]\n",
      "Epoch: 028 | Lr: 0.00090249999999999998 |Train loss: 0.246383 | Val loss: 0.298416 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:33<00:00, 22.38it/s]\n",
      "Epoch: 029 | Lr: 0.00090249999999999998 |Train loss: 0.250910 | Val loss: 0.288852 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:34<00:00, 21.74it/s]\n",
      "Epoch: 030 | Lr: 0.00085737499999999996 |Train loss: 0.245192 | Val loss: 0.295782 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.76it/s]\n",
      "Epoch: 031 | Lr: 0.00085737499999999996 |Train loss: 0.245589 | Val loss: 0.290703 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 22.89it/s]\n",
      "Epoch: 032 | Lr: 0.00085737499999999996 |Train loss: 0.244978 | Val loss: 0.289810 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:34<00:00, 22.03it/s]\n",
      "Epoch: 033 | Lr: 0.00085737499999999996 |Train loss: 0.245831 | Val loss: 0.290100 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:33<00:00, 22.65it/s]\n",
      "Epoch: 034 | Lr: 0.00085737499999999996 |Train loss: 0.246064 | Val loss: 0.290863 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.32it/s]\n",
      "Epoch: 035 | Lr: 0.00085737499999999996 |Train loss: 0.245971 | Val loss: 0.287435 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:34<00:00, 21.63it/s]\n",
      "Epoch: 036 | Lr: 0.00085737499999999996 |Train loss: 0.244830 | Val loss: 0.292086 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 23.23it/s]\n",
      "Epoch: 037 | Lr: 0.00085737499999999996 |Train loss: 0.245931 | Val loss: 0.293304 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 22.77it/s]\n",
      "Epoch: 038 | Lr: 0.00085737499999999996 |Train loss: 0.245085 | Val loss: 0.287899 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:34<00:00, 21.96it/s]\n",
      "Epoch: 039 | Lr: 0.00085737499999999996 |Train loss: 0.246017 | Val loss: 0.289979 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.89it/s]\n",
      "Epoch: 040 | Lr: 0.00081450624999999987 |Train loss: 0.245467 | Val loss: 0.288207 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:33<00:00, 22.38it/s]\n",
      "Epoch: 041 | Lr: 0.00081450624999999987 |Train loss: 0.243487 | Val loss: 0.285900 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 22.87it/s]\n",
      "Epoch: 042 | Lr: 0.00081450624999999987 |Train loss: 0.244563 | Val loss: 0.285613 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:34<00:00, 21.88it/s]\n",
      "Epoch: 043 | Lr: 0.00081450624999999987 |Train loss: 0.243347 | Val loss: 0.287880 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:34<00:00, 22.03it/s]\n",
      "Epoch: 044 | Lr: 0.00081450624999999987 |Train loss: 0.243884 | Val loss: 0.291110 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:33<00:00, 22.71it/s]\n",
      "Epoch: 045 | Lr: 0.00081450624999999987 |Train loss: 0.244072 | Val loss: 0.288911 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:33<00:00, 22.41it/s]\n",
      "Epoch: 046 | Lr: 0.00081450624999999987 |Train loss: 0.244718 | Val loss: 0.286326 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:34<00:00, 21.79it/s]\n",
      "Epoch: 047 | Lr: 0.00081450624999999987 |Train loss: 0.243682 | Val loss: 0.285399 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 23.38it/s]\n",
      "Epoch: 048 | Lr: 0.00081450624999999987 |Train loss: 0.243910 | Val loss: 0.288171 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:33<00:00, 22.28it/s]\n",
      "Epoch: 049 | Lr: 0.00081450624999999987 |Train loss: 0.243335 | Val loss: 0.286629 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:34<00:00, 21.82it/s]\n",
      "Epoch: 050 | Lr: 0.00077378093749999979 |Train loss: 0.244036 | Val loss: 0.288384 | GPU occupy: 592.738816 MiB\n",
      "Dataset metr-la | Test loss 0.291164 | MAE 5.443934 | RMSE 9.832631 | WMAPE 0.10716645\n"
     ]
    }
   ],
   "source": [
    "#1: 0 middle layer + first order\n",
    "\n",
    "!python main.py --stblock_num=1 --Kt=2 --Ks=2 --middle_layer=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d20bd689-7afe-4c43-a290-f84382f86141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configs: Namespace(Ks=3, Kt=2, act_func='glu', batch_size=32, dataset='metr-la', droprate=0.5, enable_bias=True, enable_cuda=True, epochs=50, gamma=0.95, graph_conv_type='cheb_graph_conv', gso_type='sym_norm_lap', lr=0.001, middle_layer=True, n_his=12, n_pred=3, opt='adam', patience=30, seed=42, stblock_num=1, step_size=10, time_intvl=5, weight_decay_rate=0.0005)\n",
      "Blocks:  [[1], [64, 16, 64], [128, 128], [1]]\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00822724]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "Use iteration 19 instead with accuracy \n",
      "0.007941234546600588.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00794123]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "Modules:  [STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(1, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")]\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 24.12it/s]\n",
      "Epoch: 001 | Lr: 0.00100000000000000002 |Train loss: 0.349815 | Val loss: 0.392014 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:36<00:00, 20.49it/s]\n",
      "Epoch: 002 | Lr: 0.00100000000000000002 |Train loss: 0.280626 | Val loss: 0.359643 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:34<00:00, 21.95it/s]\n",
      "Epoch: 003 | Lr: 0.00100000000000000002 |Train loss: 0.272748 | Val loss: 0.342036 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:34<00:00, 21.61it/s]\n",
      "Epoch: 004 | Lr: 0.00100000000000000002 |Train loss: 0.259768 | Val loss: 0.330859 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:34<00:00, 21.79it/s]\n",
      "Epoch: 005 | Lr: 0.00100000000000000002 |Train loss: 0.263441 | Val loss: 0.332612 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:35<00:00, 21.13it/s]\n",
      "Epoch: 006 | Lr: 0.00100000000000000002 |Train loss: 0.256261 | Val loss: 0.304473 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:35<00:00, 20.97it/s]\n",
      "Epoch: 007 | Lr: 0.00100000000000000002 |Train loss: 0.254795 | Val loss: 0.323928 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 22.82it/s]\n",
      "Epoch: 008 | Lr: 0.00100000000000000002 |Train loss: 0.256904 | Val loss: 0.310731 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:35<00:00, 20.86it/s]\n",
      "Epoch: 009 | Lr: 0.00100000000000000002 |Train loss: 0.254063 | Val loss: 0.315724 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:33<00:00, 22.10it/s]\n",
      "Epoch: 010 | Lr: 0.00095000000000000000 |Train loss: 0.254350 | Val loss: 0.360023 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:37<00:00, 20.19it/s]\n",
      "Epoch: 011 | Lr: 0.00095000000000000000 |Train loss: 0.249832 | Val loss: 0.312627 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:33<00:00, 22.51it/s]\n",
      "Epoch: 012 | Lr: 0.00095000000000000000 |Train loss: 0.252278 | Val loss: 0.304345 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:37<00:00, 19.77it/s]\n",
      "Epoch: 013 | Lr: 0.00095000000000000000 |Train loss: 0.251140 | Val loss: 0.305465 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:34<00:00, 21.65it/s]\n",
      "Epoch: 014 | Lr: 0.00095000000000000000 |Train loss: 0.250462 | Val loss: 0.314455 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:34<00:00, 21.76it/s]\n",
      "Epoch: 015 | Lr: 0.00095000000000000000 |Train loss: 0.251900 | Val loss: 0.305489 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:36<00:00, 20.81it/s]\n",
      "Epoch: 016 | Lr: 0.00095000000000000000 |Train loss: 0.250797 | Val loss: 0.302275 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:34<00:00, 22.02it/s]\n",
      "Epoch: 017 | Lr: 0.00095000000000000000 |Train loss: 0.248990 | Val loss: 0.327531 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:33<00:00, 22.12it/s]\n",
      "Epoch: 018 | Lr: 0.00095000000000000000 |Train loss: 0.249994 | Val loss: 0.298972 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:34<00:00, 21.72it/s]\n",
      "Epoch: 019 | Lr: 0.00095000000000000000 |Train loss: 0.250806 | Val loss: 0.311254 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:35<00:00, 21.24it/s]\n",
      "Epoch: 020 | Lr: 0.00090249999999999998 |Train loss: 0.248853 | Val loss: 0.296744 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:35<00:00, 21.35it/s]\n",
      "Epoch: 021 | Lr: 0.00090249999999999998 |Train loss: 0.248593 | Val loss: 0.290587 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:34<00:00, 21.84it/s]\n",
      "Epoch: 022 | Lr: 0.00090249999999999998 |Train loss: 0.246703 | Val loss: 0.302140 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:35<00:00, 20.93it/s]\n",
      "Epoch: 023 | Lr: 0.00090249999999999998 |Train loss: 0.248659 | Val loss: 0.293107 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:36<00:00, 20.48it/s]\n",
      "Epoch: 024 | Lr: 0.00090249999999999998 |Train loss: 0.249249 | Val loss: 0.295442 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:35<00:00, 21.09it/s]\n",
      "Epoch: 025 | Lr: 0.00090249999999999998 |Train loss: 0.246257 | Val loss: 0.291388 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.57it/s]\n",
      "Epoch: 026 | Lr: 0.00090249999999999998 |Train loss: 0.247143 | Val loss: 0.297130 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:34<00:00, 22.03it/s]\n",
      "Epoch: 027 | Lr: 0.00090249999999999998 |Train loss: 0.248004 | Val loss: 0.289089 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:33<00:00, 22.30it/s]\n",
      "Epoch: 028 | Lr: 0.00090249999999999998 |Train loss: 0.245283 | Val loss: 0.291772 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:39<00:00, 19.03it/s]\n",
      "Epoch: 029 | Lr: 0.00090249999999999998 |Train loss: 0.248485 | Val loss: 0.295704 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:41<00:00, 18.05it/s]\n",
      "Epoch: 030 | Lr: 0.00085737499999999996 |Train loss: 0.244867 | Val loss: 0.290305 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:36<00:00, 20.49it/s]\n",
      "Epoch: 031 | Lr: 0.00085737499999999996 |Train loss: 0.244554 | Val loss: 0.287432 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:34<00:00, 21.70it/s]\n",
      "Epoch: 032 | Lr: 0.00085737499999999996 |Train loss: 0.244748 | Val loss: 0.288971 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.26it/s]\n",
      "Epoch: 033 | Lr: 0.00085737499999999996 |Train loss: 0.247766 | Val loss: 0.286971 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:37<00:00, 19.95it/s]\n",
      "Epoch: 034 | Lr: 0.00085737499999999996 |Train loss: 0.243319 | Val loss: 0.285578 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:39<00:00, 18.85it/s]\n",
      "Epoch: 035 | Lr: 0.00085737499999999996 |Train loss: 0.244531 | Val loss: 0.284668 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:35<00:00, 21.26it/s]\n",
      "Epoch: 036 | Lr: 0.00085737499999999996 |Train loss: 0.244447 | Val loss: 0.285786 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:37<00:00, 19.93it/s]\n",
      "Epoch: 037 | Lr: 0.00085737499999999996 |Train loss: 0.242823 | Val loss: 0.288117 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.64it/s]\n",
      "Epoch: 038 | Lr: 0.00085737499999999996 |Train loss: 0.244051 | Val loss: 0.287055 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:35<00:00, 21.17it/s]\n",
      "Epoch: 039 | Lr: 0.00085737499999999996 |Train loss: 0.243832 | Val loss: 0.287624 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.72it/s]\n",
      "Epoch: 040 | Lr: 0.00081450624999999987 |Train loss: 0.244346 | Val loss: 0.286668 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:37<00:00, 19.99it/s]\n",
      "Epoch: 041 | Lr: 0.00081450624999999987 |Train loss: 0.241624 | Val loss: 0.283193 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:36<00:00, 20.49it/s]\n",
      "Epoch: 042 | Lr: 0.00081450624999999987 |Train loss: 0.242719 | Val loss: 0.285530 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:36<00:00, 20.54it/s]\n",
      "Epoch: 043 | Lr: 0.00081450624999999987 |Train loss: 0.241801 | Val loss: 0.283818 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:37<00:00, 20.22it/s]\n",
      "Epoch: 044 | Lr: 0.00081450624999999987 |Train loss: 0.243090 | Val loss: 0.283347 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:36<00:00, 20.83it/s]\n",
      "Epoch: 045 | Lr: 0.00081450624999999987 |Train loss: 0.242040 | Val loss: 0.285399 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.73it/s]\n",
      "Epoch: 046 | Lr: 0.00081450624999999987 |Train loss: 0.243907 | Val loss: 0.281414 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:36<00:00, 20.34it/s]\n",
      "Epoch: 047 | Lr: 0.00081450624999999987 |Train loss: 0.241427 | Val loss: 0.284270 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:36<00:00, 20.55it/s]\n",
      "Epoch: 048 | Lr: 0.00081450624999999987 |Train loss: 0.242627 | Val loss: 0.281301 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:42<00:00, 17.68it/s]\n",
      "Epoch: 049 | Lr: 0.00081450624999999987 |Train loss: 0.241385 | Val loss: 0.283463 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:40<00:00, 18.30it/s]\n",
      "Epoch: 050 | Lr: 0.00077378093749999979 |Train loss: 0.241345 | Val loss: 0.282872 | GPU occupy: 592.964096 MiB\n",
      "Dataset metr-la | Test loss 0.282142 | MAE 5.285260 | RMSE 9.697785 | WMAPE 0.10404288\n"
     ]
    }
   ],
   "source": [
    "#2: 0 middle layer + second order\n",
    "\n",
    "!python main.py --stblock_num=1 --Kt=2 --Ks=3 --middle_layer=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7df41c1-6923-4cf6-93a8-b55f42f5cbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configs: Namespace(Ks=4, Kt=2, act_func='glu', batch_size=32, dataset='metr-la', droprate=0.5, enable_bias=True, enable_cuda=True, epochs=50, gamma=0.95, graph_conv_type='cheb_graph_conv', gso_type='sym_norm_lap', lr=0.001, middle_layer=True, n_his=12, n_pred=3, opt='adam', patience=30, seed=42, stblock_num=1, step_size=10, time_intvl=5, weight_decay_rate=0.0005)\n",
      "Blocks:  [[1], [64, 16, 64], [128, 128], [1]]\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00822724]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "Use iteration 19 instead with accuracy \n",
      "0.007941234546600588.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00794123]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "Modules:  [STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(1, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")]\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.70it/s]\n",
      "Epoch: 001 | Lr: 0.00100000000000000002 |Train loss: 0.319273 | Val loss: 0.369475 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:36<00:00, 20.67it/s]\n",
      "Epoch: 002 | Lr: 0.00100000000000000002 |Train loss: 0.288046 | Val loss: 0.394690 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:36<00:00, 20.45it/s]\n",
      "Epoch: 003 | Lr: 0.00100000000000000002 |Train loss: 0.282919 | Val loss: 0.321220 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:37<00:00, 20.02it/s]\n",
      "Epoch: 004 | Lr: 0.00100000000000000002 |Train loss: 0.260927 | Val loss: 0.356222 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.56it/s]\n",
      "Epoch: 005 | Lr: 0.00100000000000000002 |Train loss: 0.267647 | Val loss: 0.314341 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:43<00:00, 17.30it/s]\n",
      "Epoch: 006 | Lr: 0.00100000000000000002 |Train loss: 0.258167 | Val loss: 0.318521 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.80it/s]\n",
      "Epoch: 007 | Lr: 0.00100000000000000002 |Train loss: 0.261941 | Val loss: 0.319174 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.46it/s]\n",
      "Epoch: 008 | Lr: 0.00100000000000000002 |Train loss: 0.258476 | Val loss: 0.314431 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.31it/s]\n",
      "Epoch: 009 | Lr: 0.00100000000000000002 |Train loss: 0.260084 | Val loss: 0.311042 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:42<00:00, 17.74it/s]\n",
      "Epoch: 010 | Lr: 0.00095000000000000000 |Train loss: 0.255654 | Val loss: 0.312323 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:37<00:00, 20.15it/s]\n",
      "Epoch: 011 | Lr: 0.00095000000000000000 |Train loss: 0.253328 | Val loss: 0.346039 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:35<00:00, 20.95it/s]\n",
      "Epoch: 012 | Lr: 0.00095000000000000000 |Train loss: 0.252779 | Val loss: 0.303668 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:35<00:00, 20.97it/s]\n",
      "Epoch: 013 | Lr: 0.00095000000000000000 |Train loss: 0.253034 | Val loss: 0.303687 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:41<00:00, 18.10it/s]\n",
      "Epoch: 014 | Lr: 0.00095000000000000000 |Train loss: 0.251390 | Val loss: 0.354673 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:39<00:00, 18.80it/s]\n",
      "Epoch: 015 | Lr: 0.00095000000000000000 |Train loss: 0.248814 | Val loss: 0.304051 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:37<00:00, 19.82it/s]\n",
      "Epoch: 016 | Lr: 0.00095000000000000000 |Train loss: 0.251282 | Val loss: 0.298393 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:36<00:00, 20.83it/s]\n",
      "Epoch: 017 | Lr: 0.00095000000000000000 |Train loss: 0.249717 | Val loss: 0.304367 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.68it/s]\n",
      "Epoch: 018 | Lr: 0.00095000000000000000 |Train loss: 0.250635 | Val loss: 0.301636 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:39<00:00, 19.23it/s]\n",
      "Epoch: 019 | Lr: 0.00095000000000000000 |Train loss: 0.250723 | Val loss: 0.374099 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:36<00:00, 20.54it/s]\n",
      "Epoch: 020 | Lr: 0.00090249999999999998 |Train loss: 0.244488 | Val loss: 0.313977 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.71it/s]\n",
      "Epoch: 021 | Lr: 0.00090249999999999998 |Train loss: 0.250707 | Val loss: 0.302705 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:36<00:00, 20.68it/s]\n",
      "Epoch: 022 | Lr: 0.00090249999999999998 |Train loss: 0.245350 | Val loss: 0.292999 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:36<00:00, 20.28it/s]\n",
      "Epoch: 023 | Lr: 0.00090249999999999998 |Train loss: 0.247597 | Val loss: 0.291172 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:36<00:00, 20.49it/s]\n",
      "Epoch: 024 | Lr: 0.00090249999999999998 |Train loss: 0.245661 | Val loss: 0.304960 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:36<00:00, 20.71it/s]\n",
      "Epoch: 025 | Lr: 0.00090249999999999998 |Train loss: 0.248355 | Val loss: 0.296365 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.58it/s]\n",
      "Epoch: 026 | Lr: 0.00090249999999999998 |Train loss: 0.245267 | Val loss: 0.296852 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:39<00:00, 19.10it/s]\n",
      "Epoch: 027 | Lr: 0.00090249999999999998 |Train loss: 0.246825 | Val loss: 0.294800 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.72it/s]\n",
      "Epoch: 028 | Lr: 0.00090249999999999998 |Train loss: 0.245361 | Val loss: 0.299809 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:42<00:00, 17.78it/s]\n",
      "Epoch: 029 | Lr: 0.00090249999999999998 |Train loss: 0.246847 | Val loss: 0.293600 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:35<00:00, 20.99it/s]\n",
      "Epoch: 030 | Lr: 0.00085737499999999996 |Train loss: 0.244814 | Val loss: 0.294751 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:36<00:00, 20.52it/s]\n",
      "Epoch: 031 | Lr: 0.00085737499999999996 |Train loss: 0.244177 | Val loss: 0.291358 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.55it/s]\n",
      "Epoch: 032 | Lr: 0.00085737499999999996 |Train loss: 0.244267 | Val loss: 0.289546 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:34<00:00, 21.45it/s]\n",
      "Epoch: 033 | Lr: 0.00085737499999999996 |Train loss: 0.244256 | Val loss: 0.293236 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:36<00:00, 20.42it/s]\n",
      "Epoch: 034 | Lr: 0.00085737499999999996 |Train loss: 0.245930 | Val loss: 0.288366 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:37<00:00, 19.77it/s]\n",
      "Epoch: 035 | Lr: 0.00085737499999999996 |Train loss: 0.243356 | Val loss: 0.294546 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:40<00:00, 18.73it/s]\n",
      "Epoch: 036 | Lr: 0.00085737499999999996 |Train loss: 0.243656 | Val loss: 0.289733 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:40<00:00, 18.70it/s]\n",
      "Epoch: 037 | Lr: 0.00085737499999999996 |Train loss: 0.244732 | Val loss: 0.288212 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:37<00:00, 20.06it/s]\n",
      "Epoch: 038 | Lr: 0.00085737499999999996 |Train loss: 0.243611 | Val loss: 0.291971 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.24it/s]\n",
      "Epoch: 039 | Lr: 0.00085737499999999996 |Train loss: 0.244307 | Val loss: 0.289138 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.71it/s]\n",
      "Epoch: 040 | Lr: 0.00081450624999999987 |Train loss: 0.242965 | Val loss: 0.291403 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:37<00:00, 20.04it/s]\n",
      "Epoch: 041 | Lr: 0.00081450624999999987 |Train loss: 0.245139 | Val loss: 0.328349 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.46it/s]\n",
      "Epoch: 042 | Lr: 0.00081450624999999987 |Train loss: 0.240797 | Val loss: 0.285295 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.52it/s]\n",
      "Epoch: 043 | Lr: 0.00081450624999999987 |Train loss: 0.242399 | Val loss: 0.290148 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:39<00:00, 18.91it/s]\n",
      "Epoch: 044 | Lr: 0.00081450624999999987 |Train loss: 0.243228 | Val loss: 0.286027 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:40<00:00, 18.38it/s]\n",
      "Epoch: 045 | Lr: 0.00081450624999999987 |Train loss: 0.242228 | Val loss: 0.282394 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:37<00:00, 19.94it/s]\n",
      "Epoch: 046 | Lr: 0.00081450624999999987 |Train loss: 0.241012 | Val loss: 0.284302 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:39<00:00, 18.97it/s]\n",
      "Epoch: 047 | Lr: 0.00081450624999999987 |Train loss: 0.243844 | Val loss: 0.331179 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:37<00:00, 19.76it/s]\n",
      "Epoch: 048 | Lr: 0.00081450624999999987 |Train loss: 0.242302 | Val loss: 0.288078 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:38<00:00, 19.51it/s]\n",
      "Epoch: 049 | Lr: 0.00081450624999999987 |Train loss: 0.241901 | Val loss: 0.285215 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:37<00:00, 20.06it/s]\n",
      "Epoch: 050 | Lr: 0.00077378093749999979 |Train loss: 0.241314 | Val loss: 0.282121 | GPU occupy: 594.579968 MiB\n",
      "Dataset metr-la | Test loss 0.281462 | MAE 5.324363 | RMSE 9.688947 | WMAPE 0.10481264\n"
     ]
    }
   ],
   "source": [
    "#3: 0 middle layer + third order\n",
    "\n",
    "!python main.py --stblock_num=1 --Kt=2 --Ks=4 --middle_layer=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b09d3869-6f2b-4502-a590-660e0cbbafa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configs: Namespace(Ks=2, Kt=2, act_func='glu', batch_size=32, dataset='metr-la', droprate=0.5, enable_bias=True, enable_cuda=True, epochs=50, gamma=0.95, graph_conv_type='cheb_graph_conv', gso_type='sym_norm_lap', lr=0.001, middle_layer=True, n_his=12, n_pred=3, opt='adam', patience=30, seed=42, stblock_num=2, step_size=10, time_intvl=5, weight_decay_rate=0.0005)\n",
      "Blocks:  [[1], [64, 16, 64], [64, 16, 64], [128, 128], [1]]\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00822724]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "Use iteration 19 instead with accuracy \n",
      "0.007941234546600588.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00794123]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "Modules:  [STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(1, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), MiddleBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 256, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (tc1_ln): LayerNorm((207, 128), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")]\n",
      "100%|█████████████████████████████████████████| 750/750 [00:54<00:00, 13.86it/s]\n",
      "Epoch: 001 | Lr: 0.00100000000000000002 |Train loss: 0.347104 | Val loss: 0.496707 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:54<00:00, 13.80it/s]\n",
      "Epoch: 002 | Lr: 0.00100000000000000002 |Train loss: 0.289022 | Val loss: 0.427631 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.93it/s]\n",
      "Epoch: 003 | Lr: 0.00100000000000000002 |Train loss: 0.289281 | Val loss: 0.371758 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:54<00:00, 13.86it/s]\n",
      "Epoch: 004 | Lr: 0.00100000000000000002 |Train loss: 0.278724 | Val loss: 0.350667 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.65it/s]\n",
      "Epoch: 005 | Lr: 0.00100000000000000002 |Train loss: 0.270531 | Val loss: 0.358207 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:56<00:00, 13.35it/s]\n",
      "Epoch: 006 | Lr: 0.00100000000000000002 |Train loss: 0.277070 | Val loss: 0.338763 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:54<00:00, 13.73it/s]\n",
      "Epoch: 007 | Lr: 0.00100000000000000002 |Train loss: 0.265507 | Val loss: 0.336594 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:51<00:00, 14.51it/s]\n",
      "Epoch: 008 | Lr: 0.00100000000000000002 |Train loss: 0.269080 | Val loss: 0.339207 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:53<00:00, 14.09it/s]\n",
      "Epoch: 009 | Lr: 0.00100000000000000002 |Train loss: 0.265339 | Val loss: 0.321310 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:53<00:00, 13.97it/s]\n",
      "Epoch: 010 | Lr: 0.00095000000000000000 |Train loss: 0.262763 | Val loss: 0.324650 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:55<00:00, 13.52it/s]\n",
      "Epoch: 011 | Lr: 0.00095000000000000000 |Train loss: 0.262099 | Val loss: 0.318814 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:53<00:00, 14.13it/s]\n",
      "Epoch: 012 | Lr: 0.00095000000000000000 |Train loss: 0.261963 | Val loss: 0.314685 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:54<00:00, 13.83it/s]\n",
      "Epoch: 013 | Lr: 0.00095000000000000000 |Train loss: 0.261829 | Val loss: 0.314089 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:56<00:00, 13.18it/s]\n",
      "Epoch: 014 | Lr: 0.00095000000000000000 |Train loss: 0.259740 | Val loss: 0.319109 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:00<00:00, 12.32it/s]\n",
      "Epoch: 015 | Lr: 0.00095000000000000000 |Train loss: 0.260054 | Val loss: 0.310176 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:53<00:00, 13.92it/s]\n",
      "Epoch: 016 | Lr: 0.00095000000000000000 |Train loss: 0.277935 | Val loss: 0.300243 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:55<00:00, 13.63it/s]\n",
      "Epoch: 017 | Lr: 0.00095000000000000000 |Train loss: 0.255906 | Val loss: 0.308077 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:55<00:00, 13.54it/s]\n",
      "Epoch: 018 | Lr: 0.00095000000000000000 |Train loss: 0.259110 | Val loss: 0.333019 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.10it/s]\n",
      "Epoch: 019 | Lr: 0.00095000000000000000 |Train loss: 0.261131 | Val loss: 0.308760 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:54<00:00, 13.84it/s]\n",
      "Epoch: 020 | Lr: 0.00090249999999999998 |Train loss: 0.258017 | Val loss: 0.311128 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.02it/s]\n",
      "Epoch: 021 | Lr: 0.00090249999999999998 |Train loss: 0.257008 | Val loss: 0.305289 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:56<00:00, 13.19it/s]\n",
      "Epoch: 022 | Lr: 0.00090249999999999998 |Train loss: 0.256846 | Val loss: 0.308476 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:54<00:00, 13.85it/s]\n",
      "Epoch: 023 | Lr: 0.00090249999999999998 |Train loss: 0.256805 | Val loss: 0.308531 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:06<00:00, 11.29it/s]\n",
      "Epoch: 024 | Lr: 0.00090249999999999998 |Train loss: 0.271825 | Val loss: 0.298502 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:55<00:00, 13.56it/s]\n",
      "Epoch: 025 | Lr: 0.00090249999999999998 |Train loss: 0.254744 | Val loss: 0.301228 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:55<00:00, 13.55it/s]\n",
      "Epoch: 026 | Lr: 0.00090249999999999998 |Train loss: 0.254482 | Val loss: 0.307069 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:53<00:00, 14.08it/s]\n",
      "Epoch: 027 | Lr: 0.00090249999999999998 |Train loss: 0.255317 | Val loss: 0.309290 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:53<00:00, 14.02it/s]\n",
      "Epoch: 028 | Lr: 0.00090249999999999998 |Train loss: 0.255721 | Val loss: 0.312069 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:54<00:00, 13.75it/s]\n",
      "Epoch: 029 | Lr: 0.00090249999999999998 |Train loss: 0.256481 | Val loss: 0.306579 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:55<00:00, 13.62it/s]\n",
      "Epoch: 030 | Lr: 0.00085737499999999996 |Train loss: 0.256431 | Val loss: 0.306621 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:55<00:00, 13.53it/s]\n",
      "Epoch: 031 | Lr: 0.00085737499999999996 |Train loss: 0.255822 | Val loss: 0.299392 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.62it/s]\n",
      "Epoch: 032 | Lr: 0.00085737499999999996 |Train loss: 0.253225 | Val loss: 0.304593 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:00<00:00, 12.37it/s]\n",
      "Epoch: 033 | Lr: 0.00085737499999999996 |Train loss: 0.254510 | Val loss: 0.298940 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:53<00:00, 14.13it/s]\n",
      "Epoch: 034 | Lr: 0.00085737499999999996 |Train loss: 0.252883 | Val loss: 0.305738 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:53<00:00, 13.97it/s]\n",
      "Epoch: 035 | Lr: 0.00085737499999999996 |Train loss: 0.254983 | Val loss: 0.300545 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:55<00:00, 13.55it/s]\n",
      "Epoch: 036 | Lr: 0.00085737499999999996 |Train loss: 0.252782 | Val loss: 0.300023 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:52<00:00, 14.18it/s]\n",
      "Epoch: 037 | Lr: 0.00085737499999999996 |Train loss: 0.253430 | Val loss: 0.306228 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:54<00:00, 13.70it/s]\n",
      "Epoch: 038 | Lr: 0.00085737499999999996 |Train loss: 0.253488 | Val loss: 0.297417 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:53<00:00, 14.07it/s]\n",
      "Epoch: 039 | Lr: 0.00085737499999999996 |Train loss: 0.251384 | Val loss: 0.303405 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:52<00:00, 14.42it/s]\n",
      "Epoch: 040 | Lr: 0.00081450624999999987 |Train loss: 0.252084 | Val loss: 0.305050 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:52<00:00, 14.32it/s]\n",
      "Epoch: 041 | Lr: 0.00081450624999999987 |Train loss: 0.251569 | Val loss: 0.300426 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.68it/s]\n",
      "Epoch: 042 | Lr: 0.00081450624999999987 |Train loss: 0.250769 | Val loss: 0.301657 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:52<00:00, 14.37it/s]\n",
      "Epoch: 043 | Lr: 0.00081450624999999987 |Train loss: 0.251032 | Val loss: 0.302186 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:51<00:00, 14.45it/s]\n",
      "Epoch: 044 | Lr: 0.00081450624999999987 |Train loss: 0.253792 | Val loss: 0.304823 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:54<00:00, 13.79it/s]\n",
      "Epoch: 045 | Lr: 0.00081450624999999987 |Train loss: 0.250958 | Val loss: 0.292404 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:53<00:00, 14.08it/s]\n",
      "Epoch: 046 | Lr: 0.00081450624999999987 |Train loss: 0.249672 | Val loss: 0.299260 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:53<00:00, 14.03it/s]\n",
      "Epoch: 047 | Lr: 0.00081450624999999987 |Train loss: 0.251212 | Val loss: 0.299583 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:52<00:00, 14.31it/s]\n",
      "Epoch: 048 | Lr: 0.00081450624999999987 |Train loss: 0.250045 | Val loss: 0.300063 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:54<00:00, 13.82it/s]\n",
      "Epoch: 049 | Lr: 0.00081450624999999987 |Train loss: 0.251094 | Val loss: 0.298717 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:53<00:00, 14.01it/s]\n",
      "Epoch: 050 | Lr: 0.00077378093749999979 |Train loss: 0.250138 | Val loss: 0.299895 | GPU occupy: 879.232512 MiB\n",
      "Dataset metr-la | Test loss 0.314490 | MAE 5.806239 | RMSE 10.210864 | WMAPE 0.11429860\n"
     ]
    }
   ],
   "source": [
    "#4: 1 middle layer + first order\n",
    "\n",
    "!python main.py --stblock_num=2 --Kt=2 --Ks=2 --middle_layer=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d8dfdda-60a1-4d93-9968-bb428023ecea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configs: Namespace(Ks=3, Kt=2, act_func='glu', batch_size=32, dataset='metr-la', droprate=0.5, enable_bias=True, enable_cuda=True, epochs=50, gamma=0.95, graph_conv_type='cheb_graph_conv', gso_type='sym_norm_lap', lr=0.001, middle_layer=True, n_his=12, n_pred=3, opt='adam', patience=30, seed=42, stblock_num=2, step_size=10, time_intvl=5, weight_decay_rate=0.0005)\n",
      "Blocks:  [[1], [64, 16, 64], [64, 16, 64], [128, 128], [1]]\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00822724]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "Use iteration 19 instead with accuracy \n",
      "0.007941234546600588.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00794123]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "Modules:  [STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(1, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), MiddleBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 256, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (tc1_ln): LayerNorm((207, 128), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")]\n",
      "100%|█████████████████████████████████████████| 750/750 [01:00<00:00, 12.31it/s]\n",
      "Epoch: 001 | Lr: 0.00100000000000000002 |Train loss: 0.354510 | Val loss: 0.429226 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:53<00:00, 14.00it/s]\n",
      "Epoch: 002 | Lr: 0.00100000000000000002 |Train loss: 0.294443 | Val loss: 0.392565 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:55<00:00, 13.61it/s]\n",
      "Epoch: 003 | Lr: 0.00100000000000000002 |Train loss: 0.292956 | Val loss: 0.370435 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:54<00:00, 13.76it/s]\n",
      "Epoch: 004 | Lr: 0.00100000000000000002 |Train loss: 0.398606 | Val loss: 0.353352 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:54<00:00, 13.85it/s]\n",
      "Epoch: 005 | Lr: 0.00100000000000000002 |Train loss: 0.272514 | Val loss: 0.345500 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:52<00:00, 14.27it/s]\n",
      "Epoch: 006 | Lr: 0.00100000000000000002 |Train loss: 0.271437 | Val loss: 0.346624 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:53<00:00, 14.11it/s]\n",
      "Epoch: 007 | Lr: 0.00100000000000000002 |Train loss: 0.268610 | Val loss: 0.333902 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:51<00:00, 14.45it/s]\n",
      "Epoch: 008 | Lr: 0.00100000000000000002 |Train loss: 0.267803 | Val loss: 0.330520 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:52<00:00, 14.35it/s]\n",
      "Epoch: 009 | Lr: 0.00100000000000000002 |Train loss: 0.266124 | Val loss: 0.323959 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.89it/s]\n",
      "Epoch: 010 | Lr: 0.00095000000000000000 |Train loss: 0.263156 | Val loss: 0.324174 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:53<00:00, 13.92it/s]\n",
      "Epoch: 011 | Lr: 0.00095000000000000000 |Train loss: 0.263171 | Val loss: 0.323370 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:51<00:00, 14.56it/s]\n",
      "Epoch: 012 | Lr: 0.00095000000000000000 |Train loss: 0.262186 | Val loss: 0.316660 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:50<00:00, 14.75it/s]\n",
      "Epoch: 013 | Lr: 0.00095000000000000000 |Train loss: 0.261876 | Val loss: 0.310067 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:51<00:00, 14.48it/s]\n",
      "Epoch: 014 | Lr: 0.00095000000000000000 |Train loss: 0.258220 | Val loss: 0.315329 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:50<00:00, 14.88it/s]\n",
      "Epoch: 015 | Lr: 0.00095000000000000000 |Train loss: 0.259622 | Val loss: 0.316202 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:51<00:00, 14.52it/s]\n",
      "Epoch: 016 | Lr: 0.00095000000000000000 |Train loss: 0.260493 | Val loss: 0.308082 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:52<00:00, 14.41it/s]\n",
      "Epoch: 017 | Lr: 0.00095000000000000000 |Train loss: 0.260685 | Val loss: 0.313269 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:51<00:00, 14.66it/s]\n",
      "Epoch: 018 | Lr: 0.00095000000000000000 |Train loss: 0.257510 | Val loss: 0.316660 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:55<00:00, 13.41it/s]\n",
      "Epoch: 019 | Lr: 0.00095000000000000000 |Train loss: 0.259741 | Val loss: 0.309669 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:51<00:00, 14.61it/s]\n",
      "Epoch: 020 | Lr: 0.00090249999999999998 |Train loss: 0.257474 | Val loss: 0.310454 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:52<00:00, 14.26it/s]\n",
      "Epoch: 021 | Lr: 0.00090249999999999998 |Train loss: 0.255047 | Val loss: 0.305852 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:55<00:00, 13.62it/s]\n",
      "Epoch: 022 | Lr: 0.00090249999999999998 |Train loss: 0.255657 | Val loss: 0.306306 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:52<00:00, 14.36it/s]\n",
      "Epoch: 023 | Lr: 0.00090249999999999998 |Train loss: 0.255454 | Val loss: 0.307606 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:52<00:00, 14.19it/s]\n",
      "Epoch: 024 | Lr: 0.00090249999999999998 |Train loss: 0.254706 | Val loss: 0.308246 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:53<00:00, 13.93it/s]\n",
      "Epoch: 025 | Lr: 0.00090249999999999998 |Train loss: 0.253927 | Val loss: 0.307464 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:52<00:00, 14.30it/s]\n",
      "Epoch: 026 | Lr: 0.00090249999999999998 |Train loss: 0.256131 | Val loss: 0.309693 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:53<00:00, 14.05it/s]\n",
      "Epoch: 027 | Lr: 0.00090249999999999998 |Train loss: 0.255656 | Val loss: 0.300637 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:00<00:00, 12.31it/s]\n",
      "Epoch: 028 | Lr: 0.00090249999999999998 |Train loss: 0.252587 | Val loss: 0.307494 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:52<00:00, 14.20it/s]\n",
      "Epoch: 029 | Lr: 0.00090249999999999998 |Train loss: 0.255247 | Val loss: 0.303255 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:52<00:00, 14.18it/s]\n",
      "Epoch: 030 | Lr: 0.00085737499999999996 |Train loss: 0.252778 | Val loss: 0.299751 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:51<00:00, 14.43it/s]\n",
      "Epoch: 031 | Lr: 0.00085737499999999996 |Train loss: 0.251811 | Val loss: 0.298926 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:53<00:00, 14.14it/s]\n",
      "Epoch: 032 | Lr: 0.00085737499999999996 |Train loss: 0.251316 | Val loss: 0.301156 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:51<00:00, 14.61it/s]\n",
      "Epoch: 033 | Lr: 0.00085737499999999996 |Train loss: 0.251426 | Val loss: 0.298012 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:51<00:00, 14.52it/s]\n",
      "Epoch: 034 | Lr: 0.00085737499999999996 |Train loss: 0.250206 | Val loss: 0.300855 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:53<00:00, 14.13it/s]\n",
      "Epoch: 035 | Lr: 0.00085737499999999996 |Train loss: 0.250358 | Val loss: 0.341683 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:51<00:00, 14.45it/s]\n",
      "Epoch: 036 | Lr: 0.00085737499999999996 |Train loss: 0.255815 | Val loss: 0.302626 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.85it/s]\n",
      "Epoch: 037 | Lr: 0.00085737499999999996 |Train loss: 0.251126 | Val loss: 0.301562 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:55<00:00, 13.63it/s]\n",
      "Epoch: 038 | Lr: 0.00085737499999999996 |Train loss: 0.250087 | Val loss: 0.299784 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:51<00:00, 14.64it/s]\n",
      "Epoch: 039 | Lr: 0.00085737499999999996 |Train loss: 0.249569 | Val loss: 0.299654 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:50<00:00, 14.73it/s]\n",
      "Epoch: 040 | Lr: 0.00081450624999999987 |Train loss: 0.249871 | Val loss: 0.300286 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:52<00:00, 14.39it/s]\n",
      "Epoch: 041 | Lr: 0.00081450624999999987 |Train loss: 0.248794 | Val loss: 0.297078 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:52<00:00, 14.38it/s]\n",
      "Epoch: 042 | Lr: 0.00081450624999999987 |Train loss: 0.248785 | Val loss: 0.329050 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:51<00:00, 14.44it/s]\n",
      "Epoch: 043 | Lr: 0.00081450624999999987 |Train loss: 0.251908 | Val loss: 0.299075 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:51<00:00, 14.46it/s]\n",
      "Epoch: 044 | Lr: 0.00081450624999999987 |Train loss: 0.248368 | Val loss: 0.301976 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:50<00:00, 14.89it/s]\n",
      "Epoch: 045 | Lr: 0.00081450624999999987 |Train loss: 0.248426 | Val loss: 0.298431 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:55<00:00, 13.54it/s]\n",
      "Epoch: 046 | Lr: 0.00081450624999999987 |Train loss: 0.247727 | Val loss: 0.293935 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:54<00:00, 13.65it/s]\n",
      "Epoch: 047 | Lr: 0.00081450624999999987 |Train loss: 0.248167 | Val loss: 0.299731 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:51<00:00, 14.66it/s]\n",
      "Epoch: 048 | Lr: 0.00081450624999999987 |Train loss: 0.248726 | Val loss: 0.295161 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:51<00:00, 14.63it/s]\n",
      "Epoch: 049 | Lr: 0.00081450624999999987 |Train loss: 0.248597 | Val loss: 0.298297 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:51<00:00, 14.44it/s]\n",
      "Epoch: 050 | Lr: 0.00077378093749999979 |Train loss: 0.247549 | Val loss: 0.297371 | GPU occupy: 889.995776 MiB\n",
      "Dataset metr-la | Test loss 0.311453 | MAE 5.749840 | RMSE 10.150211 | WMAPE 0.11318835\n"
     ]
    }
   ],
   "source": [
    "#5: 1 middle layer + second order\n",
    "\n",
    "!python main.py --stblock_num=2 --Kt=2 --Ks=3 --middle_layer=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90f96ece-7c60-409c-9c39-8a255046ef6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configs: Namespace(Ks=4, Kt=2, act_func='glu', batch_size=32, dataset='metr-la', droprate=0.5, enable_bias=True, enable_cuda=True, epochs=50, gamma=0.95, graph_conv_type='cheb_graph_conv', gso_type='sym_norm_lap', lr=0.001, middle_layer=True, n_his=12, n_pred=3, opt='adam', patience=30, seed=42, stblock_num=2, step_size=10, time_intvl=5, weight_decay_rate=0.0005)\n",
      "Blocks:  [[1], [64, 16, 64], [64, 16, 64], [128, 128], [1]]\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00822724]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "Use iteration 19 instead with accuracy \n",
      "0.007941234546600588.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00794123]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "Modules:  [STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(1, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), MiddleBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 256, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (tc1_ln): LayerNorm((207, 128), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")]\n",
      "100%|█████████████████████████████████████████| 750/750 [00:52<00:00, 14.22it/s]\n",
      "Epoch: 001 | Lr: 0.00100000000000000002 |Train loss: 0.375132 | Val loss: 0.388112 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:52<00:00, 14.21it/s]\n",
      "Epoch: 002 | Lr: 0.00100000000000000002 |Train loss: 0.287234 | Val loss: 0.365838 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:52<00:00, 14.28it/s]\n",
      "Epoch: 003 | Lr: 0.00100000000000000002 |Train loss: 0.292018 | Val loss: 0.353213 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:53<00:00, 14.07it/s]\n",
      "Epoch: 004 | Lr: 0.00100000000000000002 |Train loss: 0.278946 | Val loss: 0.363065 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.02it/s]\n",
      "Epoch: 005 | Lr: 0.00100000000000000002 |Train loss: 0.276777 | Val loss: 0.355159 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:54<00:00, 13.78it/s]\n",
      "Epoch: 006 | Lr: 0.00100000000000000002 |Train loss: 0.336617 | Val loss: 0.311269 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:54<00:00, 13.86it/s]\n",
      "Epoch: 007 | Lr: 0.00100000000000000002 |Train loss: 0.262622 | Val loss: 0.324482 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:50<00:00, 14.76it/s]\n",
      "Epoch: 008 | Lr: 0.00100000000000000002 |Train loss: 0.266799 | Val loss: 0.352131 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:54<00:00, 13.66it/s]\n",
      "Epoch: 009 | Lr: 0.00100000000000000002 |Train loss: 0.269166 | Val loss: 0.335091 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:53<00:00, 13.94it/s]\n",
      "Epoch: 010 | Lr: 0.00095000000000000000 |Train loss: 0.264475 | Val loss: 0.332037 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:53<00:00, 13.93it/s]\n",
      "Epoch: 011 | Lr: 0.00095000000000000000 |Train loss: 0.262810 | Val loss: 0.326522 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:54<00:00, 13.87it/s]\n",
      "Epoch: 012 | Lr: 0.00095000000000000000 |Train loss: 0.261991 | Val loss: 0.326017 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:50<00:00, 14.99it/s]\n",
      "Epoch: 013 | Lr: 0.00095000000000000000 |Train loss: 0.263827 | Val loss: 0.324296 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:02<00:00, 11.99it/s]\n",
      "Epoch: 014 | Lr: 0.00095000000000000000 |Train loss: 0.263024 | Val loss: 0.318039 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:52<00:00, 14.33it/s]\n",
      "Epoch: 015 | Lr: 0.00095000000000000000 |Train loss: 0.259647 | Val loss: 0.322351 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:52<00:00, 14.35it/s]\n",
      "Epoch: 016 | Lr: 0.00095000000000000000 |Train loss: 0.259839 | Val loss: 0.319377 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:54<00:00, 13.73it/s]\n",
      "Epoch: 017 | Lr: 0.00095000000000000000 |Train loss: 0.259631 | Val loss: 0.320514 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:54<00:00, 13.75it/s]\n",
      "Epoch: 018 | Lr: 0.00095000000000000000 |Train loss: 0.259429 | Val loss: 0.327369 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:53<00:00, 14.02it/s]\n",
      "Epoch: 019 | Lr: 0.00095000000000000000 |Train loss: 0.259721 | Val loss: 0.310945 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:53<00:00, 13.89it/s]\n",
      "Epoch: 020 | Lr: 0.00090249999999999998 |Train loss: 0.257119 | Val loss: 0.313977 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:54<00:00, 13.64it/s]\n",
      "Epoch: 021 | Lr: 0.00090249999999999998 |Train loss: 0.255366 | Val loss: 0.311504 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:56<00:00, 13.21it/s]\n",
      "Epoch: 022 | Lr: 0.00090249999999999998 |Train loss: 0.257521 | Val loss: 0.320613 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:55<00:00, 13.62it/s]\n",
      "Epoch: 023 | Lr: 0.00090249999999999998 |Train loss: 0.256335 | Val loss: 0.307265 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:53<00:00, 14.13it/s]\n",
      "Epoch: 024 | Lr: 0.00090249999999999998 |Train loss: 0.254216 | Val loss: 0.307864 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:53<00:00, 14.00it/s]\n",
      "Epoch: 025 | Lr: 0.00090249999999999998 |Train loss: 0.256523 | Val loss: 0.310798 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:50<00:00, 14.75it/s]\n",
      "Epoch: 026 | Lr: 0.00090249999999999998 |Train loss: 0.254016 | Val loss: 0.306268 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:51<00:00, 14.65it/s]\n",
      "Epoch: 027 | Lr: 0.00090249999999999998 |Train loss: 0.253453 | Val loss: 0.308374 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:50<00:00, 14.99it/s]\n",
      "Epoch: 028 | Lr: 0.00090249999999999998 |Train loss: 0.254917 | Val loss: 0.309956 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:50<00:00, 14.99it/s]\n",
      "Epoch: 029 | Lr: 0.00090249999999999998 |Train loss: 0.254453 | Val loss: 0.306308 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:50<00:00, 14.80it/s]\n",
      "Epoch: 030 | Lr: 0.00085737499999999996 |Train loss: 0.252982 | Val loss: 0.306302 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:51<00:00, 14.50it/s]\n",
      "Epoch: 031 | Lr: 0.00085737499999999996 |Train loss: 0.251756 | Val loss: 0.307546 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:52<00:00, 14.36it/s]\n",
      "Epoch: 032 | Lr: 0.00085737499999999996 |Train loss: 0.252822 | Val loss: 0.301327 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:50<00:00, 14.80it/s]\n",
      "Epoch: 033 | Lr: 0.00085737499999999996 |Train loss: 0.251480 | Val loss: 0.303993 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:50<00:00, 14.94it/s]\n",
      "Epoch: 034 | Lr: 0.00085737499999999996 |Train loss: 0.250147 | Val loss: 0.307604 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:50<00:00, 14.96it/s]\n",
      "Epoch: 035 | Lr: 0.00085737499999999996 |Train loss: 0.253748 | Val loss: 0.312280 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:51<00:00, 14.53it/s]\n",
      "Epoch: 036 | Lr: 0.00085737499999999996 |Train loss: 0.250836 | Val loss: 0.297047 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:50<00:00, 14.81it/s]\n",
      "Epoch: 037 | Lr: 0.00085737499999999996 |Train loss: 0.250218 | Val loss: 0.305860 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:50<00:00, 14.98it/s]\n",
      "Epoch: 038 | Lr: 0.00085737499999999996 |Train loss: 0.250056 | Val loss: 0.306649 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:50<00:00, 14.88it/s]\n",
      "Epoch: 039 | Lr: 0.00085737499999999996 |Train loss: 0.255170 | Val loss: 0.315890 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:50<00:00, 14.86it/s]\n",
      "Epoch: 040 | Lr: 0.00081450624999999987 |Train loss: 0.251527 | Val loss: 0.294416 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:51<00:00, 14.68it/s]\n",
      "Epoch: 041 | Lr: 0.00081450624999999987 |Train loss: 0.249520 | Val loss: 0.296230 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.26it/s]\n",
      "Epoch: 042 | Lr: 0.00081450624999999987 |Train loss: 0.248958 | Val loss: 0.297929 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:50<00:00, 14.79it/s]\n",
      "Epoch: 043 | Lr: 0.00081450624999999987 |Train loss: 0.250316 | Val loss: 0.300316 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.75it/s]\n",
      "Epoch: 044 | Lr: 0.00081450624999999987 |Train loss: 0.248750 | Val loss: 0.298098 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.42it/s]\n",
      "Epoch: 045 | Lr: 0.00081450624999999987 |Train loss: 0.249528 | Val loss: 0.304697 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.24it/s]\n",
      "Epoch: 046 | Lr: 0.00081450624999999987 |Train loss: 0.250997 | Val loss: 0.300859 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.18it/s]\n",
      "Epoch: 047 | Lr: 0.00081450624999999987 |Train loss: 0.250315 | Val loss: 0.294531 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.16it/s]\n",
      "Epoch: 048 | Lr: 0.00081450624999999987 |Train loss: 0.249187 | Val loss: 0.296529 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.36it/s]\n",
      "Epoch: 049 | Lr: 0.00081450624999999987 |Train loss: 0.249071 | Val loss: 0.295417 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:50<00:00, 14.82it/s]\n",
      "Epoch: 050 | Lr: 0.00077378093749999979 |Train loss: 0.248093 | Val loss: 0.296057 | GPU occupy: 897.713664 MiB\n",
      "Dataset metr-la | Test loss 0.311898 | MAE 5.738469 | RMSE 10.158444 | WMAPE 0.11296451\n"
     ]
    }
   ],
   "source": [
    "#6: 1 middle layer + third order\n",
    "\n",
    "!python main.py --stblock_num=2 --Kt=2 --Ks=4 --middle_layer=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efc803c1-80a8-4784-8bc0-21d27b17c58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configs: Namespace(Ks=2, Kt=2, act_func='glu', batch_size=32, dataset='metr-la', droprate=0.5, enable_bias=True, enable_cuda=True, epochs=50, gamma=0.95, graph_conv_type='cheb_graph_conv', gso_type='sym_norm_lap', lr=0.001, middle_layer=True, n_his=12, n_pred=3, opt='adam', patience=30, seed=42, stblock_num=3, step_size=10, time_intvl=5, weight_decay_rate=0.0005)\n",
      "Blocks:  [[1], [64, 16, 64], [64, 16, 64], [64, 16, 64], [128, 128], [1]]\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00822724]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "Use iteration 19 instead with accuracy \n",
      "0.007941234546600588.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00794123]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "Modules:  [STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(1, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), MiddleBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 256, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (tc1_ln): LayerNorm((207, 128), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), MiddleBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 256, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (tc1_ln): LayerNorm((207, 128), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")]\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.64it/s]\n",
      "Epoch: 001 | Lr: 0.00100000000000000002 |Train loss: 0.459113 | Val loss: 0.409648 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.61it/s]\n",
      "Epoch: 002 | Lr: 0.00100000000000000002 |Train loss: 0.325074 | Val loss: 0.414665 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.51it/s]\n",
      "Epoch: 003 | Lr: 0.00100000000000000002 |Train loss: 0.313550 | Val loss: 0.372719 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.68it/s]\n",
      "Epoch: 004 | Lr: 0.00100000000000000002 |Train loss: 0.299959 | Val loss: 0.372877 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.50it/s]\n",
      "Epoch: 005 | Lr: 0.00100000000000000002 |Train loss: 0.301122 | Val loss: 0.358869 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:04<00:00, 11.61it/s]\n",
      "Epoch: 006 | Lr: 0.00100000000000000002 |Train loss: 0.297616 | Val loss: 0.346290 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 12.99it/s]\n",
      "Epoch: 007 | Lr: 0.00100000000000000002 |Train loss: 0.287114 | Val loss: 0.348886 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 12.93it/s]\n",
      "Epoch: 008 | Lr: 0.00100000000000000002 |Train loss: 0.282614 | Val loss: 0.340012 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.78it/s]\n",
      "Epoch: 009 | Lr: 0.00100000000000000002 |Train loss: 0.281371 | Val loss: 0.339365 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.75it/s]\n",
      "Epoch: 010 | Lr: 0.00095000000000000000 |Train loss: 0.279878 | Val loss: 0.335667 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.75it/s]\n",
      "Epoch: 011 | Lr: 0.00095000000000000000 |Train loss: 0.277073 | Val loss: 0.333448 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.79it/s]\n",
      "Epoch: 012 | Lr: 0.00095000000000000000 |Train loss: 0.276110 | Val loss: 0.330721 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:03<00:00, 11.75it/s]\n",
      "Epoch: 013 | Lr: 0.00095000000000000000 |Train loss: 0.272186 | Val loss: 0.334936 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.52it/s]\n",
      "Epoch: 014 | Lr: 0.00095000000000000000 |Train loss: 0.275937 | Val loss: 0.330492 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.76it/s]\n",
      "Epoch: 015 | Lr: 0.00095000000000000000 |Train loss: 0.269545 | Val loss: 0.328579 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.65it/s]\n",
      "Epoch: 016 | Lr: 0.00095000000000000000 |Train loss: 0.271021 | Val loss: 0.321426 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.72it/s]\n",
      "Epoch: 017 | Lr: 0.00095000000000000000 |Train loss: 0.269380 | Val loss: 0.326113 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.75it/s]\n",
      "Epoch: 018 | Lr: 0.00095000000000000000 |Train loss: 0.269746 | Val loss: 0.322157 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.58it/s]\n",
      "Epoch: 019 | Lr: 0.00095000000000000000 |Train loss: 0.269082 | Val loss: 0.327477 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.75it/s]\n",
      "Epoch: 020 | Lr: 0.00090249999999999998 |Train loss: 0.269472 | Val loss: 0.318947 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:56<00:00, 13.31it/s]\n",
      "Epoch: 021 | Lr: 0.00090249999999999998 |Train loss: 0.270270 | Val loss: 0.320910 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.08it/s]\n",
      "Epoch: 022 | Lr: 0.00090249999999999998 |Train loss: 0.267791 | Val loss: 0.323146 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:56<00:00, 13.33it/s]\n",
      "Epoch: 023 | Lr: 0.00090249999999999998 |Train loss: 0.265930 | Val loss: 0.318406 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:55<00:00, 13.50it/s]\n",
      "Epoch: 024 | Lr: 0.00090249999999999998 |Train loss: 0.267415 | Val loss: 0.316517 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:55<00:00, 13.47it/s]\n",
      "Epoch: 025 | Lr: 0.00090249999999999998 |Train loss: 0.267260 | Val loss: 0.320432 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.08it/s]\n",
      "Epoch: 026 | Lr: 0.00090249999999999998 |Train loss: 0.273676 | Val loss: 0.312219 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 12.98it/s]\n",
      "Epoch: 027 | Lr: 0.00090249999999999998 |Train loss: 0.264151 | Val loss: 0.313857 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:56<00:00, 13.17it/s]\n",
      "Epoch: 028 | Lr: 0.00090249999999999998 |Train loss: 0.263699 | Val loss: 0.316725 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.02it/s]\n",
      "Epoch: 029 | Lr: 0.00090249999999999998 |Train loss: 0.267165 | Val loss: 0.316882 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.89it/s]\n",
      "Epoch: 030 | Lr: 0.00085737499999999996 |Train loss: 0.273010 | Val loss: 0.315367 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 12.95it/s]\n",
      "Epoch: 031 | Lr: 0.00085737499999999996 |Train loss: 0.264149 | Val loss: 0.313175 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:01<00:00, 12.16it/s]\n",
      "Epoch: 032 | Lr: 0.00085737499999999996 |Train loss: 0.265046 | Val loss: 0.312578 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.06it/s]\n",
      "Epoch: 033 | Lr: 0.00085737499999999996 |Train loss: 0.267653 | Val loss: 0.308617 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.10it/s]\n",
      "Epoch: 034 | Lr: 0.00085737499999999996 |Train loss: 0.262185 | Val loss: 0.310001 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.09it/s]\n",
      "Epoch: 035 | Lr: 0.00085737499999999996 |Train loss: 0.263836 | Val loss: 0.314933 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:02<00:00, 12.09it/s]\n",
      "Epoch: 036 | Lr: 0.00085737499999999996 |Train loss: 0.265622 | Val loss: 0.304273 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:02<00:00, 12.08it/s]\n",
      "Epoch: 037 | Lr: 0.00085737499999999996 |Train loss: 0.265125 | Val loss: 0.311142 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:11<00:00, 10.54it/s]\n",
      "Epoch: 038 | Lr: 0.00085737499999999996 |Train loss: 0.262597 | Val loss: 0.314898 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.56it/s]\n",
      "Epoch: 039 | Lr: 0.00085737499999999996 |Train loss: 0.263914 | Val loss: 0.308542 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.02it/s]\n",
      "Epoch: 040 | Lr: 0.00081450624999999987 |Train loss: 0.264291 | Val loss: 0.315872 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.09it/s]\n",
      "Epoch: 041 | Lr: 0.00081450624999999987 |Train loss: 0.262537 | Val loss: 0.303851 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:01<00:00, 12.18it/s]\n",
      "Epoch: 042 | Lr: 0.00081450624999999987 |Train loss: 0.262019 | Val loss: 0.306577 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:09<00:00, 10.74it/s]\n",
      "Epoch: 043 | Lr: 0.00081450624999999987 |Train loss: 0.260990 | Val loss: 0.308151 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:06<00:00, 11.33it/s]\n",
      "Epoch: 044 | Lr: 0.00081450624999999987 |Train loss: 0.262659 | Val loss: 0.309022 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.75it/s]\n",
      "Epoch: 045 | Lr: 0.00081450624999999987 |Train loss: 0.261144 | Val loss: 0.304637 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:56<00:00, 13.21it/s]\n",
      "Epoch: 046 | Lr: 0.00081450624999999987 |Train loss: 0.261027 | Val loss: 0.305989 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.92it/s]\n",
      "Epoch: 047 | Lr: 0.00081450624999999987 |Train loss: 0.260672 | Val loss: 0.306544 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.76it/s]\n",
      "Epoch: 048 | Lr: 0.00081450624999999987 |Train loss: 0.262009 | Val loss: 0.301673 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.55it/s]\n",
      "Epoch: 049 | Lr: 0.00081450624999999987 |Train loss: 0.261158 | Val loss: 0.301672 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.88it/s]\n",
      "Epoch: 050 | Lr: 0.00077378093749999979 |Train loss: 0.259620 | Val loss: 0.305600 | GPU occupy: 1072.379904 MiB\n",
      "Dataset metr-la | Test loss 0.324535 | MAE 5.807275 | RMSE 10.346455 | WMAPE 0.11431898\n"
     ]
    }
   ],
   "source": [
    "#7: 2 middle layer + first order\n",
    "\n",
    "!python main.py --stblock_num=3 --Kt=2 --Ks=2 --middle_layer=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4b866c3-e593-432c-9c32-c80942f6c566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configs: Namespace(Ks=3, Kt=2, act_func='glu', batch_size=32, dataset='metr-la', droprate=0.5, enable_bias=True, enable_cuda=True, epochs=50, gamma=0.95, graph_conv_type='cheb_graph_conv', gso_type='sym_norm_lap', lr=0.001, middle_layer=True, n_his=12, n_pred=3, opt='adam', patience=30, seed=42, stblock_num=3, step_size=10, time_intvl=5, weight_decay_rate=0.0005)\n",
      "Blocks:  [[1], [64, 16, 64], [64, 16, 64], [64, 16, 64], [128, 128], [1]]\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00822724]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "Use iteration 19 instead with accuracy \n",
      "0.007941234546600588.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00794123]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "Modules:  [STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(1, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), MiddleBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 256, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (tc1_ln): LayerNorm((207, 128), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), MiddleBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 256, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (tc1_ln): LayerNorm((207, 128), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")]\n",
      "100%|█████████████████████████████████████████| 750/750 [01:10<00:00, 10.68it/s]\n",
      "Epoch: 001 | Lr: 0.00100000000000000002 |Train loss: 0.377619 | Val loss: 0.383305 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:04<00:00, 11.67it/s]\n",
      "Epoch: 002 | Lr: 0.00100000000000000002 |Train loss: 0.292081 | Val loss: 0.345105 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.50it/s]\n",
      "Epoch: 003 | Lr: 0.00100000000000000002 |Train loss: 0.785062 | Val loss: 1.139701 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:05<00:00, 11.38it/s]\n",
      "Epoch: 004 | Lr: 0.00100000000000000002 |Train loss: 0.656695 | Val loss: 0.449178 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:17<00:00,  9.66it/s]\n",
      "Epoch: 005 | Lr: 0.00100000000000000002 |Train loss: 0.317446 | Val loss: 0.374417 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:32<00:00,  8.11it/s]\n",
      "Epoch: 006 | Lr: 0.00100000000000000002 |Train loss: 0.299347 | Val loss: 0.354419 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:24<00:00,  8.86it/s]\n",
      "Epoch: 007 | Lr: 0.00100000000000000002 |Train loss: 0.285448 | Val loss: 0.348349 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.57it/s]\n",
      "Epoch: 008 | Lr: 0.00100000000000000002 |Train loss: 0.283827 | Val loss: 0.340854 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:05<00:00, 11.42it/s]\n",
      "Epoch: 009 | Lr: 0.00100000000000000002 |Train loss: 0.280742 | Val loss: 0.338296 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.64it/s]\n",
      "Epoch: 010 | Lr: 0.00095000000000000000 |Train loss: 0.279508 | Val loss: 0.338451 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.56it/s]\n",
      "Epoch: 011 | Lr: 0.00095000000000000000 |Train loss: 0.275288 | Val loss: 0.329669 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.52it/s]\n",
      "Epoch: 012 | Lr: 0.00095000000000000000 |Train loss: 0.273686 | Val loss: 0.327653 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:02<00:00, 11.92it/s]\n",
      "Epoch: 013 | Lr: 0.00095000000000000000 |Train loss: 0.273868 | Val loss: 0.325720 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:00<00:00, 12.50it/s]\n",
      "Epoch: 014 | Lr: 0.00095000000000000000 |Train loss: 0.272261 | Val loss: 0.326218 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:00<00:00, 12.34it/s]\n",
      "Epoch: 015 | Lr: 0.00095000000000000000 |Train loss: 0.271542 | Val loss: 0.322918 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.66it/s]\n",
      "Epoch: 016 | Lr: 0.00095000000000000000 |Train loss: 0.270471 | Val loss: 0.320285 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 12.95it/s]\n",
      "Epoch: 017 | Lr: 0.00095000000000000000 |Train loss: 0.270000 | Val loss: 0.323676 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.54it/s]\n",
      "Epoch: 018 | Lr: 0.00095000000000000000 |Train loss: 0.268363 | Val loss: 0.320964 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:01<00:00, 12.16it/s]\n",
      "Epoch: 019 | Lr: 0.00095000000000000000 |Train loss: 0.268498 | Val loss: 0.322912 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:02<00:00, 11.96it/s]\n",
      "Epoch: 020 | Lr: 0.00090249999999999998 |Train loss: 0.267591 | Val loss: 0.325428 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.50it/s]\n",
      "Epoch: 021 | Lr: 0.00090249999999999998 |Train loss: 0.267744 | Val loss: 0.321204 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.80it/s]\n",
      "Epoch: 022 | Lr: 0.00090249999999999998 |Train loss: 0.265587 | Val loss: 0.322858 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.71it/s]\n",
      "Epoch: 023 | Lr: 0.00090249999999999998 |Train loss: 0.265915 | Val loss: 0.324446 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.89it/s]\n",
      "Epoch: 024 | Lr: 0.00090249999999999998 |Train loss: 0.266465 | Val loss: 0.321874 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.51it/s]\n",
      "Epoch: 025 | Lr: 0.00090249999999999998 |Train loss: 0.263906 | Val loss: 0.318034 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:03<00:00, 11.82it/s]\n",
      "Epoch: 026 | Lr: 0.00090249999999999998 |Train loss: 0.265830 | Val loss: 0.319082 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.75it/s]\n",
      "Epoch: 027 | Lr: 0.00090249999999999998 |Train loss: 0.264467 | Val loss: 0.317203 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.55it/s]\n",
      "Epoch: 028 | Lr: 0.00090249999999999998 |Train loss: 0.264134 | Val loss: 0.321525 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:00<00:00, 12.43it/s]\n",
      "Epoch: 029 | Lr: 0.00090249999999999998 |Train loss: 0.264782 | Val loss: 0.311999 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.92it/s]\n",
      "Epoch: 030 | Lr: 0.00085737499999999996 |Train loss: 0.263061 | Val loss: 0.318324 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.72it/s]\n",
      "Epoch: 031 | Lr: 0.00085737499999999996 |Train loss: 0.264745 | Val loss: 0.321242 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:01<00:00, 12.17it/s]\n",
      "Epoch: 032 | Lr: 0.00085737499999999996 |Train loss: 0.263006 | Val loss: 0.308534 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.76it/s]\n",
      "Epoch: 033 | Lr: 0.00085737499999999996 |Train loss: 0.260777 | Val loss: 0.314016 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.73it/s]\n",
      "Epoch: 034 | Lr: 0.00085737499999999996 |Train loss: 0.263358 | Val loss: 0.312816 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.50it/s]\n",
      "Epoch: 035 | Lr: 0.00085737499999999996 |Train loss: 0.261911 | Val loss: 0.313461 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.93it/s]\n",
      "Epoch: 036 | Lr: 0.00085737499999999996 |Train loss: 0.261998 | Val loss: 0.311177 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 12.95it/s]\n",
      "Epoch: 037 | Lr: 0.00085737499999999996 |Train loss: 0.263042 | Val loss: 0.325001 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:00<00:00, 12.37it/s]\n",
      "Epoch: 038 | Lr: 0.00085737499999999996 |Train loss: 0.261276 | Val loss: 0.306469 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:00<00:00, 12.48it/s]\n",
      "Epoch: 039 | Lr: 0.00085737499999999996 |Train loss: 0.260055 | Val loss: 0.311272 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.74it/s]\n",
      "Epoch: 040 | Lr: 0.00081450624999999987 |Train loss: 0.262644 | Val loss: 0.310229 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.87it/s]\n",
      "Epoch: 041 | Lr: 0.00081450624999999987 |Train loss: 0.259962 | Val loss: 0.301727 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.07it/s]\n",
      "Epoch: 042 | Lr: 0.00081450624999999987 |Train loss: 0.259067 | Val loss: 0.306472 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.08it/s]\n",
      "Epoch: 043 | Lr: 0.00081450624999999987 |Train loss: 0.260541 | Val loss: 0.323626 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.61it/s]\n",
      "Epoch: 044 | Lr: 0.00081450624999999987 |Train loss: 0.261388 | Val loss: 0.304580 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:00<00:00, 12.47it/s]\n",
      "Epoch: 045 | Lr: 0.00081450624999999987 |Train loss: 0.258477 | Val loss: 0.308388 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.61it/s]\n",
      "Epoch: 046 | Lr: 0.00081450624999999987 |Train loss: 0.260592 | Val loss: 0.315145 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.05it/s]\n",
      "Epoch: 047 | Lr: 0.00081450624999999987 |Train loss: 0.259636 | Val loss: 0.303667 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 12.98it/s]\n",
      "Epoch: 048 | Lr: 0.00081450624999999987 |Train loss: 0.258881 | Val loss: 0.316375 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 12.93it/s]\n",
      "Epoch: 049 | Lr: 0.00081450624999999987 |Train loss: 0.259755 | Val loss: 0.306412 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.09it/s]\n",
      "Epoch: 050 | Lr: 0.00077378093749999979 |Train loss: 0.258586 | Val loss: 0.306957 | GPU occupy: 1083.571712 MiB\n",
      "Dataset metr-la | Test loss 0.329149 | MAE 5.951623 | RMSE 10.422139 | WMAPE 0.11716055\n"
     ]
    }
   ],
   "source": [
    "#8: 2 middle layer + second order\n",
    "\n",
    "!python main.py --stblock_num=3 --Kt=2 --Ks=3 --middle_layer=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9604338f-a506-4b03-9399-4bee00d6440e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configs: Namespace(Ks=4, Kt=2, act_func='glu', batch_size=32, dataset='metr-la', droprate=0.5, enable_bias=True, enable_cuda=True, epochs=50, gamma=0.95, graph_conv_type='cheb_graph_conv', gso_type='sym_norm_lap', lr=0.001, middle_layer=True, n_his=12, n_pred=3, opt='adam', patience=30, seed=42, stblock_num=3, step_size=10, time_intvl=5, weight_decay_rate=0.0005)\n",
      "Blocks:  [[1], [64, 16, 64], [64, 16, 64], [64, 16, 64], [128, 128], [1]]\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00822724]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "Use iteration 19 instead with accuracy \n",
      "0.007941234546600588.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00794123]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "Modules:  [STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(1, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), MiddleBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 256, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (tc1_ln): LayerNorm((207, 128), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), MiddleBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 256, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (tc1_ln): LayerNorm((207, 128), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")]\n",
      "100%|█████████████████████████████████████████| 750/750 [01:04<00:00, 11.62it/s]\n",
      "Epoch: 001 | Lr: 0.00100000000000000002 |Train loss: 0.512002 | Val loss: 0.420864 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:06<00:00, 11.31it/s]\n",
      "Epoch: 002 | Lr: 0.00100000000000000002 |Train loss: 0.638079 | Val loss: 0.635412 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.62it/s]\n",
      "Epoch: 003 | Lr: 0.00100000000000000002 |Train loss: 0.650611 | Val loss: 0.553848 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.92it/s]\n",
      "Epoch: 004 | Lr: 0.00100000000000000002 |Train loss: 0.350678 | Val loss: 0.405161 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.92it/s]\n",
      "Epoch: 005 | Lr: 0.00100000000000000002 |Train loss: 0.314310 | Val loss: 0.525338 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.69it/s]\n",
      "Epoch: 006 | Lr: 0.00100000000000000002 |Train loss: 0.309541 | Val loss: 0.411780 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 12.94it/s]\n",
      "Epoch: 007 | Lr: 0.00100000000000000002 |Train loss: 0.313904 | Val loss: 0.364683 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.10it/s]\n",
      "Epoch: 008 | Lr: 0.00100000000000000002 |Train loss: 0.297187 | Val loss: 0.396576 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.10it/s]\n",
      "Epoch: 009 | Lr: 0.00100000000000000002 |Train loss: 0.300400 | Val loss: 0.367315 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:56<00:00, 13.24it/s]\n",
      "Epoch: 010 | Lr: 0.00095000000000000000 |Train loss: 0.291050 | Val loss: 0.360371 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.76it/s]\n",
      "Epoch: 011 | Lr: 0.00095000000000000000 |Train loss: 0.287375 | Val loss: 0.367834 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:56<00:00, 13.18it/s]\n",
      "Epoch: 012 | Lr: 0.00095000000000000000 |Train loss: 0.285516 | Val loss: 0.354296 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.13it/s]\n",
      "Epoch: 013 | Lr: 0.00095000000000000000 |Train loss: 0.283417 | Val loss: 0.348896 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 12.94it/s]\n",
      "Epoch: 014 | Lr: 0.00095000000000000000 |Train loss: 0.282789 | Val loss: 0.332834 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.00it/s]\n",
      "Epoch: 015 | Lr: 0.00095000000000000000 |Train loss: 0.280790 | Val loss: 0.340557 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.04it/s]\n",
      "Epoch: 016 | Lr: 0.00095000000000000000 |Train loss: 0.281056 | Val loss: 0.343273 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.15it/s]\n",
      "Epoch: 017 | Lr: 0.00095000000000000000 |Train loss: 0.277992 | Val loss: 0.331450 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.92it/s]\n",
      "Epoch: 018 | Lr: 0.00095000000000000000 |Train loss: 0.275768 | Val loss: 0.331593 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.07it/s]\n",
      "Epoch: 019 | Lr: 0.00095000000000000000 |Train loss: 0.283384 | Val loss: 0.322869 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.00it/s]\n",
      "Epoch: 020 | Lr: 0.00090249999999999998 |Train loss: 0.272052 | Val loss: 0.329484 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 12.97it/s]\n",
      "Epoch: 021 | Lr: 0.00090249999999999998 |Train loss: 0.271123 | Val loss: 0.331689 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.13it/s]\n",
      "Epoch: 022 | Lr: 0.00090249999999999998 |Train loss: 0.270601 | Val loss: 0.329464 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.14it/s]\n",
      "Epoch: 023 | Lr: 0.00090249999999999998 |Train loss: 0.270565 | Val loss: 0.328166 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.09it/s]\n",
      "Epoch: 024 | Lr: 0.00090249999999999998 |Train loss: 0.772377 | Val loss: 1.291781 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 12.95it/s]\n",
      "Epoch: 025 | Lr: 0.00090249999999999998 |Train loss: 0.977163 | Val loss: 0.913066 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.15it/s]\n",
      "Epoch: 026 | Lr: 0.00090249999999999998 |Train loss: 0.357628 | Val loss: 0.376790 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.16it/s]\n",
      "Epoch: 027 | Lr: 0.00090249999999999998 |Train loss: 0.292845 | Val loss: 0.315193 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.06it/s]\n",
      "Epoch: 028 | Lr: 0.00090249999999999998 |Train loss: 0.273988 | Val loss: 0.323140 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.08it/s]\n",
      "Epoch: 029 | Lr: 0.00090249999999999998 |Train loss: 0.271157 | Val loss: 0.343910 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.00it/s]\n",
      "Epoch: 030 | Lr: 0.00085737499999999996 |Train loss: 0.269147 | Val loss: 0.319531 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.05it/s]\n",
      "Epoch: 031 | Lr: 0.00085737499999999996 |Train loss: 0.265557 | Val loss: 0.317296 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.05it/s]\n",
      "Epoch: 032 | Lr: 0.00085737499999999996 |Train loss: 0.262905 | Val loss: 0.315056 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:56<00:00, 13.17it/s]\n",
      "Epoch: 033 | Lr: 0.00085737499999999996 |Train loss: 0.261442 | Val loss: 0.315490 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.13it/s]\n",
      "Epoch: 034 | Lr: 0.00085737499999999996 |Train loss: 0.260943 | Val loss: 0.318708 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:55<00:00, 13.49it/s]\n",
      "Epoch: 035 | Lr: 0.00085737499999999996 |Train loss: 0.260687 | Val loss: 0.315467 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:56<00:00, 13.28it/s]\n",
      "Epoch: 036 | Lr: 0.00085737499999999996 |Train loss: 0.260027 | Val loss: 0.316355 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.78it/s]\n",
      "Epoch: 037 | Lr: 0.00085737499999999996 |Train loss: 0.306410 | Val loss: 0.313376 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:56<00:00, 13.24it/s]\n",
      "Epoch: 038 | Lr: 0.00085737499999999996 |Train loss: 0.262889 | Val loss: 0.305280 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.05it/s]\n",
      "Epoch: 039 | Lr: 0.00085737499999999996 |Train loss: 0.259037 | Val loss: 0.303666 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.00it/s]\n",
      "Epoch: 040 | Lr: 0.00081450624999999987 |Train loss: 0.257100 | Val loss: 0.307891 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 12.94it/s]\n",
      "Epoch: 041 | Lr: 0.00081450624999999987 |Train loss: 0.256274 | Val loss: 0.308609 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.92it/s]\n",
      "Epoch: 042 | Lr: 0.00081450624999999987 |Train loss: 0.257875 | Val loss: 0.309494 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.10it/s]\n",
      "Epoch: 043 | Lr: 0.00081450624999999987 |Train loss: 0.256123 | Val loss: 0.307422 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:57<00:00, 13.04it/s]\n",
      "Epoch: 044 | Lr: 0.00081450624999999987 |Train loss: 0.256768 | Val loss: 0.315333 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.67it/s]\n",
      "Epoch: 045 | Lr: 0.00081450624999999987 |Train loss: 0.257870 | Val loss: 0.315903 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:00<00:00, 12.31it/s]\n",
      "Epoch: 046 | Lr: 0.00081450624999999987 |Train loss: 0.255580 | Val loss: 0.311894 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [01:04<00:00, 11.66it/s]\n",
      "Epoch: 047 | Lr: 0.00081450624999999987 |Train loss: 0.256846 | Val loss: 0.311377 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.78it/s]\n",
      "Epoch: 048 | Lr: 0.00081450624999999987 |Train loss: 0.255632 | Val loss: 0.308038 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:58<00:00, 12.73it/s]\n",
      "Epoch: 049 | Lr: 0.00081450624999999987 |Train loss: 0.255283 | Val loss: 0.310120 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:59<00:00, 12.64it/s]\n",
      "Epoch: 050 | Lr: 0.00077378093749999979 |Train loss: 0.255758 | Val loss: 0.314397 | GPU occupy: 1094.285312 MiB\n",
      "Dataset metr-la | Test loss 0.336392 | MAE 5.925541 | RMSE 10.522769 | WMAPE 0.11664712\n"
     ]
    }
   ],
   "source": [
    "#9: 2 middle layer + third order\n",
    "\n",
    "!python main.py --stblock_num=3 --Kt=2 --Ks=4 --middle_layer=True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
