{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "858c41b1-bb8f-495b-bd4c-e688c1698eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default\n",
    "\n",
    "#!python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ff48eb2-86b3-4837-805b-78feba4e25cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configs: Namespace(Ks=2, Kt=2, act_func='glu', batch_size=32, dataset='metr-la', droprate=0.5, enable_bias=True, enable_cuda=True, epochs=100, gamma=0.95, graph_conv_type='cheb_graph_conv', gso_type='sym_norm_lap', lr=0.001, middle_layer=True, n_his=12, n_pred=3, opt='adam', patience=30, seed=42, stblock_num=1, step_size=10, time_intvl=5, weight_decay_rate=0.0005)\n",
      "Blocks:  [[1], [64, 16, 64], [128, 128], [1]]\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00822724]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "Use iteration 19 instead with accuracy \n",
      "0.007941234546600588.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00794123]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "Modules:  [STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(1, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")]\n",
      "100%|█████████████████████████████████████████| 750/750 [00:12<00:00, 60.67it/s]\n",
      "Epoch: 001 | Lr: 0.00100000000000000002 |Train loss: 0.318501 | Val loss: 0.439343 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:11<00:00, 65.95it/s]\n",
      "Epoch: 002 | Lr: 0.00100000000000000002 |Train loss: 0.294777 | Val loss: 0.345944 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:12<00:00, 61.91it/s]\n",
      "Epoch: 003 | Lr: 0.00100000000000000002 |Train loss: 0.298778 | Val loss: 0.309495 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:11<00:00, 63.64it/s]\n",
      "Epoch: 004 | Lr: 0.00100000000000000002 |Train loss: 0.261211 | Val loss: 0.330782 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:11<00:00, 65.19it/s]\n",
      "Epoch: 005 | Lr: 0.00100000000000000002 |Train loss: 0.268692 | Val loss: 0.316793 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:11<00:00, 64.46it/s]\n",
      "Epoch: 006 | Lr: 0.00100000000000000002 |Train loss: 0.259311 | Val loss: 0.315780 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:11<00:00, 64.96it/s]\n",
      "Epoch: 007 | Lr: 0.00100000000000000002 |Train loss: 0.264682 | Val loss: 0.330965 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:13<00:00, 55.84it/s]\n",
      "Epoch: 008 | Lr: 0.00100000000000000002 |Train loss: 0.260836 | Val loss: 0.313157 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 40.91it/s]\n",
      "Epoch: 009 | Lr: 0.00100000000000000002 |Train loss: 0.259882 | Val loss: 0.315586 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 44.39it/s]\n",
      "Epoch: 010 | Lr: 0.00095000000000000000 |Train loss: 0.259758 | Val loss: 0.308634 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.73it/s]\n",
      "Epoch: 011 | Lr: 0.00095000000000000000 |Train loss: 0.255451 | Val loss: 0.304783 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:15<00:00, 48.02it/s]\n",
      "Epoch: 012 | Lr: 0.00095000000000000000 |Train loss: 0.255372 | Val loss: 0.313655 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.71it/s]\n",
      "Epoch: 013 | Lr: 0.00095000000000000000 |Train loss: 0.259888 | Val loss: 0.307516 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:14<00:00, 50.38it/s]\n",
      "Epoch: 014 | Lr: 0.00095000000000000000 |Train loss: 0.252841 | Val loss: 0.302487 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:14<00:00, 53.48it/s]\n",
      "Epoch: 015 | Lr: 0.00095000000000000000 |Train loss: 0.254963 | Val loss: 0.316551 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:14<00:00, 52.76it/s]\n",
      "Epoch: 016 | Lr: 0.00095000000000000000 |Train loss: 0.251712 | Val loss: 0.306671 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:15<00:00, 49.59it/s]\n",
      "Epoch: 017 | Lr: 0.00095000000000000000 |Train loss: 0.258117 | Val loss: 0.296211 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 40.15it/s]\n",
      "Epoch: 018 | Lr: 0.00095000000000000000 |Train loss: 0.249443 | Val loss: 0.297253 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.75it/s]\n",
      "Epoch: 019 | Lr: 0.00095000000000000000 |Train loss: 0.250815 | Val loss: 0.308018 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.00it/s]\n",
      "Epoch: 020 | Lr: 0.00090249999999999998 |Train loss: 0.251754 | Val loss: 0.298195 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 44.61it/s]\n",
      "Epoch: 021 | Lr: 0.00090249999999999998 |Train loss: 0.248763 | Val loss: 0.295763 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:15<00:00, 48.51it/s]\n",
      "Epoch: 022 | Lr: 0.00090249999999999998 |Train loss: 0.248861 | Val loss: 0.293823 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.86it/s]\n",
      "Epoch: 023 | Lr: 0.00090249999999999998 |Train loss: 0.250037 | Val loss: 0.295510 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:15<00:00, 47.10it/s]\n",
      "Epoch: 024 | Lr: 0.00090249999999999998 |Train loss: 0.246345 | Val loss: 0.295572 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.90it/s]\n",
      "Epoch: 025 | Lr: 0.00090249999999999998 |Train loss: 0.251003 | Val loss: 0.293116 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.82it/s]\n",
      "Epoch: 026 | Lr: 0.00090249999999999998 |Train loss: 0.245711 | Val loss: 0.295535 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.75it/s]\n",
      "Epoch: 027 | Lr: 0.00090249999999999998 |Train loss: 0.249766 | Val loss: 0.293031 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.58it/s]\n",
      "Epoch: 028 | Lr: 0.00090249999999999998 |Train loss: 0.246383 | Val loss: 0.298416 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 44.64it/s]\n",
      "Epoch: 029 | Lr: 0.00090249999999999998 |Train loss: 0.250910 | Val loss: 0.288852 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 44.14it/s]\n",
      "Epoch: 030 | Lr: 0.00085737499999999996 |Train loss: 0.245192 | Val loss: 0.295782 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 40.84it/s]\n",
      "Epoch: 031 | Lr: 0.00085737499999999996 |Train loss: 0.245589 | Val loss: 0.290703 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 46.68it/s]\n",
      "Epoch: 032 | Lr: 0.00085737499999999996 |Train loss: 0.244978 | Val loss: 0.289810 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 41.81it/s]\n",
      "Epoch: 033 | Lr: 0.00085737499999999996 |Train loss: 0.245831 | Val loss: 0.290100 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.63it/s]\n",
      "Epoch: 034 | Lr: 0.00085737499999999996 |Train loss: 0.246064 | Val loss: 0.290863 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 44.18it/s]\n",
      "Epoch: 035 | Lr: 0.00085737499999999996 |Train loss: 0.245971 | Val loss: 0.287435 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:15<00:00, 47.06it/s]\n",
      "Epoch: 036 | Lr: 0.00085737499999999996 |Train loss: 0.244830 | Val loss: 0.292086 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.80it/s]\n",
      "Epoch: 037 | Lr: 0.00085737499999999996 |Train loss: 0.245931 | Val loss: 0.293304 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 44.88it/s]\n",
      "Epoch: 038 | Lr: 0.00085737499999999996 |Train loss: 0.245085 | Val loss: 0.287899 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.03it/s]\n",
      "Epoch: 039 | Lr: 0.00085737499999999996 |Train loss: 0.246017 | Val loss: 0.289979 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.91it/s]\n",
      "Epoch: 040 | Lr: 0.00081450624999999987 |Train loss: 0.245467 | Val loss: 0.288207 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.74it/s]\n",
      "Epoch: 041 | Lr: 0.00081450624999999987 |Train loss: 0.243487 | Val loss: 0.285900 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.16it/s]\n",
      "Epoch: 042 | Lr: 0.00081450624999999987 |Train loss: 0.244563 | Val loss: 0.285613 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 41.04it/s]\n",
      "Epoch: 043 | Lr: 0.00081450624999999987 |Train loss: 0.243347 | Val loss: 0.287880 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 40.54it/s]\n",
      "Epoch: 044 | Lr: 0.00081450624999999987 |Train loss: 0.243884 | Val loss: 0.291110 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.63it/s]\n",
      "Epoch: 045 | Lr: 0.00081450624999999987 |Train loss: 0.244072 | Val loss: 0.288911 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 46.35it/s]\n",
      "Epoch: 046 | Lr: 0.00081450624999999987 |Train loss: 0.244718 | Val loss: 0.286326 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:15<00:00, 48.45it/s]\n",
      "Epoch: 047 | Lr: 0.00081450624999999987 |Train loss: 0.243682 | Val loss: 0.285399 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.30it/s]\n",
      "Epoch: 048 | Lr: 0.00081450624999999987 |Train loss: 0.243910 | Val loss: 0.288171 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 44.52it/s]\n",
      "Epoch: 049 | Lr: 0.00081450624999999987 |Train loss: 0.243335 | Val loss: 0.286629 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:15<00:00, 47.29it/s]\n",
      "Epoch: 050 | Lr: 0.00077378093749999979 |Train loss: 0.244036 | Val loss: 0.288384 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:15<00:00, 47.21it/s]\n",
      "Epoch: 051 | Lr: 0.00077378093749999979 |Train loss: 0.242802 | Val loss: 0.281866 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 41.64it/s]\n",
      "Epoch: 052 | Lr: 0.00077378093749999979 |Train loss: 0.243438 | Val loss: 0.285599 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.08it/s]\n",
      "Epoch: 053 | Lr: 0.00077378093749999979 |Train loss: 0.242144 | Val loss: 0.281817 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.80it/s]\n",
      "Epoch: 054 | Lr: 0.00077378093749999979 |Train loss: 0.243738 | Val loss: 0.285724 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:15<00:00, 47.16it/s]\n",
      "Epoch: 055 | Lr: 0.00077378093749999979 |Train loss: 0.242302 | Val loss: 0.281343 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 44.42it/s]\n",
      "Epoch: 056 | Lr: 0.00077378093749999979 |Train loss: 0.243573 | Val loss: 0.284743 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.30it/s]\n",
      "Epoch: 057 | Lr: 0.00077378093749999979 |Train loss: 0.242339 | Val loss: 0.282057 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.14it/s]\n",
      "Epoch: 058 | Lr: 0.00077378093749999979 |Train loss: 0.243483 | Val loss: 0.285165 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.21it/s]\n",
      "Epoch: 059 | Lr: 0.00077378093749999979 |Train loss: 0.241571 | Val loss: 0.279768 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:14<00:00, 50.28it/s]\n",
      "Epoch: 060 | Lr: 0.00073509189062499975 |Train loss: 0.243401 | Val loss: 0.283639 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 46.43it/s]\n",
      "Epoch: 061 | Lr: 0.00073509189062499975 |Train loss: 0.241262 | Val loss: 0.279267 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.30it/s]\n",
      "Epoch: 062 | Lr: 0.00073509189062499975 |Train loss: 0.242253 | Val loss: 0.285073 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 40.70it/s]\n",
      "Epoch: 063 | Lr: 0.00073509189062499975 |Train loss: 0.241958 | Val loss: 0.277675 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 40.78it/s]\n",
      "Epoch: 064 | Lr: 0.00073509189062499975 |Train loss: 0.242180 | Val loss: 0.287629 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.15it/s]\n",
      "Epoch: 065 | Lr: 0.00073509189062499975 |Train loss: 0.241821 | Val loss: 0.278736 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.41it/s]\n",
      "Epoch: 066 | Lr: 0.00073509189062499975 |Train loss: 0.242520 | Val loss: 0.280248 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.58it/s]\n",
      "Epoch: 067 | Lr: 0.00073509189062499975 |Train loss: 0.241085 | Val loss: 0.278532 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 46.66it/s]\n",
      "Epoch: 068 | Lr: 0.00073509189062499975 |Train loss: 0.242334 | Val loss: 0.291494 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 46.26it/s]\n",
      "Epoch: 069 | Lr: 0.00073509189062499975 |Train loss: 0.242318 | Val loss: 0.278496 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:15<00:00, 47.73it/s]\n",
      "Epoch: 070 | Lr: 0.00069833729609374972 |Train loss: 0.241225 | Val loss: 0.279465 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.23it/s]\n",
      "Epoch: 071 | Lr: 0.00069833729609374972 |Train loss: 0.240473 | Val loss: 0.276370 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.81it/s]\n",
      "Epoch: 072 | Lr: 0.00069833729609374972 |Train loss: 0.240770 | Val loss: 0.282648 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.17it/s]\n",
      "Epoch: 073 | Lr: 0.00069833729609374972 |Train loss: 0.240416 | Val loss: 0.277242 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:15<00:00, 47.47it/s]\n",
      "Epoch: 074 | Lr: 0.00069833729609374972 |Train loss: 0.241157 | Val loss: 0.283713 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:15<00:00, 48.45it/s]\n",
      "Epoch: 075 | Lr: 0.00069833729609374972 |Train loss: 0.240979 | Val loss: 0.277464 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:19<00:00, 39.13it/s]\n",
      "Epoch: 076 | Lr: 0.00069833729609374972 |Train loss: 0.240644 | Val loss: 0.278302 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:15<00:00, 47.30it/s]\n",
      "Epoch: 077 | Lr: 0.00069833729609374972 |Train loss: 0.240890 | Val loss: 0.279192 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.39it/s]\n",
      "Epoch: 078 | Lr: 0.00069833729609374972 |Train loss: 0.240700 | Val loss: 0.283225 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.07it/s]\n",
      "Epoch: 079 | Lr: 0.00069833729609374972 |Train loss: 0.241221 | Val loss: 0.276684 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.15it/s]\n",
      "Epoch: 080 | Lr: 0.00066342043128906215 |Train loss: 0.240908 | Val loss: 0.282265 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.73it/s]\n",
      "Epoch: 081 | Lr: 0.00066342043128906215 |Train loss: 0.240381 | Val loss: 0.274841 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 44.42it/s]\n",
      "Epoch: 082 | Lr: 0.00066342043128906215 |Train loss: 0.239477 | Val loss: 0.278035 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 46.06it/s]\n",
      "Epoch: 083 | Lr: 0.00066342043128906215 |Train loss: 0.239854 | Val loss: 0.275462 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.86it/s]\n",
      "Epoch: 084 | Lr: 0.00066342043128906215 |Train loss: 0.240216 | Val loss: 0.278339 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.91it/s]\n",
      "Epoch: 085 | Lr: 0.00066342043128906215 |Train loss: 0.239572 | Val loss: 0.275635 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.29it/s]\n",
      "Epoch: 086 | Lr: 0.00066342043128906215 |Train loss: 0.239850 | Val loss: 0.279776 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.88it/s]\n",
      "Epoch: 087 | Lr: 0.00066342043128906215 |Train loss: 0.239867 | Val loss: 0.275025 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 44.05it/s]\n",
      "Epoch: 088 | Lr: 0.00066342043128906215 |Train loss: 0.240083 | Val loss: 0.286684 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.10it/s]\n",
      "Epoch: 089 | Lr: 0.00066342043128906215 |Train loss: 0.241398 | Val loss: 0.273969 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.28it/s]\n",
      "Epoch: 090 | Lr: 0.00063024940972460899 |Train loss: 0.239870 | Val loss: 0.276288 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:15<00:00, 47.69it/s]\n",
      "Epoch: 091 | Lr: 0.00063024940972460899 |Train loss: 0.238593 | Val loss: 0.273537 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 44.94it/s]\n",
      "Epoch: 092 | Lr: 0.00063024940972460899 |Train loss: 0.238942 | Val loss: 0.279337 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 40.55it/s]\n",
      "Epoch: 093 | Lr: 0.00063024940972460899 |Train loss: 0.240077 | Val loss: 0.275237 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 44.59it/s]\n",
      "Epoch: 094 | Lr: 0.00063024940972460899 |Train loss: 0.237730 | Val loss: 0.276071 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.78it/s]\n",
      "Epoch: 095 | Lr: 0.00063024940972460899 |Train loss: 0.239673 | Val loss: 0.279726 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.84it/s]\n",
      "Epoch: 096 | Lr: 0.00063024940972460899 |Train loss: 0.239293 | Val loss: 0.273487 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 46.27it/s]\n",
      "Epoch: 097 | Lr: 0.00063024940972460899 |Train loss: 0.238919 | Val loss: 0.280633 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.35it/s]\n",
      "Epoch: 098 | Lr: 0.00063024940972460899 |Train loss: 0.239878 | Val loss: 0.273681 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 41.99it/s]\n",
      "Epoch: 099 | Lr: 0.00063024940972460899 |Train loss: 0.239942 | Val loss: 0.277157 | GPU occupy: 592.738816 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.68it/s]\n",
      "Epoch: 100 | Lr: 0.00059873693923837847 |Train loss: 0.238864 | Val loss: 0.273285 | GPU occupy: 592.738816 MiB\n",
      "Dataset metr-la | Test loss 0.266120 | MAE 5.004055 | RMSE 9.431224 | WMAPE 0.09850721\n"
     ]
    }
   ],
   "source": [
    "#1: 0 middle layer + first order\n",
    "\n",
    "!python main.py --stblock_num=1 --Kt=2 --Ks=2 --middle_layer=True --epoch=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d20bd689-7afe-4c43-a290-f84382f86141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configs: Namespace(Ks=3, Kt=2, act_func='glu', batch_size=32, dataset='metr-la', droprate=0.5, enable_bias=True, enable_cuda=True, epochs=100, gamma=0.95, graph_conv_type='cheb_graph_conv', gso_type='sym_norm_lap', lr=0.001, middle_layer=True, n_his=12, n_pred=3, opt='adam', patience=30, seed=42, stblock_num=1, step_size=10, time_intvl=5, weight_decay_rate=0.0005)\n",
      "Blocks:  [[1], [64, 16, 64], [128, 128], [1]]\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00822724]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "Use iteration 19 instead with accuracy \n",
      "0.007941234546600588.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00794123]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "Modules:  [STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(1, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")]\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 40.17it/s]\n",
      "Epoch: 001 | Lr: 0.00100000000000000002 |Train loss: 0.349815 | Val loss: 0.392014 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:15<00:00, 48.19it/s]\n",
      "Epoch: 002 | Lr: 0.00100000000000000002 |Train loss: 0.280626 | Val loss: 0.359643 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 46.37it/s]\n",
      "Epoch: 003 | Lr: 0.00100000000000000002 |Train loss: 0.272748 | Val loss: 0.342036 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.58it/s]\n",
      "Epoch: 004 | Lr: 0.00100000000000000002 |Train loss: 0.259768 | Val loss: 0.330859 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.36it/s]\n",
      "Epoch: 005 | Lr: 0.00100000000000000002 |Train loss: 0.263441 | Val loss: 0.332612 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:15<00:00, 48.38it/s]\n",
      "Epoch: 006 | Lr: 0.00100000000000000002 |Train loss: 0.256261 | Val loss: 0.304473 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:15<00:00, 47.64it/s]\n",
      "Epoch: 007 | Lr: 0.00100000000000000002 |Train loss: 0.254795 | Val loss: 0.323928 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 40.61it/s]\n",
      "Epoch: 008 | Lr: 0.00100000000000000002 |Train loss: 0.256904 | Val loss: 0.310731 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.14it/s]\n",
      "Epoch: 009 | Lr: 0.00100000000000000002 |Train loss: 0.254063 | Val loss: 0.315724 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 44.46it/s]\n",
      "Epoch: 010 | Lr: 0.00095000000000000000 |Train loss: 0.254350 | Val loss: 0.360023 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.69it/s]\n",
      "Epoch: 011 | Lr: 0.00095000000000000000 |Train loss: 0.249832 | Val loss: 0.312627 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.71it/s]\n",
      "Epoch: 012 | Lr: 0.00095000000000000000 |Train loss: 0.252278 | Val loss: 0.304345 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 44.79it/s]\n",
      "Epoch: 013 | Lr: 0.00095000000000000000 |Train loss: 0.251140 | Val loss: 0.305465 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 40.02it/s]\n",
      "Epoch: 014 | Lr: 0.00095000000000000000 |Train loss: 0.250462 | Val loss: 0.314455 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 44.30it/s]\n",
      "Epoch: 015 | Lr: 0.00095000000000000000 |Train loss: 0.251900 | Val loss: 0.305489 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.35it/s]\n",
      "Epoch: 016 | Lr: 0.00095000000000000000 |Train loss: 0.250797 | Val loss: 0.302275 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:15<00:00, 47.32it/s]\n",
      "Epoch: 017 | Lr: 0.00095000000000000000 |Train loss: 0.248990 | Val loss: 0.327531 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 46.64it/s]\n",
      "Epoch: 018 | Lr: 0.00095000000000000000 |Train loss: 0.249994 | Val loss: 0.298972 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.78it/s]\n",
      "Epoch: 019 | Lr: 0.00095000000000000000 |Train loss: 0.250806 | Val loss: 0.311254 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.62it/s]\n",
      "Epoch: 020 | Lr: 0.00090249999999999998 |Train loss: 0.248853 | Val loss: 0.296744 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.62it/s]\n",
      "Epoch: 021 | Lr: 0.00090249999999999998 |Train loss: 0.248593 | Val loss: 0.290587 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 44.66it/s]\n",
      "Epoch: 022 | Lr: 0.00090249999999999998 |Train loss: 0.246703 | Val loss: 0.302140 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.18it/s]\n",
      "Epoch: 023 | Lr: 0.00090249999999999998 |Train loss: 0.248659 | Val loss: 0.293107 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:20<00:00, 37.04it/s]\n",
      "Epoch: 024 | Lr: 0.00090249999999999998 |Train loss: 0.249249 | Val loss: 0.295442 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.58it/s]\n",
      "Epoch: 025 | Lr: 0.00090249999999999998 |Train loss: 0.246257 | Val loss: 0.291388 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 46.44it/s]\n",
      "Epoch: 026 | Lr: 0.00090249999999999998 |Train loss: 0.247143 | Val loss: 0.297130 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 41.48it/s]\n",
      "Epoch: 027 | Lr: 0.00090249999999999998 |Train loss: 0.248004 | Val loss: 0.289089 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.51it/s]\n",
      "Epoch: 028 | Lr: 0.00090249999999999998 |Train loss: 0.245283 | Val loss: 0.291772 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:15<00:00, 47.41it/s]\n",
      "Epoch: 029 | Lr: 0.00090249999999999998 |Train loss: 0.248485 | Val loss: 0.295704 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 44.51it/s]\n",
      "Epoch: 030 | Lr: 0.00085737499999999996 |Train loss: 0.244867 | Val loss: 0.290305 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 46.78it/s]\n",
      "Epoch: 031 | Lr: 0.00085737499999999996 |Train loss: 0.244554 | Val loss: 0.287432 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.84it/s]\n",
      "Epoch: 032 | Lr: 0.00085737499999999996 |Train loss: 0.244748 | Val loss: 0.288971 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 41.90it/s]\n",
      "Epoch: 033 | Lr: 0.00085737499999999996 |Train loss: 0.247766 | Val loss: 0.286971 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 46.51it/s]\n",
      "Epoch: 034 | Lr: 0.00085737499999999996 |Train loss: 0.243319 | Val loss: 0.285578 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.57it/s]\n",
      "Epoch: 035 | Lr: 0.00085737499999999996 |Train loss: 0.244531 | Val loss: 0.284668 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:19<00:00, 39.08it/s]\n",
      "Epoch: 036 | Lr: 0.00085737499999999996 |Train loss: 0.244447 | Val loss: 0.285786 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 41.39it/s]\n",
      "Epoch: 037 | Lr: 0.00085737499999999996 |Train loss: 0.242823 | Val loss: 0.288117 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 44.29it/s]\n",
      "Epoch: 038 | Lr: 0.00085737499999999996 |Train loss: 0.244051 | Val loss: 0.287055 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 44.00it/s]\n",
      "Epoch: 039 | Lr: 0.00085737499999999996 |Train loss: 0.243832 | Val loss: 0.287624 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 46.18it/s]\n",
      "Epoch: 040 | Lr: 0.00081450624999999987 |Train loss: 0.244346 | Val loss: 0.286668 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:15<00:00, 48.26it/s]\n",
      "Epoch: 041 | Lr: 0.00081450624999999987 |Train loss: 0.241624 | Val loss: 0.283193 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 40.18it/s]\n",
      "Epoch: 042 | Lr: 0.00081450624999999987 |Train loss: 0.242719 | Val loss: 0.285530 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.58it/s]\n",
      "Epoch: 043 | Lr: 0.00081450624999999987 |Train loss: 0.241801 | Val loss: 0.283818 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.16it/s]\n",
      "Epoch: 044 | Lr: 0.00081450624999999987 |Train loss: 0.243090 | Val loss: 0.283347 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.19it/s]\n",
      "Epoch: 045 | Lr: 0.00081450624999999987 |Train loss: 0.242040 | Val loss: 0.285399 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 46.77it/s]\n",
      "Epoch: 046 | Lr: 0.00081450624999999987 |Train loss: 0.243907 | Val loss: 0.281414 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.20it/s]\n",
      "Epoch: 047 | Lr: 0.00081450624999999987 |Train loss: 0.241427 | Val loss: 0.284270 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.75it/s]\n",
      "Epoch: 048 | Lr: 0.00081450624999999987 |Train loss: 0.242627 | Val loss: 0.281301 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.71it/s]\n",
      "Epoch: 049 | Lr: 0.00081450624999999987 |Train loss: 0.241385 | Val loss: 0.283463 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:15<00:00, 47.11it/s]\n",
      "Epoch: 050 | Lr: 0.00077378093749999979 |Train loss: 0.241345 | Val loss: 0.282872 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.25it/s]\n",
      "Epoch: 051 | Lr: 0.00077378093749999979 |Train loss: 0.240773 | Val loss: 0.278759 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 46.02it/s]\n",
      "Epoch: 052 | Lr: 0.00077378093749999979 |Train loss: 0.240348 | Val loss: 0.282041 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.87it/s]\n",
      "Epoch: 053 | Lr: 0.00077378093749999979 |Train loss: 0.241128 | Val loss: 0.281105 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.23it/s]\n",
      "Epoch: 054 | Lr: 0.00077378093749999979 |Train loss: 0.240999 | Val loss: 0.280245 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 41.17it/s]\n",
      "Epoch: 055 | Lr: 0.00077378093749999979 |Train loss: 0.240064 | Val loss: 0.280289 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 46.74it/s]\n",
      "Epoch: 056 | Lr: 0.00077378093749999979 |Train loss: 0.239719 | Val loss: 0.281219 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:15<00:00, 46.88it/s]\n",
      "Epoch: 057 | Lr: 0.00077378093749999979 |Train loss: 0.240060 | Val loss: 0.282164 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 44.07it/s]\n",
      "Epoch: 058 | Lr: 0.00077378093749999979 |Train loss: 0.240276 | Val loss: 0.281429 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 44.45it/s]\n",
      "Epoch: 059 | Lr: 0.00077378093749999979 |Train loss: 0.240370 | Val loss: 0.281390 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 39.87it/s]\n",
      "Epoch: 060 | Lr: 0.00073509189062499975 |Train loss: 0.239807 | Val loss: 0.280316 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.19it/s]\n",
      "Epoch: 061 | Lr: 0.00073509189062499975 |Train loss: 0.239078 | Val loss: 0.278146 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.72it/s]\n",
      "Epoch: 062 | Lr: 0.00073509189062499975 |Train loss: 0.239784 | Val loss: 0.280335 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 44.87it/s]\n",
      "Epoch: 063 | Lr: 0.00073509189062499975 |Train loss: 0.238816 | Val loss: 0.277503 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.14it/s]\n",
      "Epoch: 064 | Lr: 0.00073509189062499975 |Train loss: 0.239328 | Val loss: 0.278526 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 46.01it/s]\n",
      "Epoch: 065 | Lr: 0.00073509189062499975 |Train loss: 0.238687 | Val loss: 0.279827 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.07it/s]\n",
      "Epoch: 066 | Lr: 0.00073509189062499975 |Train loss: 0.239352 | Val loss: 0.280279 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 44.52it/s]\n",
      "Epoch: 067 | Lr: 0.00073509189062499975 |Train loss: 0.238556 | Val loss: 0.284147 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.52it/s]\n",
      "Epoch: 068 | Lr: 0.00073509189062499975 |Train loss: 0.240356 | Val loss: 0.277019 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.36it/s]\n",
      "Epoch: 069 | Lr: 0.00073509189062499975 |Train loss: 0.239194 | Val loss: 0.278735 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:15<00:00, 48.07it/s]\n",
      "Epoch: 070 | Lr: 0.00069833729609374972 |Train loss: 0.238633 | Val loss: 0.275957 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.11it/s]\n",
      "Epoch: 071 | Lr: 0.00069833729609374972 |Train loss: 0.239048 | Val loss: 0.276563 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 46.57it/s]\n",
      "Epoch: 072 | Lr: 0.00069833729609374972 |Train loss: 0.237422 | Val loss: 0.274897 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.77it/s]\n",
      "Epoch: 073 | Lr: 0.00069833729609374972 |Train loss: 0.239146 | Val loss: 0.275674 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 39.75it/s]\n",
      "Epoch: 074 | Lr: 0.00069833729609374972 |Train loss: 0.237412 | Val loss: 0.275275 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.93it/s]\n",
      "Epoch: 075 | Lr: 0.00069833729609374972 |Train loss: 0.238520 | Val loss: 0.281095 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.57it/s]\n",
      "Epoch: 076 | Lr: 0.00069833729609374972 |Train loss: 0.238370 | Val loss: 0.275567 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.54it/s]\n",
      "Epoch: 077 | Lr: 0.00069833729609374972 |Train loss: 0.238522 | Val loss: 0.275913 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.43it/s]\n",
      "Epoch: 078 | Lr: 0.00069833729609374972 |Train loss: 0.237185 | Val loss: 0.275928 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.69it/s]\n",
      "Epoch: 079 | Lr: 0.00069833729609374972 |Train loss: 0.237953 | Val loss: 0.278705 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 46.37it/s]\n",
      "Epoch: 080 | Lr: 0.00066342043128906215 |Train loss: 0.238339 | Val loss: 0.280051 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.26it/s]\n",
      "Epoch: 081 | Lr: 0.00066342043128906215 |Train loss: 0.238560 | Val loss: 0.275985 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.68it/s]\n",
      "Epoch: 082 | Lr: 0.00066342043128906215 |Train loss: 0.237780 | Val loss: 0.276445 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:14<00:00, 50.36it/s]\n",
      "Epoch: 083 | Lr: 0.00066342043128906215 |Train loss: 0.236775 | Val loss: 0.274236 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.02it/s]\n",
      "Epoch: 084 | Lr: 0.00066342043128906215 |Train loss: 0.238425 | Val loss: 0.274884 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.33it/s]\n",
      "Epoch: 085 | Lr: 0.00066342043128906215 |Train loss: 0.237389 | Val loss: 0.274009 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.06it/s]\n",
      "Epoch: 086 | Lr: 0.00066342043128906215 |Train loss: 0.236812 | Val loss: 0.274463 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:15<00:00, 49.25it/s]\n",
      "Epoch: 087 | Lr: 0.00066342043128906215 |Train loss: 0.237858 | Val loss: 0.274139 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:15<00:00, 47.85it/s]\n",
      "Epoch: 088 | Lr: 0.00066342043128906215 |Train loss: 0.237635 | Val loss: 0.275715 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 46.60it/s]\n",
      "Epoch: 089 | Lr: 0.00066342043128906215 |Train loss: 0.238023 | Val loss: 0.272774 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.22it/s]\n",
      "Epoch: 090 | Lr: 0.00063024940972460899 |Train loss: 0.236911 | Val loss: 0.272529 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.61it/s]\n",
      "Epoch: 091 | Lr: 0.00063024940972460899 |Train loss: 0.236049 | Val loss: 0.271960 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 46.02it/s]\n",
      "Epoch: 092 | Lr: 0.00063024940972460899 |Train loss: 0.236469 | Val loss: 0.274096 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.58it/s]\n",
      "Epoch: 093 | Lr: 0.00063024940972460899 |Train loss: 0.236915 | Val loss: 0.274693 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 40.51it/s]\n",
      "Epoch: 094 | Lr: 0.00063024940972460899 |Train loss: 0.237120 | Val loss: 0.272638 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.86it/s]\n",
      "Epoch: 095 | Lr: 0.00063024940972460899 |Train loss: 0.235779 | Val loss: 0.272178 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 40.74it/s]\n",
      "Epoch: 096 | Lr: 0.00063024940972460899 |Train loss: 0.236916 | Val loss: 0.275342 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:15<00:00, 47.03it/s]\n",
      "Epoch: 097 | Lr: 0.00063024940972460899 |Train loss: 0.236595 | Val loss: 0.273756 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 44.89it/s]\n",
      "Epoch: 098 | Lr: 0.00063024940972460899 |Train loss: 0.236893 | Val loss: 0.273707 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:15<00:00, 48.29it/s]\n",
      "Epoch: 099 | Lr: 0.00063024940972460899 |Train loss: 0.236712 | Val loss: 0.271330 | GPU occupy: 592.964096 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.49it/s]\n",
      "Epoch: 100 | Lr: 0.00059873693923837847 |Train loss: 0.236001 | Val loss: 0.273056 | GPU occupy: 592.964096 MiB\n",
      "Dataset metr-la | Test loss 0.266250 | MAE 4.906176 | RMSE 9.443183 | WMAPE 0.09658042\n"
     ]
    }
   ],
   "source": [
    "#2: 0 middle layer + second order\n",
    "\n",
    "!python main.py --stblock_num=1 --Kt=2 --Ks=3 --middle_layer=True --epoch=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7df41c1-6923-4cf6-93a8-b55f42f5cbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configs: Namespace(Ks=4, Kt=2, act_func='glu', batch_size=32, dataset='metr-la', droprate=0.5, enable_bias=True, enable_cuda=True, epochs=100, gamma=0.95, graph_conv_type='cheb_graph_conv', gso_type='sym_norm_lap', lr=0.001, middle_layer=True, n_his=12, n_pred=3, opt='adam', patience=30, seed=42, stblock_num=1, step_size=10, time_intvl=5, weight_decay_rate=0.0005)\n",
      "Blocks:  [[1], [64, 16, 64], [128, 128], [1]]\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00822724]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "Use iteration 19 instead with accuracy \n",
      "0.007941234546600588.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00794123]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "Modules:  [STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(1, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")]\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 41.74it/s]\n",
      "Epoch: 001 | Lr: 0.00100000000000000002 |Train loss: 0.319273 | Val loss: 0.369475 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.96it/s]\n",
      "Epoch: 002 | Lr: 0.00100000000000000002 |Train loss: 0.288046 | Val loss: 0.394690 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 41.68it/s]\n",
      "Epoch: 003 | Lr: 0.00100000000000000002 |Train loss: 0.282919 | Val loss: 0.321220 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.58it/s]\n",
      "Epoch: 004 | Lr: 0.00100000000000000002 |Train loss: 0.260927 | Val loss: 0.356222 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 39.80it/s]\n",
      "Epoch: 005 | Lr: 0.00100000000000000002 |Train loss: 0.267647 | Val loss: 0.314341 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:19<00:00, 37.92it/s]\n",
      "Epoch: 006 | Lr: 0.00100000000000000002 |Train loss: 0.258167 | Val loss: 0.318521 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 46.21it/s]\n",
      "Epoch: 007 | Lr: 0.00100000000000000002 |Train loss: 0.261941 | Val loss: 0.319174 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 41.92it/s]\n",
      "Epoch: 008 | Lr: 0.00100000000000000002 |Train loss: 0.258476 | Val loss: 0.314431 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:15<00:00, 47.17it/s]\n",
      "Epoch: 009 | Lr: 0.00100000000000000002 |Train loss: 0.260084 | Val loss: 0.311042 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.63it/s]\n",
      "Epoch: 010 | Lr: 0.00095000000000000000 |Train loss: 0.255654 | Val loss: 0.312323 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 44.30it/s]\n",
      "Epoch: 011 | Lr: 0.00095000000000000000 |Train loss: 0.253328 | Val loss: 0.346039 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 41.80it/s]\n",
      "Epoch: 012 | Lr: 0.00095000000000000000 |Train loss: 0.252779 | Val loss: 0.303668 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 44.76it/s]\n",
      "Epoch: 013 | Lr: 0.00095000000000000000 |Train loss: 0.253034 | Val loss: 0.303687 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.49it/s]\n",
      "Epoch: 014 | Lr: 0.00095000000000000000 |Train loss: 0.251390 | Val loss: 0.354673 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.76it/s]\n",
      "Epoch: 015 | Lr: 0.00095000000000000000 |Train loss: 0.248814 | Val loss: 0.304051 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.42it/s]\n",
      "Epoch: 016 | Lr: 0.00095000000000000000 |Train loss: 0.251282 | Val loss: 0.298393 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 41.84it/s]\n",
      "Epoch: 017 | Lr: 0.00095000000000000000 |Train loss: 0.249717 | Val loss: 0.304367 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 41.24it/s]\n",
      "Epoch: 018 | Lr: 0.00095000000000000000 |Train loss: 0.250635 | Val loss: 0.301636 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 41.95it/s]\n",
      "Epoch: 019 | Lr: 0.00095000000000000000 |Train loss: 0.250723 | Val loss: 0.374099 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.65it/s]\n",
      "Epoch: 020 | Lr: 0.00090249999999999998 |Train loss: 0.244488 | Val loss: 0.313977 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.48it/s]\n",
      "Epoch: 021 | Lr: 0.00090249999999999998 |Train loss: 0.250707 | Val loss: 0.302705 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.04it/s]\n",
      "Epoch: 022 | Lr: 0.00090249999999999998 |Train loss: 0.245350 | Val loss: 0.292999 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.60it/s]\n",
      "Epoch: 023 | Lr: 0.00090249999999999998 |Train loss: 0.247597 | Val loss: 0.291172 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 41.21it/s]\n",
      "Epoch: 024 | Lr: 0.00090249999999999998 |Train loss: 0.245661 | Val loss: 0.304960 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.58it/s]\n",
      "Epoch: 025 | Lr: 0.00090249999999999998 |Train loss: 0.248355 | Val loss: 0.296365 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.55it/s]\n",
      "Epoch: 026 | Lr: 0.00090249999999999998 |Train loss: 0.245267 | Val loss: 0.296852 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 41.40it/s]\n",
      "Epoch: 027 | Lr: 0.00090249999999999998 |Train loss: 0.246825 | Val loss: 0.294800 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.76it/s]\n",
      "Epoch: 028 | Lr: 0.00090249999999999998 |Train loss: 0.245361 | Val loss: 0.299809 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 39.86it/s]\n",
      "Epoch: 029 | Lr: 0.00090249999999999998 |Train loss: 0.246847 | Val loss: 0.293600 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.05it/s]\n",
      "Epoch: 030 | Lr: 0.00085737499999999996 |Train loss: 0.244814 | Val loss: 0.294751 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 40.00it/s]\n",
      "Epoch: 031 | Lr: 0.00085737499999999996 |Train loss: 0.244177 | Val loss: 0.291358 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.72it/s]\n",
      "Epoch: 032 | Lr: 0.00085737499999999996 |Train loss: 0.244267 | Val loss: 0.289546 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 44.52it/s]\n",
      "Epoch: 033 | Lr: 0.00085737499999999996 |Train loss: 0.244256 | Val loss: 0.293236 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 41.06it/s]\n",
      "Epoch: 034 | Lr: 0.00085737499999999996 |Train loss: 0.245930 | Val loss: 0.288366 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 46.00it/s]\n",
      "Epoch: 035 | Lr: 0.00085737499999999996 |Train loss: 0.243356 | Val loss: 0.294546 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:19<00:00, 38.67it/s]\n",
      "Epoch: 036 | Lr: 0.00085737499999999996 |Train loss: 0.243656 | Val loss: 0.289733 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.98it/s]\n",
      "Epoch: 037 | Lr: 0.00085737499999999996 |Train loss: 0.244732 | Val loss: 0.288212 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 41.34it/s]\n",
      "Epoch: 038 | Lr: 0.00085737499999999996 |Train loss: 0.243611 | Val loss: 0.291971 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.42it/s]\n",
      "Epoch: 039 | Lr: 0.00085737499999999996 |Train loss: 0.244307 | Val loss: 0.289138 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 40.32it/s]\n",
      "Epoch: 040 | Lr: 0.00081450624999999987 |Train loss: 0.242965 | Val loss: 0.291403 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.62it/s]\n",
      "Epoch: 041 | Lr: 0.00081450624999999987 |Train loss: 0.245139 | Val loss: 0.328349 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.05it/s]\n",
      "Epoch: 042 | Lr: 0.00081450624999999987 |Train loss: 0.240797 | Val loss: 0.285295 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.27it/s]\n",
      "Epoch: 043 | Lr: 0.00081450624999999987 |Train loss: 0.242399 | Val loss: 0.290148 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.12it/s]\n",
      "Epoch: 044 | Lr: 0.00081450624999999987 |Train loss: 0.243228 | Val loss: 0.286027 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.05it/s]\n",
      "Epoch: 045 | Lr: 0.00081450624999999987 |Train loss: 0.242228 | Val loss: 0.282394 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.40it/s]\n",
      "Epoch: 046 | Lr: 0.00081450624999999987 |Train loss: 0.241012 | Val loss: 0.284302 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 41.61it/s]\n",
      "Epoch: 047 | Lr: 0.00081450624999999987 |Train loss: 0.243844 | Val loss: 0.331179 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.30it/s]\n",
      "Epoch: 048 | Lr: 0.00081450624999999987 |Train loss: 0.242302 | Val loss: 0.288078 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.54it/s]\n",
      "Epoch: 049 | Lr: 0.00081450624999999987 |Train loss: 0.241901 | Val loss: 0.285215 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 44.81it/s]\n",
      "Epoch: 050 | Lr: 0.00077378093749999979 |Train loss: 0.241314 | Val loss: 0.282121 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 40.16it/s]\n",
      "Epoch: 051 | Lr: 0.00077378093749999979 |Train loss: 0.240174 | Val loss: 0.283114 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.17it/s]\n",
      "Epoch: 052 | Lr: 0.00077378093749999979 |Train loss: 0.241487 | Val loss: 0.284780 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.85it/s]\n",
      "Epoch: 053 | Lr: 0.00077378093749999979 |Train loss: 0.240590 | Val loss: 0.278846 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 44.16it/s]\n",
      "Epoch: 054 | Lr: 0.00077378093749999979 |Train loss: 0.240236 | Val loss: 0.285026 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:19<00:00, 37.99it/s]\n",
      "Epoch: 055 | Lr: 0.00077378093749999979 |Train loss: 0.241357 | Val loss: 0.280435 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 46.23it/s]\n",
      "Epoch: 056 | Lr: 0.00077378093749999979 |Train loss: 0.240016 | Val loss: 0.286032 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.75it/s]\n",
      "Epoch: 057 | Lr: 0.00077378093749999979 |Train loss: 0.240128 | Val loss: 0.287879 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.44it/s]\n",
      "Epoch: 058 | Lr: 0.00077378093749999979 |Train loss: 0.242538 | Val loss: 0.291707 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:19<00:00, 39.30it/s]\n",
      "Epoch: 059 | Lr: 0.00077378093749999979 |Train loss: 0.240316 | Val loss: 0.283159 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.50it/s]\n",
      "Epoch: 060 | Lr: 0.00073509189062499975 |Train loss: 0.241077 | Val loss: 0.279676 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.44it/s]\n",
      "Epoch: 061 | Lr: 0.00073509189062499975 |Train loss: 0.239549 | Val loss: 0.280415 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.14it/s]\n",
      "Epoch: 062 | Lr: 0.00073509189062499975 |Train loss: 0.238986 | Val loss: 0.275455 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.21it/s]\n",
      "Epoch: 063 | Lr: 0.00073509189062499975 |Train loss: 0.238590 | Val loss: 0.281868 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 40.21it/s]\n",
      "Epoch: 064 | Lr: 0.00073509189062499975 |Train loss: 0.239474 | Val loss: 0.278687 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 45.86it/s]\n",
      "Epoch: 065 | Lr: 0.00073509189062499975 |Train loss: 0.239587 | Val loss: 0.283307 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 40.32it/s]\n",
      "Epoch: 066 | Lr: 0.00073509189062499975 |Train loss: 0.240132 | Val loss: 0.292451 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.38it/s]\n",
      "Epoch: 067 | Lr: 0.00073509189062499975 |Train loss: 0.241090 | Val loss: 0.276589 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 40.61it/s]\n",
      "Epoch: 068 | Lr: 0.00073509189062499975 |Train loss: 0.237783 | Val loss: 0.277370 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.84it/s]\n",
      "Epoch: 069 | Lr: 0.00073509189062499975 |Train loss: 0.239728 | Val loss: 0.284302 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:20<00:00, 36.79it/s]\n",
      "Epoch: 070 | Lr: 0.00069833729609374972 |Train loss: 0.239621 | Val loss: 0.275263 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.60it/s]\n",
      "Epoch: 071 | Lr: 0.00069833729609374972 |Train loss: 0.237680 | Val loss: 0.276163 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 40.68it/s]\n",
      "Epoch: 072 | Lr: 0.00069833729609374972 |Train loss: 0.237491 | Val loss: 0.276384 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 41.99it/s]\n",
      "Epoch: 073 | Lr: 0.00069833729609374972 |Train loss: 0.238199 | Val loss: 0.280624 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 41.09it/s]\n",
      "Epoch: 074 | Lr: 0.00069833729609374972 |Train loss: 0.239078 | Val loss: 0.276172 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 40.88it/s]\n",
      "Epoch: 075 | Lr: 0.00069833729609374972 |Train loss: 0.238842 | Val loss: 0.280741 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.71it/s]\n",
      "Epoch: 076 | Lr: 0.00069833729609374972 |Train loss: 0.238205 | Val loss: 0.279485 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.34it/s]\n",
      "Epoch: 077 | Lr: 0.00069833729609374972 |Train loss: 0.238381 | Val loss: 0.290387 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 44.57it/s]\n",
      "Epoch: 078 | Lr: 0.00069833729609374972 |Train loss: 0.239602 | Val loss: 0.279508 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 44.12it/s]\n",
      "Epoch: 079 | Lr: 0.00069833729609374972 |Train loss: 0.238497 | Val loss: 0.276010 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 41.89it/s]\n",
      "Epoch: 080 | Lr: 0.00066342043128906215 |Train loss: 0.237560 | Val loss: 0.277009 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 39.95it/s]\n",
      "Epoch: 081 | Lr: 0.00066342043128906215 |Train loss: 0.237389 | Val loss: 0.275181 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 40.57it/s]\n",
      "Epoch: 082 | Lr: 0.00066342043128906215 |Train loss: 0.236494 | Val loss: 0.276220 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 41.64it/s]\n",
      "Epoch: 083 | Lr: 0.00066342043128906215 |Train loss: 0.237253 | Val loss: 0.278205 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.57it/s]\n",
      "Epoch: 084 | Lr: 0.00066342043128906215 |Train loss: 0.238506 | Val loss: 0.277774 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 41.80it/s]\n",
      "Epoch: 085 | Lr: 0.00066342043128906215 |Train loss: 0.237990 | Val loss: 0.275714 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 41.06it/s]\n",
      "Epoch: 086 | Lr: 0.00066342043128906215 |Train loss: 0.236559 | Val loss: 0.275300 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 39.75it/s]\n",
      "Epoch: 087 | Lr: 0.00066342043128906215 |Train loss: 0.238212 | Val loss: 0.284467 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 40.84it/s]\n",
      "Epoch: 088 | Lr: 0.00066342043128906215 |Train loss: 0.238223 | Val loss: 0.277645 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:19<00:00, 37.85it/s]\n",
      "Epoch: 089 | Lr: 0.00066342043128906215 |Train loss: 0.238188 | Val loss: 0.279815 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 43.69it/s]\n",
      "Epoch: 090 | Lr: 0.00063024940972460899 |Train loss: 0.237730 | Val loss: 0.274762 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.20it/s]\n",
      "Epoch: 091 | Lr: 0.00063024940972460899 |Train loss: 0.237061 | Val loss: 0.271887 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 40.93it/s]\n",
      "Epoch: 092 | Lr: 0.00063024940972460899 |Train loss: 0.236507 | Val loss: 0.274852 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 40.35it/s]\n",
      "Epoch: 093 | Lr: 0.00063024940972460899 |Train loss: 0.236598 | Val loss: 0.272795 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.68it/s]\n",
      "Epoch: 094 | Lr: 0.00063024940972460899 |Train loss: 0.235471 | Val loss: 0.273524 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.87it/s]\n",
      "Epoch: 095 | Lr: 0.00063024940972460899 |Train loss: 0.236529 | Val loss: 0.278409 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 44.90it/s]\n",
      "Epoch: 096 | Lr: 0.00063024940972460899 |Train loss: 0.237807 | Val loss: 0.273677 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:17<00:00, 42.90it/s]\n",
      "Epoch: 097 | Lr: 0.00063024940972460899 |Train loss: 0.236182 | Val loss: 0.273828 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:16<00:00, 44.60it/s]\n",
      "Epoch: 098 | Lr: 0.00063024940972460899 |Train loss: 0.236075 | Val loss: 0.274861 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:18<00:00, 41.56it/s]\n",
      "Epoch: 099 | Lr: 0.00063024940972460899 |Train loss: 0.235901 | Val loss: 0.272979 | GPU occupy: 594.579968 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:19<00:00, 39.08it/s]\n",
      "Epoch: 100 | Lr: 0.00059873693923837847 |Train loss: 0.236717 | Val loss: 0.277682 | GPU occupy: 594.579968 MiB\n",
      "Dataset metr-la | Test loss 0.277353 | MAE 5.211773 | RMSE 9.622222 | WMAPE 0.10259625\n"
     ]
    }
   ],
   "source": [
    "#3: 0 middle layer + third order\n",
    "\n",
    "!python main.py --stblock_num=1 --Kt=2 --Ks=4 --middle_layer=True --epoch=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b09d3869-6f2b-4502-a590-660e0cbbafa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configs: Namespace(Ks=2, Kt=2, act_func='glu', batch_size=32, dataset='metr-la', droprate=0.5, enable_bias=True, enable_cuda=True, epochs=100, gamma=0.95, graph_conv_type='cheb_graph_conv', gso_type='sym_norm_lap', lr=0.001, middle_layer=True, n_his=12, n_pred=3, opt='adam', patience=30, seed=42, stblock_num=2, step_size=10, time_intvl=5, weight_decay_rate=0.0005)\n",
      "Blocks:  [[1], [64, 16, 64], [64, 16, 64], [128, 128], [1]]\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00822724]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "Use iteration 19 instead with accuracy \n",
      "0.007941234546600588.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00794123]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "Modules:  [STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(1, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), MiddleBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 256, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (tc1_ln): LayerNorm((207, 128), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")]\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 24.03it/s]\n",
      "Epoch: 001 | Lr: 0.00100000000000000002 |Train loss: 0.347104 | Val loss: 0.496707 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.99it/s]\n",
      "Epoch: 002 | Lr: 0.00100000000000000002 |Train loss: 0.289022 | Val loss: 0.427631 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.55it/s]\n",
      "Epoch: 003 | Lr: 0.00100000000000000002 |Train loss: 0.289281 | Val loss: 0.371758 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.22it/s]\n",
      "Epoch: 004 | Lr: 0.00100000000000000002 |Train loss: 0.278724 | Val loss: 0.350667 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.36it/s]\n",
      "Epoch: 005 | Lr: 0.00100000000000000002 |Train loss: 0.270531 | Val loss: 0.358207 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.96it/s]\n",
      "Epoch: 006 | Lr: 0.00100000000000000002 |Train loss: 0.277070 | Val loss: 0.338763 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 22.77it/s]\n",
      "Epoch: 007 | Lr: 0.00100000000000000002 |Train loss: 0.265507 | Val loss: 0.336594 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 24.07it/s]\n",
      "Epoch: 008 | Lr: 0.00100000000000000002 |Train loss: 0.269080 | Val loss: 0.339207 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.17it/s]\n",
      "Epoch: 009 | Lr: 0.00100000000000000002 |Train loss: 0.265339 | Val loss: 0.321310 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.27it/s]\n",
      "Epoch: 010 | Lr: 0.00095000000000000000 |Train loss: 0.262763 | Val loss: 0.324650 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 24.17it/s]\n",
      "Epoch: 011 | Lr: 0.00095000000000000000 |Train loss: 0.262099 | Val loss: 0.318814 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.37it/s]\n",
      "Epoch: 012 | Lr: 0.00095000000000000000 |Train loss: 0.261963 | Val loss: 0.314685 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 25.87it/s]\n",
      "Epoch: 013 | Lr: 0.00095000000000000000 |Train loss: 0.261829 | Val loss: 0.314089 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 24.12it/s]\n",
      "Epoch: 014 | Lr: 0.00095000000000000000 |Train loss: 0.259740 | Val loss: 0.319109 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.43it/s]\n",
      "Epoch: 015 | Lr: 0.00095000000000000000 |Train loss: 0.260054 | Val loss: 0.310176 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.90it/s]\n",
      "Epoch: 016 | Lr: 0.00095000000000000000 |Train loss: 0.277935 | Val loss: 0.300243 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 23.28it/s]\n",
      "Epoch: 017 | Lr: 0.00095000000000000000 |Train loss: 0.255906 | Val loss: 0.308077 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.28it/s]\n",
      "Epoch: 018 | Lr: 0.00095000000000000000 |Train loss: 0.259110 | Val loss: 0.333019 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.77it/s]\n",
      "Epoch: 019 | Lr: 0.00095000000000000000 |Train loss: 0.261131 | Val loss: 0.308760 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 24.00it/s]\n",
      "Epoch: 020 | Lr: 0.00090249999999999998 |Train loss: 0.258017 | Val loss: 0.311128 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.59it/s]\n",
      "Epoch: 021 | Lr: 0.00090249999999999998 |Train loss: 0.257008 | Val loss: 0.305289 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.04it/s]\n",
      "Epoch: 022 | Lr: 0.00090249999999999998 |Train loss: 0.256846 | Val loss: 0.308476 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.32it/s]\n",
      "Epoch: 023 | Lr: 0.00090249999999999998 |Train loss: 0.256805 | Val loss: 0.308531 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 25.91it/s]\n",
      "Epoch: 024 | Lr: 0.00090249999999999998 |Train loss: 0.271825 | Val loss: 0.298502 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.96it/s]\n",
      "Epoch: 025 | Lr: 0.00090249999999999998 |Train loss: 0.254744 | Val loss: 0.301228 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.62it/s]\n",
      "Epoch: 026 | Lr: 0.00090249999999999998 |Train loss: 0.254482 | Val loss: 0.307069 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.20it/s]\n",
      "Epoch: 027 | Lr: 0.00090249999999999998 |Train loss: 0.255317 | Val loss: 0.309290 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.51it/s]\n",
      "Epoch: 028 | Lr: 0.00090249999999999998 |Train loss: 0.255721 | Val loss: 0.312069 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.69it/s]\n",
      "Epoch: 029 | Lr: 0.00090249999999999998 |Train loss: 0.256481 | Val loss: 0.306579 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.28it/s]\n",
      "Epoch: 030 | Lr: 0.00085737499999999996 |Train loss: 0.256431 | Val loss: 0.306621 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.26it/s]\n",
      "Epoch: 031 | Lr: 0.00085737499999999996 |Train loss: 0.255822 | Val loss: 0.299392 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.64it/s]\n",
      "Epoch: 032 | Lr: 0.00085737499999999996 |Train loss: 0.253225 | Val loss: 0.304593 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 24.13it/s]\n",
      "Epoch: 033 | Lr: 0.00085737499999999996 |Train loss: 0.254510 | Val loss: 0.298940 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 23.40it/s]\n",
      "Epoch: 034 | Lr: 0.00085737499999999996 |Train loss: 0.252883 | Val loss: 0.305738 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:33<00:00, 22.65it/s]\n",
      "Epoch: 035 | Lr: 0.00085737499999999996 |Train loss: 0.254983 | Val loss: 0.300545 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 24.04it/s]\n",
      "Epoch: 036 | Lr: 0.00085737499999999996 |Train loss: 0.252782 | Val loss: 0.300023 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 23.03it/s]\n",
      "Epoch: 037 | Lr: 0.00085737499999999996 |Train loss: 0.253430 | Val loss: 0.306228 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:27<00:00, 26.84it/s]\n",
      "Epoch: 038 | Lr: 0.00085737499999999996 |Train loss: 0.253488 | Val loss: 0.297417 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.66it/s]\n",
      "Epoch: 039 | Lr: 0.00085737499999999996 |Train loss: 0.251384 | Val loss: 0.303405 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.84it/s]\n",
      "Epoch: 040 | Lr: 0.00081450624999999987 |Train loss: 0.252084 | Val loss: 0.305050 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 23.18it/s]\n",
      "Epoch: 041 | Lr: 0.00081450624999999987 |Train loss: 0.251569 | Val loss: 0.300426 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 24.09it/s]\n",
      "Epoch: 042 | Lr: 0.00081450624999999987 |Train loss: 0.250769 | Val loss: 0.301657 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.76it/s]\n",
      "Epoch: 043 | Lr: 0.00081450624999999987 |Train loss: 0.251032 | Val loss: 0.302186 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.02it/s]\n",
      "Epoch: 044 | Lr: 0.00081450624999999987 |Train loss: 0.253792 | Val loss: 0.304823 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.11it/s]\n",
      "Epoch: 045 | Lr: 0.00081450624999999987 |Train loss: 0.250958 | Val loss: 0.292404 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.28it/s]\n",
      "Epoch: 046 | Lr: 0.00081450624999999987 |Train loss: 0.249672 | Val loss: 0.299260 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.55it/s]\n",
      "Epoch: 047 | Lr: 0.00081450624999999987 |Train loss: 0.251212 | Val loss: 0.299583 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.29it/s]\n",
      "Epoch: 048 | Lr: 0.00081450624999999987 |Train loss: 0.250045 | Val loss: 0.300063 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.62it/s]\n",
      "Epoch: 049 | Lr: 0.00081450624999999987 |Train loss: 0.251094 | Val loss: 0.298717 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.81it/s]\n",
      "Epoch: 050 | Lr: 0.00077378093749999979 |Train loss: 0.250138 | Val loss: 0.299895 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.04it/s]\n",
      "Epoch: 051 | Lr: 0.00077378093749999979 |Train loss: 0.250015 | Val loss: 0.296197 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 24.00it/s]\n",
      "Epoch: 052 | Lr: 0.00077378093749999979 |Train loss: 0.249465 | Val loss: 0.294333 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.44it/s]\n",
      "Epoch: 053 | Lr: 0.00077378093749999979 |Train loss: 0.249413 | Val loss: 0.298706 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.11it/s]\n",
      "Epoch: 054 | Lr: 0.00077378093749999979 |Train loss: 0.250888 | Val loss: 0.295407 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.87it/s]\n",
      "Epoch: 055 | Lr: 0.00077378093749999979 |Train loss: 0.249252 | Val loss: 0.291469 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.99it/s]\n",
      "Epoch: 056 | Lr: 0.00077378093749999979 |Train loss: 0.248777 | Val loss: 0.297547 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.87it/s]\n",
      "Epoch: 057 | Lr: 0.00077378093749999979 |Train loss: 0.249230 | Val loss: 0.292861 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.23it/s]\n",
      "Epoch: 058 | Lr: 0.00077378093749999979 |Train loss: 0.249723 | Val loss: 0.289822 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:27<00:00, 26.93it/s]\n",
      "Epoch: 059 | Lr: 0.00077378093749999979 |Train loss: 0.248308 | Val loss: 0.292536 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.03it/s]\n",
      "Epoch: 060 | Lr: 0.00073509189062499975 |Train loss: 0.248629 | Val loss: 0.294681 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.70it/s]\n",
      "Epoch: 061 | Lr: 0.00073509189062499975 |Train loss: 0.247507 | Val loss: 0.288413 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.76it/s]\n",
      "Epoch: 062 | Lr: 0.00073509189062499975 |Train loss: 0.246943 | Val loss: 0.378733 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.67it/s]\n",
      "Epoch: 063 | Lr: 0.00073509189062499975 |Train loss: 0.254141 | Val loss: 0.287733 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.80it/s]\n",
      "Epoch: 064 | Lr: 0.00073509189062499975 |Train loss: 0.247113 | Val loss: 0.292203 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.95it/s]\n",
      "Epoch: 065 | Lr: 0.00073509189062499975 |Train loss: 0.248155 | Val loss: 0.293963 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.95it/s]\n",
      "Epoch: 066 | Lr: 0.00073509189062499975 |Train loss: 0.247754 | Val loss: 0.290848 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 22.92it/s]\n",
      "Epoch: 067 | Lr: 0.00073509189062499975 |Train loss: 0.247644 | Val loss: 0.293934 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 25.89it/s]\n",
      "Epoch: 068 | Lr: 0.00073509189062499975 |Train loss: 0.246184 | Val loss: 0.289802 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 23.27it/s]\n",
      "Epoch: 069 | Lr: 0.00073509189062499975 |Train loss: 0.247834 | Val loss: 0.290110 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.48it/s]\n",
      "Epoch: 070 | Lr: 0.00069833729609374972 |Train loss: 0.247546 | Val loss: 0.295741 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.64it/s]\n",
      "Epoch: 071 | Lr: 0.00069833729609374972 |Train loss: 0.246642 | Val loss: 0.288610 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 24.05it/s]\n",
      "Epoch: 072 | Lr: 0.00069833729609374972 |Train loss: 0.246565 | Val loss: 0.287297 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.33it/s]\n",
      "Epoch: 073 | Lr: 0.00069833729609374972 |Train loss: 0.246016 | Val loss: 0.289225 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.72it/s]\n",
      "Epoch: 074 | Lr: 0.00069833729609374972 |Train loss: 0.245943 | Val loss: 0.287694 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.79it/s]\n",
      "Epoch: 075 | Lr: 0.00069833729609374972 |Train loss: 0.245541 | Val loss: 0.292196 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.62it/s]\n",
      "Epoch: 076 | Lr: 0.00069833729609374972 |Train loss: 0.246127 | Val loss: 0.290634 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.59it/s]\n",
      "Epoch: 077 | Lr: 0.00069833729609374972 |Train loss: 0.245605 | Val loss: 0.288816 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.58it/s]\n",
      "Epoch: 078 | Lr: 0.00069833729609374972 |Train loss: 0.246721 | Val loss: 0.294357 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.61it/s]\n",
      "Epoch: 079 | Lr: 0.00069833729609374972 |Train loss: 0.246452 | Val loss: 0.287547 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.88it/s]\n",
      "Epoch: 080 | Lr: 0.00066342043128906215 |Train loss: 0.245777 | Val loss: 0.286590 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 23.41it/s]\n",
      "Epoch: 081 | Lr: 0.00066342043128906215 |Train loss: 0.243793 | Val loss: 0.284200 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 23.07it/s]\n",
      "Epoch: 082 | Lr: 0.00066342043128906215 |Train loss: 0.244686 | Val loss: 0.290466 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.37it/s]\n",
      "Epoch: 083 | Lr: 0.00066342043128906215 |Train loss: 0.244787 | Val loss: 0.286944 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 24.17it/s]\n",
      "Epoch: 084 | Lr: 0.00066342043128906215 |Train loss: 0.245184 | Val loss: 0.286587 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.79it/s]\n",
      "Epoch: 085 | Lr: 0.00066342043128906215 |Train loss: 0.245096 | Val loss: 0.287948 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.57it/s]\n",
      "Epoch: 086 | Lr: 0.00066342043128906215 |Train loss: 0.245215 | Val loss: 0.285892 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.70it/s]\n",
      "Epoch: 087 | Lr: 0.00066342043128906215 |Train loss: 0.244735 | Val loss: 0.286212 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.99it/s]\n",
      "Epoch: 088 | Lr: 0.00066342043128906215 |Train loss: 0.244523 | Val loss: 0.284890 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.02it/s]\n",
      "Epoch: 089 | Lr: 0.00066342043128906215 |Train loss: 0.244496 | Val loss: 0.284297 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.48it/s]\n",
      "Epoch: 090 | Lr: 0.00063024940972460899 |Train loss: 0.243519 | Val loss: 0.286859 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.30it/s]\n",
      "Epoch: 091 | Lr: 0.00063024940972460899 |Train loss: 0.244776 | Val loss: 0.283238 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.13it/s]\n",
      "Epoch: 092 | Lr: 0.00063024940972460899 |Train loss: 0.242359 | Val loss: 0.282734 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.65it/s]\n",
      "Epoch: 093 | Lr: 0.00063024940972460899 |Train loss: 0.242853 | Val loss: 0.282332 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.85it/s]\n",
      "Epoch: 094 | Lr: 0.00063024940972460899 |Train loss: 0.243663 | Val loss: 0.293484 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.55it/s]\n",
      "Epoch: 095 | Lr: 0.00063024940972460899 |Train loss: 0.245374 | Val loss: 0.279700 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.72it/s]\n",
      "Epoch: 096 | Lr: 0.00063024940972460899 |Train loss: 0.242162 | Val loss: 0.281776 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.48it/s]\n",
      "Epoch: 097 | Lr: 0.00063024940972460899 |Train loss: 0.242712 | Val loss: 0.284407 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.72it/s]\n",
      "Epoch: 098 | Lr: 0.00063024940972460899 |Train loss: 0.243852 | Val loss: 0.286369 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.52it/s]\n",
      "Epoch: 099 | Lr: 0.00063024940972460899 |Train loss: 0.242767 | Val loss: 0.284087 | GPU occupy: 879.232512 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.13it/s]\n",
      "Epoch: 100 | Lr: 0.00059873693923837847 |Train loss: 0.243268 | Val loss: 0.284429 | GPU occupy: 879.232512 MiB\n",
      "Dataset metr-la | Test loss 0.285951 | MAE 5.414411 | RMSE 9.773450 | WMAPE 0.10658528\n"
     ]
    }
   ],
   "source": [
    "#4: 1 middle layer + first order\n",
    "\n",
    "!python main.py --stblock_num=2 --Kt=2 --Ks=2 --middle_layer=True --epoch=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d8dfdda-60a1-4d93-9968-bb428023ecea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configs: Namespace(Ks=3, Kt=2, act_func='glu', batch_size=32, dataset='metr-la', droprate=0.5, enable_bias=True, enable_cuda=True, epochs=100, gamma=0.95, graph_conv_type='cheb_graph_conv', gso_type='sym_norm_lap', lr=0.001, middle_layer=True, n_his=12, n_pred=3, opt='adam', patience=30, seed=42, stblock_num=2, step_size=10, time_intvl=5, weight_decay_rate=0.0005)\n",
      "Blocks:  [[1], [64, 16, 64], [64, 16, 64], [128, 128], [1]]\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00822724]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "Use iteration 19 instead with accuracy \n",
      "0.007941234546600588.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00794123]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "Modules:  [STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(1, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), MiddleBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 256, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (tc1_ln): LayerNorm((207, 128), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")]\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.32it/s]\n",
      "Epoch: 001 | Lr: 0.00100000000000000002 |Train loss: 0.354510 | Val loss: 0.429226 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.77it/s]\n",
      "Epoch: 002 | Lr: 0.00100000000000000002 |Train loss: 0.294443 | Val loss: 0.392565 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.40it/s]\n",
      "Epoch: 003 | Lr: 0.00100000000000000002 |Train loss: 0.292956 | Val loss: 0.370435 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.59it/s]\n",
      "Epoch: 004 | Lr: 0.00100000000000000002 |Train loss: 0.398606 | Val loss: 0.353352 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.58it/s]\n",
      "Epoch: 005 | Lr: 0.00100000000000000002 |Train loss: 0.272514 | Val loss: 0.345500 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.01it/s]\n",
      "Epoch: 006 | Lr: 0.00100000000000000002 |Train loss: 0.271437 | Val loss: 0.346624 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.86it/s]\n",
      "Epoch: 007 | Lr: 0.00100000000000000002 |Train loss: 0.268610 | Val loss: 0.333902 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.36it/s]\n",
      "Epoch: 008 | Lr: 0.00100000000000000002 |Train loss: 0.267803 | Val loss: 0.330520 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.42it/s]\n",
      "Epoch: 009 | Lr: 0.00100000000000000002 |Train loss: 0.266124 | Val loss: 0.323959 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.47it/s]\n",
      "Epoch: 010 | Lr: 0.00095000000000000000 |Train loss: 0.263156 | Val loss: 0.324174 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.36it/s]\n",
      "Epoch: 011 | Lr: 0.00095000000000000000 |Train loss: 0.263171 | Val loss: 0.323370 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.63it/s]\n",
      "Epoch: 012 | Lr: 0.00095000000000000000 |Train loss: 0.262186 | Val loss: 0.316660 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.57it/s]\n",
      "Epoch: 013 | Lr: 0.00095000000000000000 |Train loss: 0.261876 | Val loss: 0.310067 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:27<00:00, 27.44it/s]\n",
      "Epoch: 014 | Lr: 0.00095000000000000000 |Train loss: 0.258220 | Val loss: 0.315329 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.11it/s]\n",
      "Epoch: 015 | Lr: 0.00095000000000000000 |Train loss: 0.259622 | Val loss: 0.316202 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:27<00:00, 27.49it/s]\n",
      "Epoch: 016 | Lr: 0.00095000000000000000 |Train loss: 0.260493 | Val loss: 0.308082 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.62it/s]\n",
      "Epoch: 017 | Lr: 0.00095000000000000000 |Train loss: 0.260685 | Val loss: 0.313269 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.33it/s]\n",
      "Epoch: 018 | Lr: 0.00095000000000000000 |Train loss: 0.257510 | Val loss: 0.316660 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.50it/s]\n",
      "Epoch: 019 | Lr: 0.00095000000000000000 |Train loss: 0.259741 | Val loss: 0.309669 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.77it/s]\n",
      "Epoch: 020 | Lr: 0.00090249999999999998 |Train loss: 0.257474 | Val loss: 0.310454 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.48it/s]\n",
      "Epoch: 021 | Lr: 0.00090249999999999998 |Train loss: 0.255047 | Val loss: 0.305852 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.84it/s]\n",
      "Epoch: 022 | Lr: 0.00090249999999999998 |Train loss: 0.255657 | Val loss: 0.306306 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:33<00:00, 22.60it/s]\n",
      "Epoch: 023 | Lr: 0.00090249999999999998 |Train loss: 0.255454 | Val loss: 0.307606 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.06it/s]\n",
      "Epoch: 024 | Lr: 0.00090249999999999998 |Train loss: 0.254706 | Val loss: 0.308246 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.10it/s]\n",
      "Epoch: 025 | Lr: 0.00090249999999999998 |Train loss: 0.253927 | Val loss: 0.307464 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.27it/s]\n",
      "Epoch: 026 | Lr: 0.00090249999999999998 |Train loss: 0.256131 | Val loss: 0.309693 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.54it/s]\n",
      "Epoch: 027 | Lr: 0.00090249999999999998 |Train loss: 0.255656 | Val loss: 0.300637 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.13it/s]\n",
      "Epoch: 028 | Lr: 0.00090249999999999998 |Train loss: 0.252587 | Val loss: 0.307494 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.63it/s]\n",
      "Epoch: 029 | Lr: 0.00090249999999999998 |Train loss: 0.255247 | Val loss: 0.303255 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.23it/s]\n",
      "Epoch: 030 | Lr: 0.00085737499999999996 |Train loss: 0.252778 | Val loss: 0.299751 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.63it/s]\n",
      "Epoch: 031 | Lr: 0.00085737499999999996 |Train loss: 0.251811 | Val loss: 0.298926 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.83it/s]\n",
      "Epoch: 032 | Lr: 0.00085737499999999996 |Train loss: 0.251316 | Val loss: 0.301156 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 23.34it/s]\n",
      "Epoch: 033 | Lr: 0.00085737499999999996 |Train loss: 0.251426 | Val loss: 0.298012 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.45it/s]\n",
      "Epoch: 034 | Lr: 0.00085737499999999996 |Train loss: 0.250206 | Val loss: 0.300855 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:27<00:00, 27.09it/s]\n",
      "Epoch: 035 | Lr: 0.00085737499999999996 |Train loss: 0.250358 | Val loss: 0.341683 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.59it/s]\n",
      "Epoch: 036 | Lr: 0.00085737499999999996 |Train loss: 0.255815 | Val loss: 0.302626 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.95it/s]\n",
      "Epoch: 037 | Lr: 0.00085737499999999996 |Train loss: 0.251126 | Val loss: 0.301562 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:27<00:00, 26.85it/s]\n",
      "Epoch: 038 | Lr: 0.00085737499999999996 |Train loss: 0.250087 | Val loss: 0.299784 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.44it/s]\n",
      "Epoch: 039 | Lr: 0.00085737499999999996 |Train loss: 0.249569 | Val loss: 0.299654 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 23.22it/s]\n",
      "Epoch: 040 | Lr: 0.00081450624999999987 |Train loss: 0.249871 | Val loss: 0.300286 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.74it/s]\n",
      "Epoch: 041 | Lr: 0.00081450624999999987 |Train loss: 0.248794 | Val loss: 0.297078 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.29it/s]\n",
      "Epoch: 042 | Lr: 0.00081450624999999987 |Train loss: 0.248785 | Val loss: 0.329050 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.85it/s]\n",
      "Epoch: 043 | Lr: 0.00081450624999999987 |Train loss: 0.251908 | Val loss: 0.299075 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:27<00:00, 27.40it/s]\n",
      "Epoch: 044 | Lr: 0.00081450624999999987 |Train loss: 0.248368 | Val loss: 0.301976 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.41it/s]\n",
      "Epoch: 045 | Lr: 0.00081450624999999987 |Train loss: 0.248426 | Val loss: 0.298431 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.30it/s]\n",
      "Epoch: 046 | Lr: 0.00081450624999999987 |Train loss: 0.247727 | Val loss: 0.293935 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.84it/s]\n",
      "Epoch: 047 | Lr: 0.00081450624999999987 |Train loss: 0.248167 | Val loss: 0.299731 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.61it/s]\n",
      "Epoch: 048 | Lr: 0.00081450624999999987 |Train loss: 0.248726 | Val loss: 0.295161 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.70it/s]\n",
      "Epoch: 049 | Lr: 0.00081450624999999987 |Train loss: 0.248597 | Val loss: 0.298297 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.58it/s]\n",
      "Epoch: 050 | Lr: 0.00077378093749999979 |Train loss: 0.247549 | Val loss: 0.297371 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.65it/s]\n",
      "Epoch: 051 | Lr: 0.00077378093749999979 |Train loss: 0.248661 | Val loss: 0.290625 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 25.95it/s]\n",
      "Epoch: 052 | Lr: 0.00077378093749999979 |Train loss: 0.246655 | Val loss: 0.291158 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:27<00:00, 26.87it/s]\n",
      "Epoch: 053 | Lr: 0.00077378093749999979 |Train loss: 0.247012 | Val loss: 0.295412 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.90it/s]\n",
      "Epoch: 054 | Lr: 0.00077378093749999979 |Train loss: 0.247185 | Val loss: 0.294579 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.71it/s]\n",
      "Epoch: 055 | Lr: 0.00077378093749999979 |Train loss: 0.247411 | Val loss: 0.294882 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.12it/s]\n",
      "Epoch: 056 | Lr: 0.00077378093749999979 |Train loss: 0.247431 | Val loss: 0.292251 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 25.88it/s]\n",
      "Epoch: 057 | Lr: 0.00077378093749999979 |Train loss: 0.247679 | Val loss: 0.292149 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.62it/s]\n",
      "Epoch: 058 | Lr: 0.00077378093749999979 |Train loss: 0.245277 | Val loss: 0.291814 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.29it/s]\n",
      "Epoch: 059 | Lr: 0.00077378093749999979 |Train loss: 0.247470 | Val loss: 0.292199 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:27<00:00, 26.91it/s]\n",
      "Epoch: 060 | Lr: 0.00073509189062499975 |Train loss: 0.246642 | Val loss: 0.292200 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:27<00:00, 27.05it/s]\n",
      "Epoch: 061 | Lr: 0.00073509189062499975 |Train loss: 0.246166 | Val loss: 0.288270 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.50it/s]\n",
      "Epoch: 062 | Lr: 0.00073509189062499975 |Train loss: 0.244709 | Val loss: 0.291254 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.31it/s]\n",
      "Epoch: 063 | Lr: 0.00073509189062499975 |Train loss: 0.246260 | Val loss: 0.294381 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.94it/s]\n",
      "Epoch: 064 | Lr: 0.00073509189062499975 |Train loss: 0.245620 | Val loss: 0.289952 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.30it/s]\n",
      "Epoch: 065 | Lr: 0.00073509189062499975 |Train loss: 0.245705 | Val loss: 0.286774 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.76it/s]\n",
      "Epoch: 066 | Lr: 0.00073509189062499975 |Train loss: 0.244484 | Val loss: 0.289726 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.55it/s]\n",
      "Epoch: 067 | Lr: 0.00073509189062499975 |Train loss: 0.245564 | Val loss: 0.291927 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.31it/s]\n",
      "Epoch: 068 | Lr: 0.00073509189062499975 |Train loss: 0.245698 | Val loss: 0.289508 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.15it/s]\n",
      "Epoch: 069 | Lr: 0.00073509189062499975 |Train loss: 0.244584 | Val loss: 0.291587 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 25.99it/s]\n",
      "Epoch: 070 | Lr: 0.00069833729609374972 |Train loss: 0.246321 | Val loss: 0.293214 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.17it/s]\n",
      "Epoch: 071 | Lr: 0.00069833729609374972 |Train loss: 0.244397 | Val loss: 0.285250 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.58it/s]\n",
      "Epoch: 072 | Lr: 0.00069833729609374972 |Train loss: 0.245314 | Val loss: 0.286702 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.50it/s]\n",
      "Epoch: 073 | Lr: 0.00069833729609374972 |Train loss: 0.243475 | Val loss: 0.287132 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.13it/s]\n",
      "Epoch: 074 | Lr: 0.00069833729609374972 |Train loss: 0.244045 | Val loss: 0.288657 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.54it/s]\n",
      "Epoch: 075 | Lr: 0.00069833729609374972 |Train loss: 0.244610 | Val loss: 0.284251 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.51it/s]\n",
      "Epoch: 076 | Lr: 0.00069833729609374972 |Train loss: 0.243878 | Val loss: 0.286959 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.11it/s]\n",
      "Epoch: 077 | Lr: 0.00069833729609374972 |Train loss: 0.244379 | Val loss: 0.290013 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 25.95it/s]\n",
      "Epoch: 078 | Lr: 0.00069833729609374972 |Train loss: 0.244351 | Val loss: 0.289235 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 22.91it/s]\n",
      "Epoch: 079 | Lr: 0.00069833729609374972 |Train loss: 0.245156 | Val loss: 0.285457 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.08it/s]\n",
      "Epoch: 080 | Lr: 0.00066342043128906215 |Train loss: 0.243774 | Val loss: 0.286810 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 22.97it/s]\n",
      "Epoch: 081 | Lr: 0.00066342043128906215 |Train loss: 0.242587 | Val loss: 0.284518 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.99it/s]\n",
      "Epoch: 082 | Lr: 0.00066342043128906215 |Train loss: 0.243929 | Val loss: 0.284914 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.54it/s]\n",
      "Epoch: 083 | Lr: 0.00066342043128906215 |Train loss: 0.243394 | Val loss: 0.285797 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.43it/s]\n",
      "Epoch: 084 | Lr: 0.00066342043128906215 |Train loss: 0.244049 | Val loss: 0.283692 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.62it/s]\n",
      "Epoch: 085 | Lr: 0.00066342043128906215 |Train loss: 0.242497 | Val loss: 0.285194 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.76it/s]\n",
      "Epoch: 086 | Lr: 0.00066342043128906215 |Train loss: 0.243072 | Val loss: 0.283650 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.52it/s]\n",
      "Epoch: 087 | Lr: 0.00066342043128906215 |Train loss: 0.243035 | Val loss: 0.286516 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.47it/s]\n",
      "Epoch: 088 | Lr: 0.00066342043128906215 |Train loss: 0.243260 | Val loss: 0.283896 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.29it/s]\n",
      "Epoch: 089 | Lr: 0.00066342043128906215 |Train loss: 0.242940 | Val loss: 0.284202 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 24.04it/s]\n",
      "Epoch: 090 | Lr: 0.00063024940972460899 |Train loss: 0.242455 | Val loss: 0.284288 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.49it/s]\n",
      "Epoch: 091 | Lr: 0.00063024940972460899 |Train loss: 0.242347 | Val loss: 0.283217 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 24.19it/s]\n",
      "Epoch: 092 | Lr: 0.00063024940972460899 |Train loss: 0.242367 | Val loss: 0.282476 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:27<00:00, 26.96it/s]\n",
      "Epoch: 093 | Lr: 0.00063024940972460899 |Train loss: 0.241469 | Val loss: 0.283962 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.16it/s]\n",
      "Epoch: 094 | Lr: 0.00063024940972460899 |Train loss: 0.242226 | Val loss: 0.281739 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.26it/s]\n",
      "Epoch: 095 | Lr: 0.00063024940972460899 |Train loss: 0.241446 | Val loss: 0.281077 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.03it/s]\n",
      "Epoch: 096 | Lr: 0.00063024940972460899 |Train loss: 0.241064 | Val loss: 0.289281 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.66it/s]\n",
      "Epoch: 097 | Lr: 0.00063024940972460899 |Train loss: 0.241882 | Val loss: 0.284299 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.68it/s]\n",
      "Epoch: 098 | Lr: 0.00063024940972460899 |Train loss: 0.242830 | Val loss: 0.291905 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.69it/s]\n",
      "Epoch: 099 | Lr: 0.00063024940972460899 |Train loss: 0.242424 | Val loss: 0.280246 | GPU occupy: 889.995776 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.47it/s]\n",
      "Epoch: 100 | Lr: 0.00059873693923837847 |Train loss: 0.241496 | Val loss: 0.280791 | GPU occupy: 889.995776 MiB\n",
      "Dataset metr-la | Test loss 0.278472 | MAE 5.273021 | RMSE 9.644845 | WMAPE 0.10380194\n"
     ]
    }
   ],
   "source": [
    "#5: 1 middle layer + second order\n",
    "\n",
    "!python main.py --stblock_num=2 --Kt=2 --Ks=3 --middle_layer=True --epoch=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90f96ece-7c60-409c-9c39-8a255046ef6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configs: Namespace(Ks=4, Kt=2, act_func='glu', batch_size=32, dataset='metr-la', droprate=0.5, enable_bias=True, enable_cuda=True, epochs=100, gamma=0.95, graph_conv_type='cheb_graph_conv', gso_type='sym_norm_lap', lr=0.001, middle_layer=True, n_his=12, n_pred=3, opt='adam', patience=30, seed=42, stblock_num=2, step_size=10, time_intvl=5, weight_decay_rate=0.0005)\n",
      "Blocks:  [[1], [64, 16, 64], [64, 16, 64], [128, 128], [1]]\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00822724]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "Use iteration 19 instead with accuracy \n",
      "0.007941234546600588.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00794123]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "Modules:  [STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(1, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), MiddleBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 256, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (tc1_ln): LayerNorm((207, 128), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")]\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.64it/s]\n",
      "Epoch: 001 | Lr: 0.00100000000000000002 |Train loss: 0.375132 | Val loss: 0.388112 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.40it/s]\n",
      "Epoch: 002 | Lr: 0.00100000000000000002 |Train loss: 0.287234 | Val loss: 0.365838 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.11it/s]\n",
      "Epoch: 003 | Lr: 0.00100000000000000002 |Train loss: 0.292018 | Val loss: 0.353213 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.85it/s]\n",
      "Epoch: 004 | Lr: 0.00100000000000000002 |Train loss: 0.278946 | Val loss: 0.363065 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.57it/s]\n",
      "Epoch: 005 | Lr: 0.00100000000000000002 |Train loss: 0.276777 | Val loss: 0.355159 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.90it/s]\n",
      "Epoch: 006 | Lr: 0.00100000000000000002 |Train loss: 0.336617 | Val loss: 0.311269 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 24.03it/s]\n",
      "Epoch: 007 | Lr: 0.00100000000000000002 |Train loss: 0.262622 | Val loss: 0.324482 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 23.33it/s]\n",
      "Epoch: 008 | Lr: 0.00100000000000000002 |Train loss: 0.266799 | Val loss: 0.352131 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.76it/s]\n",
      "Epoch: 009 | Lr: 0.00100000000000000002 |Train loss: 0.269166 | Val loss: 0.335091 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.80it/s]\n",
      "Epoch: 010 | Lr: 0.00095000000000000000 |Train loss: 0.264475 | Val loss: 0.332037 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 23.42it/s]\n",
      "Epoch: 011 | Lr: 0.00095000000000000000 |Train loss: 0.262810 | Val loss: 0.326522 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.66it/s]\n",
      "Epoch: 012 | Lr: 0.00095000000000000000 |Train loss: 0.261991 | Val loss: 0.326017 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.06it/s]\n",
      "Epoch: 013 | Lr: 0.00095000000000000000 |Train loss: 0.263827 | Val loss: 0.324296 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 24.11it/s]\n",
      "Epoch: 014 | Lr: 0.00095000000000000000 |Train loss: 0.263024 | Val loss: 0.318039 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.64it/s]\n",
      "Epoch: 015 | Lr: 0.00095000000000000000 |Train loss: 0.259647 | Val loss: 0.322351 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.66it/s]\n",
      "Epoch: 016 | Lr: 0.00095000000000000000 |Train loss: 0.259839 | Val loss: 0.319377 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.17it/s]\n",
      "Epoch: 017 | Lr: 0.00095000000000000000 |Train loss: 0.259631 | Val loss: 0.320514 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.25it/s]\n",
      "Epoch: 018 | Lr: 0.00095000000000000000 |Train loss: 0.259429 | Val loss: 0.327369 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.06it/s]\n",
      "Epoch: 019 | Lr: 0.00095000000000000000 |Train loss: 0.259721 | Val loss: 0.310945 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.20it/s]\n",
      "Epoch: 020 | Lr: 0.00090249999999999998 |Train loss: 0.257119 | Val loss: 0.313977 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.26it/s]\n",
      "Epoch: 021 | Lr: 0.00090249999999999998 |Train loss: 0.255366 | Val loss: 0.311504 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.63it/s]\n",
      "Epoch: 022 | Lr: 0.00090249999999999998 |Train loss: 0.257521 | Val loss: 0.320613 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.81it/s]\n",
      "Epoch: 023 | Lr: 0.00090249999999999998 |Train loss: 0.256335 | Val loss: 0.307265 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.36it/s]\n",
      "Epoch: 024 | Lr: 0.00090249999999999998 |Train loss: 0.254216 | Val loss: 0.307864 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.15it/s]\n",
      "Epoch: 025 | Lr: 0.00090249999999999998 |Train loss: 0.256523 | Val loss: 0.310798 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.81it/s]\n",
      "Epoch: 026 | Lr: 0.00090249999999999998 |Train loss: 0.254016 | Val loss: 0.306268 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.53it/s]\n",
      "Epoch: 027 | Lr: 0.00090249999999999998 |Train loss: 0.253453 | Val loss: 0.308374 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.37it/s]\n",
      "Epoch: 028 | Lr: 0.00090249999999999998 |Train loss: 0.254917 | Val loss: 0.309956 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:33<00:00, 22.57it/s]\n",
      "Epoch: 029 | Lr: 0.00090249999999999998 |Train loss: 0.254453 | Val loss: 0.306308 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.57it/s]\n",
      "Epoch: 030 | Lr: 0.00085737499999999996 |Train loss: 0.252982 | Val loss: 0.306302 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.41it/s]\n",
      "Epoch: 031 | Lr: 0.00085737499999999996 |Train loss: 0.251756 | Val loss: 0.307546 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.47it/s]\n",
      "Epoch: 032 | Lr: 0.00085737499999999996 |Train loss: 0.252822 | Val loss: 0.301327 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.34it/s]\n",
      "Epoch: 033 | Lr: 0.00085737499999999996 |Train loss: 0.251480 | Val loss: 0.303993 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.58it/s]\n",
      "Epoch: 034 | Lr: 0.00085737499999999996 |Train loss: 0.250147 | Val loss: 0.307604 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.62it/s]\n",
      "Epoch: 035 | Lr: 0.00085737499999999996 |Train loss: 0.253748 | Val loss: 0.312280 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.04it/s]\n",
      "Epoch: 036 | Lr: 0.00085737499999999996 |Train loss: 0.250836 | Val loss: 0.297047 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.17it/s]\n",
      "Epoch: 037 | Lr: 0.00085737499999999996 |Train loss: 0.250218 | Val loss: 0.305860 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.81it/s]\n",
      "Epoch: 038 | Lr: 0.00085737499999999996 |Train loss: 0.250056 | Val loss: 0.306649 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 22.88it/s]\n",
      "Epoch: 039 | Lr: 0.00085737499999999996 |Train loss: 0.255170 | Val loss: 0.315890 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.59it/s]\n",
      "Epoch: 040 | Lr: 0.00081450624999999987 |Train loss: 0.251527 | Val loss: 0.294416 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.79it/s]\n",
      "Epoch: 041 | Lr: 0.00081450624999999987 |Train loss: 0.249520 | Val loss: 0.296230 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.07it/s]\n",
      "Epoch: 042 | Lr: 0.00081450624999999987 |Train loss: 0.248958 | Val loss: 0.297929 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.44it/s]\n",
      "Epoch: 043 | Lr: 0.00081450624999999987 |Train loss: 0.250316 | Val loss: 0.300316 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.77it/s]\n",
      "Epoch: 044 | Lr: 0.00081450624999999987 |Train loss: 0.248750 | Val loss: 0.298098 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.84it/s]\n",
      "Epoch: 045 | Lr: 0.00081450624999999987 |Train loss: 0.249528 | Val loss: 0.304697 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.90it/s]\n",
      "Epoch: 046 | Lr: 0.00081450624999999987 |Train loss: 0.250997 | Val loss: 0.300859 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.54it/s]\n",
      "Epoch: 047 | Lr: 0.00081450624999999987 |Train loss: 0.250315 | Val loss: 0.294531 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.13it/s]\n",
      "Epoch: 048 | Lr: 0.00081450624999999987 |Train loss: 0.249187 | Val loss: 0.296529 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.02it/s]\n",
      "Epoch: 049 | Lr: 0.00081450624999999987 |Train loss: 0.249071 | Val loss: 0.295417 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.63it/s]\n",
      "Epoch: 050 | Lr: 0.00077378093749999979 |Train loss: 0.248093 | Val loss: 0.296057 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.75it/s]\n",
      "Epoch: 051 | Lr: 0.00077378093749999979 |Train loss: 0.248727 | Val loss: 0.294392 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.66it/s]\n",
      "Epoch: 052 | Lr: 0.00077378093749999979 |Train loss: 0.247480 | Val loss: 0.290507 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.12it/s]\n",
      "Epoch: 053 | Lr: 0.00077378093749999979 |Train loss: 0.247541 | Val loss: 0.300062 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.37it/s]\n",
      "Epoch: 054 | Lr: 0.00077378093749999979 |Train loss: 0.250644 | Val loss: 0.293551 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.89it/s]\n",
      "Epoch: 055 | Lr: 0.00077378093749999979 |Train loss: 0.247658 | Val loss: 0.289002 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.42it/s]\n",
      "Epoch: 056 | Lr: 0.00077378093749999979 |Train loss: 0.246826 | Val loss: 0.291635 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.44it/s]\n",
      "Epoch: 057 | Lr: 0.00077378093749999979 |Train loss: 0.246891 | Val loss: 0.294425 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.06it/s]\n",
      "Epoch: 058 | Lr: 0.00077378093749999979 |Train loss: 0.248289 | Val loss: 0.294675 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:32<00:00, 22.91it/s]\n",
      "Epoch: 059 | Lr: 0.00077378093749999979 |Train loss: 0.245839 | Val loss: 0.288933 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.03it/s]\n",
      "Epoch: 060 | Lr: 0.00073509189062499975 |Train loss: 0.247191 | Val loss: 0.293192 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.02it/s]\n",
      "Epoch: 061 | Lr: 0.00073509189062499975 |Train loss: 0.246105 | Val loss: 0.288107 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.89it/s]\n",
      "Epoch: 062 | Lr: 0.00073509189062499975 |Train loss: 0.246976 | Val loss: 0.295174 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.86it/s]\n",
      "Epoch: 063 | Lr: 0.00073509189062499975 |Train loss: 0.245538 | Val loss: 0.290440 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.22it/s]\n",
      "Epoch: 064 | Lr: 0.00073509189062499975 |Train loss: 0.246332 | Val loss: 0.299962 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.22it/s]\n",
      "Epoch: 065 | Lr: 0.00073509189062499975 |Train loss: 0.247330 | Val loss: 0.285194 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 24.10it/s]\n",
      "Epoch: 066 | Lr: 0.00073509189062499975 |Train loss: 0.245005 | Val loss: 0.284670 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 24.16it/s]\n",
      "Epoch: 067 | Lr: 0.00073509189062499975 |Train loss: 0.246111 | Val loss: 0.407360 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.97it/s]\n",
      "Epoch: 068 | Lr: 0.00073509189062499975 |Train loss: 0.245741 | Val loss: 0.285892 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.71it/s]\n",
      "Epoch: 069 | Lr: 0.00073509189062499975 |Train loss: 0.246231 | Val loss: 0.317389 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.24it/s]\n",
      "Epoch: 070 | Lr: 0.00069833729609374972 |Train loss: 0.246718 | Val loss: 0.284597 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.43it/s]\n",
      "Epoch: 071 | Lr: 0.00069833729609374972 |Train loss: 0.243388 | Val loss: 0.282710 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.56it/s]\n",
      "Epoch: 072 | Lr: 0.00069833729609374972 |Train loss: 0.244792 | Val loss: 0.284805 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 24.13it/s]\n",
      "Epoch: 073 | Lr: 0.00069833729609374972 |Train loss: 0.243018 | Val loss: 0.284641 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.67it/s]\n",
      "Epoch: 074 | Lr: 0.00069833729609374972 |Train loss: 0.243336 | Val loss: 0.288422 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.41it/s]\n",
      "Epoch: 075 | Lr: 0.00069833729609374972 |Train loss: 0.244157 | Val loss: 0.292059 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.01it/s]\n",
      "Epoch: 076 | Lr: 0.00069833729609374972 |Train loss: 0.246946 | Val loss: 0.296223 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.25it/s]\n",
      "Epoch: 077 | Lr: 0.00069833729609374972 |Train loss: 0.245428 | Val loss: 0.283614 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.99it/s]\n",
      "Epoch: 078 | Lr: 0.00069833729609374972 |Train loss: 0.243413 | Val loss: 0.282453 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.12it/s]\n",
      "Epoch: 079 | Lr: 0.00069833729609374972 |Train loss: 0.242369 | Val loss: 0.284048 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 24.11it/s]\n",
      "Epoch: 080 | Lr: 0.00066342043128906215 |Train loss: 0.243623 | Val loss: 0.294157 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.84it/s]\n",
      "Epoch: 081 | Lr: 0.00066342043128906215 |Train loss: 0.243734 | Val loss: 0.280643 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.44it/s]\n",
      "Epoch: 082 | Lr: 0.00066342043128906215 |Train loss: 0.243166 | Val loss: 0.284029 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.35it/s]\n",
      "Epoch: 083 | Lr: 0.00066342043128906215 |Train loss: 0.242576 | Val loss: 0.287067 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.50it/s]\n",
      "Epoch: 084 | Lr: 0.00066342043128906215 |Train loss: 0.242840 | Val loss: 0.283896 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.31it/s]\n",
      "Epoch: 085 | Lr: 0.00066342043128906215 |Train loss: 0.243352 | Val loss: 0.283071 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.76it/s]\n",
      "Epoch: 086 | Lr: 0.00066342043128906215 |Train loss: 0.241843 | Val loss: 0.281821 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.31it/s]\n",
      "Epoch: 087 | Lr: 0.00066342043128906215 |Train loss: 0.241803 | Val loss: 0.283141 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.43it/s]\n",
      "Epoch: 088 | Lr: 0.00066342043128906215 |Train loss: 0.243308 | Val loss: 0.284782 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.03it/s]\n",
      "Epoch: 089 | Lr: 0.00066342043128906215 |Train loss: 0.241277 | Val loss: 0.279155 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.37it/s]\n",
      "Epoch: 090 | Lr: 0.00063024940972460899 |Train loss: 0.242491 | Val loss: 0.281451 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.99it/s]\n",
      "Epoch: 091 | Lr: 0.00063024940972460899 |Train loss: 0.241842 | Val loss: 0.300757 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.33it/s]\n",
      "Epoch: 092 | Lr: 0.00063024940972460899 |Train loss: 0.245952 | Val loss: 0.284447 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.86it/s]\n",
      "Epoch: 093 | Lr: 0.00063024940972460899 |Train loss: 0.240734 | Val loss: 0.275724 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.75it/s]\n",
      "Epoch: 094 | Lr: 0.00063024940972460899 |Train loss: 0.240489 | Val loss: 0.276496 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.39it/s]\n",
      "Epoch: 095 | Lr: 0.00063024940972460899 |Train loss: 0.241020 | Val loss: 0.283808 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.60it/s]\n",
      "Epoch: 096 | Lr: 0.00063024940972460899 |Train loss: 0.240910 | Val loss: 0.279694 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:28<00:00, 26.19it/s]\n",
      "Epoch: 097 | Lr: 0.00063024940972460899 |Train loss: 0.242106 | Val loss: 0.284591 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:30<00:00, 24.43it/s]\n",
      "Epoch: 098 | Lr: 0.00063024940972460899 |Train loss: 0.242062 | Val loss: 0.280932 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:29<00:00, 25.55it/s]\n",
      "Epoch: 099 | Lr: 0.00063024940972460899 |Train loss: 0.241346 | Val loss: 0.279343 | GPU occupy: 897.713664 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:31<00:00, 23.81it/s]\n",
      "Epoch: 100 | Lr: 0.00059873693923837847 |Train loss: 0.240722 | Val loss: 0.278122 | GPU occupy: 897.713664 MiB\n",
      "Dataset metr-la | Test loss 0.275585 | MAE 5.273232 | RMSE 9.599163 | WMAPE 0.10380609\n"
     ]
    }
   ],
   "source": [
    "#6: 1 middle layer + third order\n",
    "\n",
    "!python main.py --stblock_num=2 --Kt=2 --Ks=4 --middle_layer=True --epoch=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efc803c1-80a8-4784-8bc0-21d27b17c58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configs: Namespace(Ks=2, Kt=2, act_func='glu', batch_size=32, dataset='metr-la', droprate=0.5, enable_bias=True, enable_cuda=True, epochs=100, gamma=0.95, graph_conv_type='cheb_graph_conv', gso_type='sym_norm_lap', lr=0.001, middle_layer=True, n_his=12, n_pred=3, opt='adam', patience=30, seed=42, stblock_num=3, step_size=10, time_intvl=5, weight_decay_rate=0.0005)\n",
      "Blocks:  [[1], [64, 16, 64], [64, 16, 64], [64, 16, 64], [128, 128], [1]]\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00822724]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "Use iteration 19 instead with accuracy \n",
      "0.007941234546600588.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00794123]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "Modules:  [STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(1, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), MiddleBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 256, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (tc1_ln): LayerNorm((207, 128), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), MiddleBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 256, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (tc1_ln): LayerNorm((207, 128), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")]\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.08it/s]\n",
      "Epoch: 001 | Lr: 0.00100000000000000002 |Train loss: 0.459113 | Val loss: 0.409648 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.19it/s]\n",
      "Epoch: 002 | Lr: 0.00100000000000000002 |Train loss: 0.325074 | Val loss: 0.414665 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.26it/s]\n",
      "Epoch: 003 | Lr: 0.00100000000000000002 |Train loss: 0.313550 | Val loss: 0.372719 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:44<00:00, 16.98it/s]\n",
      "Epoch: 004 | Lr: 0.00100000000000000002 |Train loss: 0.299959 | Val loss: 0.372877 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.72it/s]\n",
      "Epoch: 005 | Lr: 0.00100000000000000002 |Train loss: 0.301122 | Val loss: 0.358869 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.29it/s]\n",
      "Epoch: 006 | Lr: 0.00100000000000000002 |Train loss: 0.297616 | Val loss: 0.346290 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.86it/s]\n",
      "Epoch: 007 | Lr: 0.00100000000000000002 |Train loss: 0.287114 | Val loss: 0.348886 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:44<00:00, 16.74it/s]\n",
      "Epoch: 008 | Lr: 0.00100000000000000002 |Train loss: 0.282614 | Val loss: 0.340012 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.41it/s]\n",
      "Epoch: 009 | Lr: 0.00100000000000000002 |Train loss: 0.281371 | Val loss: 0.339365 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 15.99it/s]\n",
      "Epoch: 010 | Lr: 0.00095000000000000000 |Train loss: 0.279878 | Val loss: 0.335667 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:44<00:00, 16.68it/s]\n",
      "Epoch: 011 | Lr: 0.00095000000000000000 |Train loss: 0.277073 | Val loss: 0.333448 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 15.96it/s]\n",
      "Epoch: 012 | Lr: 0.00095000000000000000 |Train loss: 0.276110 | Val loss: 0.330721 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.02it/s]\n",
      "Epoch: 013 | Lr: 0.00095000000000000000 |Train loss: 0.272186 | Val loss: 0.334936 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 15.99it/s]\n",
      "Epoch: 014 | Lr: 0.00095000000000000000 |Train loss: 0.275937 | Val loss: 0.330492 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.86it/s]\n",
      "Epoch: 015 | Lr: 0.00095000000000000000 |Train loss: 0.269545 | Val loss: 0.328579 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.56it/s]\n",
      "Epoch: 016 | Lr: 0.00095000000000000000 |Train loss: 0.271021 | Val loss: 0.321426 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.39it/s]\n",
      "Epoch: 017 | Lr: 0.00095000000000000000 |Train loss: 0.269380 | Val loss: 0.326113 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.33it/s]\n",
      "Epoch: 018 | Lr: 0.00095000000000000000 |Train loss: 0.269746 | Val loss: 0.322157 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.67it/s]\n",
      "Epoch: 019 | Lr: 0.00095000000000000000 |Train loss: 0.269082 | Val loss: 0.327477 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.23it/s]\n",
      "Epoch: 020 | Lr: 0.00090249999999999998 |Train loss: 0.269472 | Val loss: 0.318947 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.01it/s]\n",
      "Epoch: 021 | Lr: 0.00090249999999999998 |Train loss: 0.270270 | Val loss: 0.320910 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 15.96it/s]\n",
      "Epoch: 022 | Lr: 0.00090249999999999998 |Train loss: 0.267791 | Val loss: 0.323146 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.57it/s]\n",
      "Epoch: 023 | Lr: 0.00090249999999999998 |Train loss: 0.265930 | Val loss: 0.318406 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.57it/s]\n",
      "Epoch: 024 | Lr: 0.00090249999999999998 |Train loss: 0.267415 | Val loss: 0.316517 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:43<00:00, 17.30it/s]\n",
      "Epoch: 025 | Lr: 0.00090249999999999998 |Train loss: 0.267260 | Val loss: 0.320432 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.39it/s]\n",
      "Epoch: 026 | Lr: 0.00090249999999999998 |Train loss: 0.273676 | Val loss: 0.312219 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.16it/s]\n",
      "Epoch: 027 | Lr: 0.00090249999999999998 |Train loss: 0.264151 | Val loss: 0.313857 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.03it/s]\n",
      "Epoch: 028 | Lr: 0.00090249999999999998 |Train loss: 0.263699 | Val loss: 0.316725 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.58it/s]\n",
      "Epoch: 029 | Lr: 0.00090249999999999998 |Train loss: 0.267165 | Val loss: 0.316882 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.33it/s]\n",
      "Epoch: 030 | Lr: 0.00085737499999999996 |Train loss: 0.273010 | Val loss: 0.315367 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:44<00:00, 16.84it/s]\n",
      "Epoch: 031 | Lr: 0.00085737499999999996 |Train loss: 0.264149 | Val loss: 0.313175 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.64it/s]\n",
      "Epoch: 032 | Lr: 0.00085737499999999996 |Train loss: 0.265046 | Val loss: 0.312578 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:44<00:00, 16.71it/s]\n",
      "Epoch: 033 | Lr: 0.00085737499999999996 |Train loss: 0.267653 | Val loss: 0.308617 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:44<00:00, 16.70it/s]\n",
      "Epoch: 034 | Lr: 0.00085737499999999996 |Train loss: 0.262185 | Val loss: 0.310001 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:43<00:00, 17.21it/s]\n",
      "Epoch: 035 | Lr: 0.00085737499999999996 |Train loss: 0.263836 | Val loss: 0.314933 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.46it/s]\n",
      "Epoch: 036 | Lr: 0.00085737499999999996 |Train loss: 0.265622 | Val loss: 0.304273 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.89it/s]\n",
      "Epoch: 037 | Lr: 0.00085737499999999996 |Train loss: 0.265125 | Val loss: 0.311142 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.82it/s]\n",
      "Epoch: 038 | Lr: 0.00085737499999999996 |Train loss: 0.262597 | Val loss: 0.314898 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.72it/s]\n",
      "Epoch: 039 | Lr: 0.00085737499999999996 |Train loss: 0.263914 | Val loss: 0.308542 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.53it/s]\n",
      "Epoch: 040 | Lr: 0.00081450624999999987 |Train loss: 0.264291 | Val loss: 0.315872 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.45it/s]\n",
      "Epoch: 041 | Lr: 0.00081450624999999987 |Train loss: 0.262537 | Val loss: 0.303851 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.84it/s]\n",
      "Epoch: 042 | Lr: 0.00081450624999999987 |Train loss: 0.262019 | Val loss: 0.306577 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.04it/s]\n",
      "Epoch: 043 | Lr: 0.00081450624999999987 |Train loss: 0.260990 | Val loss: 0.308151 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.12it/s]\n",
      "Epoch: 044 | Lr: 0.00081450624999999987 |Train loss: 0.262659 | Val loss: 0.309022 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.89it/s]\n",
      "Epoch: 045 | Lr: 0.00081450624999999987 |Train loss: 0.261144 | Val loss: 0.304637 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.56it/s]\n",
      "Epoch: 046 | Lr: 0.00081450624999999987 |Train loss: 0.261027 | Val loss: 0.305989 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.15it/s]\n",
      "Epoch: 047 | Lr: 0.00081450624999999987 |Train loss: 0.260672 | Val loss: 0.306544 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.85it/s]\n",
      "Epoch: 048 | Lr: 0.00081450624999999987 |Train loss: 0.262009 | Val loss: 0.301673 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.47it/s]\n",
      "Epoch: 049 | Lr: 0.00081450624999999987 |Train loss: 0.261158 | Val loss: 0.301672 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.60it/s]\n",
      "Epoch: 050 | Lr: 0.00077378093749999979 |Train loss: 0.259620 | Val loss: 0.305600 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.18it/s]\n",
      "Epoch: 051 | Lr: 0.00077378093749999979 |Train loss: 0.259306 | Val loss: 0.297850 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.32it/s]\n",
      "Epoch: 052 | Lr: 0.00077378093749999979 |Train loss: 0.259679 | Val loss: 0.298374 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.63it/s]\n",
      "Epoch: 053 | Lr: 0.00077378093749999979 |Train loss: 0.258143 | Val loss: 0.298431 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 15.96it/s]\n",
      "Epoch: 054 | Lr: 0.00077378093749999979 |Train loss: 0.258540 | Val loss: 0.296439 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.87it/s]\n",
      "Epoch: 055 | Lr: 0.00077378093749999979 |Train loss: 0.258730 | Val loss: 0.300310 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.70it/s]\n",
      "Epoch: 056 | Lr: 0.00077378093749999979 |Train loss: 0.259813 | Val loss: 0.291886 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.23it/s]\n",
      "Epoch: 057 | Lr: 0.00077378093749999979 |Train loss: 0.256493 | Val loss: 0.293404 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.24it/s]\n",
      "Epoch: 058 | Lr: 0.00077378093749999979 |Train loss: 0.256984 | Val loss: 0.296168 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.57it/s]\n",
      "Epoch: 059 | Lr: 0.00077378093749999979 |Train loss: 0.256729 | Val loss: 0.298762 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.84it/s]\n",
      "Epoch: 060 | Lr: 0.00073509189062499975 |Train loss: 0.256772 | Val loss: 0.294610 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.29it/s]\n",
      "Epoch: 061 | Lr: 0.00073509189062499975 |Train loss: 0.254848 | Val loss: 0.289071 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.53it/s]\n",
      "Epoch: 062 | Lr: 0.00073509189062499975 |Train loss: 0.254628 | Val loss: 0.289564 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.37it/s]\n",
      "Epoch: 063 | Lr: 0.00073509189062499975 |Train loss: 0.254254 | Val loss: 0.292780 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.55it/s]\n",
      "Epoch: 064 | Lr: 0.00073509189062499975 |Train loss: 0.255135 | Val loss: 0.289093 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.01it/s]\n",
      "Epoch: 065 | Lr: 0.00073509189062499975 |Train loss: 0.253298 | Val loss: 0.295547 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.60it/s]\n",
      "Epoch: 066 | Lr: 0.00073509189062499975 |Train loss: 0.255176 | Val loss: 0.290999 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.09it/s]\n",
      "Epoch: 067 | Lr: 0.00073509189062499975 |Train loss: 0.257291 | Val loss: 0.286338 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.80it/s]\n",
      "Epoch: 068 | Lr: 0.00073509189062499975 |Train loss: 0.252683 | Val loss: 0.290523 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.66it/s]\n",
      "Epoch: 069 | Lr: 0.00073509189062499975 |Train loss: 0.253254 | Val loss: 0.287952 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.38it/s]\n",
      "Epoch: 070 | Lr: 0.00069833729609374972 |Train loss: 0.254221 | Val loss: 0.286342 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.90it/s]\n",
      "Epoch: 071 | Lr: 0.00069833729609374972 |Train loss: 0.252002 | Val loss: 0.286478 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.91it/s]\n",
      "Epoch: 072 | Lr: 0.00069833729609374972 |Train loss: 0.252509 | Val loss: 0.286719 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.00it/s]\n",
      "Epoch: 073 | Lr: 0.00069833729609374972 |Train loss: 0.252841 | Val loss: 0.284649 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.30it/s]\n",
      "Epoch: 074 | Lr: 0.00069833729609374972 |Train loss: 0.251571 | Val loss: 0.284261 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.38it/s]\n",
      "Epoch: 075 | Lr: 0.00069833729609374972 |Train loss: 0.251756 | Val loss: 0.286727 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.67it/s]\n",
      "Epoch: 076 | Lr: 0.00069833729609374972 |Train loss: 0.251667 | Val loss: 0.283706 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.45it/s]\n",
      "Epoch: 077 | Lr: 0.00069833729609374972 |Train loss: 0.251434 | Val loss: 0.286443 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.04it/s]\n",
      "Epoch: 078 | Lr: 0.00069833729609374972 |Train loss: 0.251955 | Val loss: 0.284504 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.05it/s]\n",
      "Epoch: 079 | Lr: 0.00069833729609374972 |Train loss: 0.251611 | Val loss: 0.283791 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.32it/s]\n",
      "Epoch: 080 | Lr: 0.00066342043128906215 |Train loss: 0.250936 | Val loss: 0.285394 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.92it/s]\n",
      "Epoch: 081 | Lr: 0.00066342043128906215 |Train loss: 0.250144 | Val loss: 0.283345 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.01it/s]\n",
      "Epoch: 082 | Lr: 0.00066342043128906215 |Train loss: 0.251092 | Val loss: 0.280612 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.68it/s]\n",
      "Epoch: 083 | Lr: 0.00066342043128906215 |Train loss: 0.249358 | Val loss: 0.281787 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.22it/s]\n",
      "Epoch: 084 | Lr: 0.00066342043128906215 |Train loss: 0.250035 | Val loss: 0.283096 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.14it/s]\n",
      "Epoch: 085 | Lr: 0.00066342043128906215 |Train loss: 0.251632 | Val loss: 0.279242 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.79it/s]\n",
      "Epoch: 086 | Lr: 0.00066342043128906215 |Train loss: 0.249403 | Val loss: 0.280468 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.86it/s]\n",
      "Epoch: 087 | Lr: 0.00066342043128906215 |Train loss: 0.249746 | Val loss: 0.280430 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.93it/s]\n",
      "Epoch: 088 | Lr: 0.00066342043128906215 |Train loss: 0.249178 | Val loss: 0.280434 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.29it/s]\n",
      "Epoch: 089 | Lr: 0.00066342043128906215 |Train loss: 0.249042 | Val loss: 0.281232 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.91it/s]\n",
      "Epoch: 090 | Lr: 0.00063024940972460899 |Train loss: 0.249023 | Val loss: 0.281363 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.89it/s]\n",
      "Epoch: 091 | Lr: 0.00063024940972460899 |Train loss: 0.248097 | Val loss: 0.282624 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.93it/s]\n",
      "Epoch: 092 | Lr: 0.00063024940972460899 |Train loss: 0.251516 | Val loss: 0.276689 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.89it/s]\n",
      "Epoch: 093 | Lr: 0.00063024940972460899 |Train loss: 0.247772 | Val loss: 0.279772 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.02it/s]\n",
      "Epoch: 094 | Lr: 0.00063024940972460899 |Train loss: 0.248508 | Val loss: 0.278873 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.81it/s]\n",
      "Epoch: 095 | Lr: 0.00063024940972460899 |Train loss: 0.247356 | Val loss: 0.276568 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.87it/s]\n",
      "Epoch: 096 | Lr: 0.00063024940972460899 |Train loss: 0.247683 | Val loss: 0.280671 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.46it/s]\n",
      "Epoch: 097 | Lr: 0.00063024940972460899 |Train loss: 0.247712 | Val loss: 0.278362 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.56it/s]\n",
      "Epoch: 098 | Lr: 0.00063024940972460899 |Train loss: 0.247615 | Val loss: 0.281886 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.44it/s]\n",
      "Epoch: 099 | Lr: 0.00063024940972460899 |Train loss: 0.248514 | Val loss: 0.277259 | GPU occupy: 1072.379904 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.82it/s]\n",
      "Epoch: 100 | Lr: 0.00059873693923837847 |Train loss: 0.247155 | Val loss: 0.278671 | GPU occupy: 1072.379904 MiB\n",
      "Dataset metr-la | Test loss 0.296919 | MAE 5.148235 | RMSE 9.942815 | WMAPE 0.10134547\n"
     ]
    }
   ],
   "source": [
    "#7: 2 middle layer + first order\n",
    "\n",
    "!python main.py --stblock_num=3 --Kt=2 --Ks=2 --middle_layer=True --epoch=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4b866c3-e593-432c-9c32-c80942f6c566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configs: Namespace(Ks=3, Kt=2, act_func='glu', batch_size=32, dataset='metr-la', droprate=0.5, enable_bias=True, enable_cuda=True, epochs=100, gamma=0.95, graph_conv_type='cheb_graph_conv', gso_type='sym_norm_lap', lr=0.001, middle_layer=True, n_his=12, n_pred=3, opt='adam', patience=30, seed=42, stblock_num=3, step_size=10, time_intvl=5, weight_decay_rate=0.0005)\n",
      "Blocks:  [[1], [64, 16, 64], [64, 16, 64], [64, 16, 64], [128, 128], [1]]\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00822724]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "Use iteration 19 instead with accuracy \n",
      "0.007941234546600588.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00794123]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "Modules:  [STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(1, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), MiddleBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 256, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (tc1_ln): LayerNorm((207, 128), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), MiddleBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 256, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (tc1_ln): LayerNorm((207, 128), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")]\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.29it/s]\n",
      "Epoch: 001 | Lr: 0.00100000000000000002 |Train loss: 0.377619 | Val loss: 0.383305 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.93it/s]\n",
      "Epoch: 002 | Lr: 0.00100000000000000002 |Train loss: 0.292081 | Val loss: 0.345105 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.82it/s]\n",
      "Epoch: 003 | Lr: 0.00100000000000000002 |Train loss: 0.785062 | Val loss: 1.139701 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.84it/s]\n",
      "Epoch: 004 | Lr: 0.00100000000000000002 |Train loss: 0.656695 | Val loss: 0.449178 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.20it/s]\n",
      "Epoch: 005 | Lr: 0.00100000000000000002 |Train loss: 0.317446 | Val loss: 0.374417 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.78it/s]\n",
      "Epoch: 006 | Lr: 0.00100000000000000002 |Train loss: 0.299347 | Val loss: 0.354419 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.89it/s]\n",
      "Epoch: 007 | Lr: 0.00100000000000000002 |Train loss: 0.285448 | Val loss: 0.348349 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.11it/s]\n",
      "Epoch: 008 | Lr: 0.00100000000000000002 |Train loss: 0.283827 | Val loss: 0.340854 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.10it/s]\n",
      "Epoch: 009 | Lr: 0.00100000000000000002 |Train loss: 0.280742 | Val loss: 0.338296 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.69it/s]\n",
      "Epoch: 010 | Lr: 0.00095000000000000000 |Train loss: 0.279508 | Val loss: 0.338451 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.63it/s]\n",
      "Epoch: 011 | Lr: 0.00095000000000000000 |Train loss: 0.275288 | Val loss: 0.329669 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.62it/s]\n",
      "Epoch: 012 | Lr: 0.00095000000000000000 |Train loss: 0.273686 | Val loss: 0.327653 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.86it/s]\n",
      "Epoch: 013 | Lr: 0.00095000000000000000 |Train loss: 0.273868 | Val loss: 0.325720 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.71it/s]\n",
      "Epoch: 014 | Lr: 0.00095000000000000000 |Train loss: 0.272261 | Val loss: 0.326218 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.68it/s]\n",
      "Epoch: 015 | Lr: 0.00095000000000000000 |Train loss: 0.271542 | Val loss: 0.322918 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.77it/s]\n",
      "Epoch: 016 | Lr: 0.00095000000000000000 |Train loss: 0.270471 | Val loss: 0.320285 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.82it/s]\n",
      "Epoch: 017 | Lr: 0.00095000000000000000 |Train loss: 0.270000 | Val loss: 0.323676 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.52it/s]\n",
      "Epoch: 018 | Lr: 0.00095000000000000000 |Train loss: 0.268363 | Val loss: 0.320964 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.58it/s]\n",
      "Epoch: 019 | Lr: 0.00095000000000000000 |Train loss: 0.268498 | Val loss: 0.322912 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.80it/s]\n",
      "Epoch: 020 | Lr: 0.00090249999999999998 |Train loss: 0.267591 | Val loss: 0.325428 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.06it/s]\n",
      "Epoch: 021 | Lr: 0.00090249999999999998 |Train loss: 0.267744 | Val loss: 0.321204 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.22it/s]\n",
      "Epoch: 022 | Lr: 0.00090249999999999998 |Train loss: 0.265587 | Val loss: 0.322858 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.23it/s]\n",
      "Epoch: 023 | Lr: 0.00090249999999999998 |Train loss: 0.265915 | Val loss: 0.324446 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.95it/s]\n",
      "Epoch: 024 | Lr: 0.00090249999999999998 |Train loss: 0.266465 | Val loss: 0.321874 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.67it/s]\n",
      "Epoch: 025 | Lr: 0.00090249999999999998 |Train loss: 0.263906 | Val loss: 0.318034 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:44<00:00, 16.84it/s]\n",
      "Epoch: 026 | Lr: 0.00090249999999999998 |Train loss: 0.265830 | Val loss: 0.319082 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.49it/s]\n",
      "Epoch: 027 | Lr: 0.00090249999999999998 |Train loss: 0.264467 | Val loss: 0.317203 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.11it/s]\n",
      "Epoch: 028 | Lr: 0.00090249999999999998 |Train loss: 0.264134 | Val loss: 0.321525 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:44<00:00, 16.69it/s]\n",
      "Epoch: 029 | Lr: 0.00090249999999999998 |Train loss: 0.264782 | Val loss: 0.311999 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:43<00:00, 17.05it/s]\n",
      "Epoch: 030 | Lr: 0.00085737499999999996 |Train loss: 0.263061 | Val loss: 0.318324 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.02it/s]\n",
      "Epoch: 031 | Lr: 0.00085737499999999996 |Train loss: 0.264745 | Val loss: 0.321242 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.78it/s]\n",
      "Epoch: 032 | Lr: 0.00085737499999999996 |Train loss: 0.263006 | Val loss: 0.308534 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.41it/s]\n",
      "Epoch: 033 | Lr: 0.00085737499999999996 |Train loss: 0.260777 | Val loss: 0.314016 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.95it/s]\n",
      "Epoch: 034 | Lr: 0.00085737499999999996 |Train loss: 0.263358 | Val loss: 0.312816 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.18it/s]\n",
      "Epoch: 035 | Lr: 0.00085737499999999996 |Train loss: 0.261911 | Val loss: 0.313461 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.39it/s]\n",
      "Epoch: 036 | Lr: 0.00085737499999999996 |Train loss: 0.261998 | Val loss: 0.311177 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.20it/s]\n",
      "Epoch: 037 | Lr: 0.00085737499999999996 |Train loss: 0.263042 | Val loss: 0.325001 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.02it/s]\n",
      "Epoch: 038 | Lr: 0.00085737499999999996 |Train loss: 0.261276 | Val loss: 0.306469 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.12it/s]\n",
      "Epoch: 039 | Lr: 0.00085737499999999996 |Train loss: 0.260055 | Val loss: 0.311272 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.50it/s]\n",
      "Epoch: 040 | Lr: 0.00081450624999999987 |Train loss: 0.262644 | Val loss: 0.310229 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.24it/s]\n",
      "Epoch: 041 | Lr: 0.00081450624999999987 |Train loss: 0.259962 | Val loss: 0.301727 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.25it/s]\n",
      "Epoch: 042 | Lr: 0.00081450624999999987 |Train loss: 0.259067 | Val loss: 0.306472 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.50it/s]\n",
      "Epoch: 043 | Lr: 0.00081450624999999987 |Train loss: 0.260541 | Val loss: 0.323626 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.15it/s]\n",
      "Epoch: 044 | Lr: 0.00081450624999999987 |Train loss: 0.261388 | Val loss: 0.304580 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.74it/s]\n",
      "Epoch: 045 | Lr: 0.00081450624999999987 |Train loss: 0.258477 | Val loss: 0.308388 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.63it/s]\n",
      "Epoch: 046 | Lr: 0.00081450624999999987 |Train loss: 0.260592 | Val loss: 0.315145 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:44<00:00, 16.83it/s]\n",
      "Epoch: 047 | Lr: 0.00081450624999999987 |Train loss: 0.259636 | Val loss: 0.303667 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:44<00:00, 16.76it/s]\n",
      "Epoch: 048 | Lr: 0.00081450624999999987 |Train loss: 0.258881 | Val loss: 0.316375 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.05it/s]\n",
      "Epoch: 049 | Lr: 0.00081450624999999987 |Train loss: 0.259755 | Val loss: 0.306412 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.16it/s]\n",
      "Epoch: 050 | Lr: 0.00077378093749999979 |Train loss: 0.258586 | Val loss: 0.306957 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.42it/s]\n",
      "Epoch: 051 | Lr: 0.00077378093749999979 |Train loss: 0.257637 | Val loss: 0.301439 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.50it/s]\n",
      "Epoch: 052 | Lr: 0.00077378093749999979 |Train loss: 0.257445 | Val loss: 0.305169 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.67it/s]\n",
      "Epoch: 053 | Lr: 0.00077378093749999979 |Train loss: 0.257224 | Val loss: 0.303167 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.28it/s]\n",
      "Epoch: 054 | Lr: 0.00077378093749999979 |Train loss: 0.257057 | Val loss: 0.305766 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.90it/s]\n",
      "Epoch: 055 | Lr: 0.00077378093749999979 |Train loss: 0.257625 | Val loss: 0.302916 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.24it/s]\n",
      "Epoch: 056 | Lr: 0.00077378093749999979 |Train loss: 0.257540 | Val loss: 0.315837 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.68it/s]\n",
      "Epoch: 057 | Lr: 0.00077378093749999979 |Train loss: 0.258032 | Val loss: 0.301854 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.00it/s]\n",
      "Epoch: 058 | Lr: 0.00077378093749999979 |Train loss: 0.256648 | Val loss: 0.300741 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.62it/s]\n",
      "Epoch: 059 | Lr: 0.00077378093749999979 |Train loss: 0.257175 | Val loss: 0.302089 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.47it/s]\n",
      "Epoch: 060 | Lr: 0.00073509189062499975 |Train loss: 0.256945 | Val loss: 0.299693 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.44it/s]\n",
      "Epoch: 061 | Lr: 0.00073509189062499975 |Train loss: 0.255220 | Val loss: 0.299599 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.23it/s]\n",
      "Epoch: 062 | Lr: 0.00073509189062499975 |Train loss: 0.256060 | Val loss: 0.300470 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.25it/s]\n",
      "Epoch: 063 | Lr: 0.00073509189062499975 |Train loss: 0.255961 | Val loss: 0.301437 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.78it/s]\n",
      "Epoch: 064 | Lr: 0.00073509189062499975 |Train loss: 0.255419 | Val loss: 0.297267 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:44<00:00, 16.72it/s]\n",
      "Epoch: 065 | Lr: 0.00073509189062499975 |Train loss: 0.255387 | Val loss: 0.299108 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 15.98it/s]\n",
      "Epoch: 066 | Lr: 0.00073509189062499975 |Train loss: 0.255914 | Val loss: 0.301318 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.22it/s]\n",
      "Epoch: 067 | Lr: 0.00073509189062499975 |Train loss: 0.255988 | Val loss: 0.300381 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.38it/s]\n",
      "Epoch: 068 | Lr: 0.00073509189062499975 |Train loss: 0.255458 | Val loss: 0.301696 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.52it/s]\n",
      "Epoch: 069 | Lr: 0.00073509189062499975 |Train loss: 0.255269 | Val loss: 0.298373 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.55it/s]\n",
      "Epoch: 070 | Lr: 0.00069833729609374972 |Train loss: 0.257515 | Val loss: 0.299914 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.12it/s]\n",
      "Epoch: 071 | Lr: 0.00069833729609374972 |Train loss: 0.256518 | Val loss: 0.297740 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.81it/s]\n",
      "Epoch: 072 | Lr: 0.00069833729609374972 |Train loss: 0.256790 | Val loss: 0.296967 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.91it/s]\n",
      "Epoch: 073 | Lr: 0.00069833729609374972 |Train loss: 0.256121 | Val loss: 0.295676 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.41it/s]\n",
      "Epoch: 074 | Lr: 0.00069833729609374972 |Train loss: 0.254315 | Val loss: 0.295099 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.15it/s]\n",
      "Epoch: 075 | Lr: 0.00069833729609374972 |Train loss: 0.254561 | Val loss: 0.303223 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.84it/s]\n",
      "Epoch: 076 | Lr: 0.00069833729609374972 |Train loss: 0.255137 | Val loss: 0.294844 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.90it/s]\n",
      "Epoch: 077 | Lr: 0.00069833729609374972 |Train loss: 0.253422 | Val loss: 0.295963 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 15.98it/s]\n",
      "Epoch: 078 | Lr: 0.00069833729609374972 |Train loss: 0.254683 | Val loss: 0.302061 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.67it/s]\n",
      "Epoch: 079 | Lr: 0.00069833729609374972 |Train loss: 0.255132 | Val loss: 0.298012 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.05it/s]\n",
      "Epoch: 080 | Lr: 0.00066342043128906215 |Train loss: 0.255595 | Val loss: 0.299926 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.26it/s]\n",
      "Epoch: 081 | Lr: 0.00066342043128906215 |Train loss: 0.255982 | Val loss: 0.295575 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.25it/s]\n",
      "Epoch: 082 | Lr: 0.00066342043128906215 |Train loss: 0.255889 | Val loss: 0.297798 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.18it/s]\n",
      "Epoch: 083 | Lr: 0.00066342043128906215 |Train loss: 0.254437 | Val loss: 0.297175 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.41it/s]\n",
      "Epoch: 084 | Lr: 0.00066342043128906215 |Train loss: 0.255145 | Val loss: 0.294181 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.86it/s]\n",
      "Epoch: 085 | Lr: 0.00066342043128906215 |Train loss: 0.254901 | Val loss: 0.304223 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 15.96it/s]\n",
      "Epoch: 086 | Lr: 0.00066342043128906215 |Train loss: 0.257302 | Val loss: 0.293839 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.72it/s]\n",
      "Epoch: 087 | Lr: 0.00066342043128906215 |Train loss: 0.253329 | Val loss: 0.294505 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.20it/s]\n",
      "Epoch: 088 | Lr: 0.00066342043128906215 |Train loss: 0.253626 | Val loss: 0.294232 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.44it/s]\n",
      "Epoch: 089 | Lr: 0.00066342043128906215 |Train loss: 0.255333 | Val loss: 0.306138 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.24it/s]\n",
      "Epoch: 090 | Lr: 0.00063024940972460899 |Train loss: 0.253733 | Val loss: 0.295300 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.56it/s]\n",
      "Epoch: 091 | Lr: 0.00063024940972460899 |Train loss: 0.252805 | Val loss: 0.291857 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.56it/s]\n",
      "Epoch: 092 | Lr: 0.00063024940972460899 |Train loss: 0.251792 | Val loss: 0.293963 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.88it/s]\n",
      "Epoch: 093 | Lr: 0.00063024940972460899 |Train loss: 0.250917 | Val loss: 0.292004 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.24it/s]\n",
      "Epoch: 094 | Lr: 0.00063024940972460899 |Train loss: 0.251918 | Val loss: 0.292745 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.06it/s]\n",
      "Epoch: 095 | Lr: 0.00063024940972460899 |Train loss: 0.251832 | Val loss: 0.290264 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 15.98it/s]\n",
      "Epoch: 096 | Lr: 0.00063024940972460899 |Train loss: 0.251271 | Val loss: 0.292842 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.37it/s]\n",
      "Epoch: 097 | Lr: 0.00063024940972460899 |Train loss: 0.252338 | Val loss: 0.292531 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.43it/s]\n",
      "Epoch: 098 | Lr: 0.00063024940972460899 |Train loss: 0.251349 | Val loss: 0.295399 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.16it/s]\n",
      "Epoch: 099 | Lr: 0.00063024940972460899 |Train loss: 0.253928 | Val loss: 0.291920 | GPU occupy: 1083.571712 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.01it/s]\n",
      "Epoch: 100 | Lr: 0.00059873693923837847 |Train loss: 0.251691 | Val loss: 0.290556 | GPU occupy: 1083.571712 MiB\n",
      "Dataset metr-la | Test loss 0.297879 | MAE 5.399598 | RMSE 9.942484 | WMAPE 0.10629367\n"
     ]
    }
   ],
   "source": [
    "#8: 2 middle layer + second order\n",
    "\n",
    "!python main.py --stblock_num=3 --Kt=2 --Ks=3 --middle_layer=True --epoch=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9604338f-a506-4b03-9399-4bee00d6440e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configs: Namespace(Ks=4, Kt=2, act_func='glu', batch_size=32, dataset='metr-la', droprate=0.5, enable_bias=True, enable_cuda=True, epochs=100, gamma=0.95, graph_conv_type='cheb_graph_conv', gso_type='sym_norm_lap', lr=0.001, middle_layer=True, n_his=12, n_pred=3, opt='adam', patience=30, seed=42, stblock_num=3, step_size=10, time_intvl=5, weight_decay_rate=0.0005)\n",
      "Blocks:  [[1], [64, 16, 64], [64, 16, 64], [64, 16, 64], [128, 128], [1]]\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited at iteration 20 with accuracies \n",
      "[0.00822724]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "Use iteration 19 instead with accuracy \n",
      "0.007941234546600588.\n",
      "\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "/home/wuyifan/anaconda3/envs/STGCN/lib/python3.8/site-packages/scipy/sparse/linalg/_eigen/_svds.py:491: UserWarning: Exited postprocessing with accuracies \n",
      "[0.00794123]\n",
      "not reaching the requested tolerance 3.084540367126465e-06.\n",
      "  _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "Modules:  [STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(1, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), MiddleBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 256, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (tc1_ln): LayerNorm((207, 128), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), MiddleBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 256, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (tc1_ln): LayerNorm((207, 128), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "), STConvBlock(\n",
      "  (tmp_conv1): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(64, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (graph_conv): GraphConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (cheb_graph_conv): ChebGraphConv()\n",
      "  )\n",
      "  (tmp_conv2): TemporalConvLayer(\n",
      "    (align): Align(\n",
      "      (align_conv): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (causal_conv): CausalConv2d(16, 128, kernel_size=(2, 1), stride=(1, 1))\n",
      "    (relu): ReLU()\n",
      "    (silu): SiLU()\n",
      "  )\n",
      "  (tc2_ln): LayerNorm((207, 64), eps=1e-05, elementwise_affine=True)\n",
      "  (relu): ReLU()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")]\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.07it/s]\n",
      "Epoch: 001 | Lr: 0.00100000000000000002 |Train loss: 0.512002 | Val loss: 0.420864 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.55it/s]\n",
      "Epoch: 002 | Lr: 0.00100000000000000002 |Train loss: 0.638079 | Val loss: 0.635412 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:50<00:00, 15.00it/s]\n",
      "Epoch: 003 | Lr: 0.00100000000000000002 |Train loss: 0.650611 | Val loss: 0.553848 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.65it/s]\n",
      "Epoch: 004 | Lr: 0.00100000000000000002 |Train loss: 0.350678 | Val loss: 0.405161 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.61it/s]\n",
      "Epoch: 005 | Lr: 0.00100000000000000002 |Train loss: 0.314310 | Val loss: 0.525338 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.34it/s]\n",
      "Epoch: 006 | Lr: 0.00100000000000000002 |Train loss: 0.309541 | Val loss: 0.411780 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:51<00:00, 14.68it/s]\n",
      "Epoch: 007 | Lr: 0.00100000000000000002 |Train loss: 0.313904 | Val loss: 0.364683 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:50<00:00, 14.88it/s]\n",
      "Epoch: 008 | Lr: 0.00100000000000000002 |Train loss: 0.297187 | Val loss: 0.396576 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:50<00:00, 14.94it/s]\n",
      "Epoch: 009 | Lr: 0.00100000000000000002 |Train loss: 0.300400 | Val loss: 0.367315 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:50<00:00, 14.72it/s]\n",
      "Epoch: 010 | Lr: 0.00095000000000000000 |Train loss: 0.291050 | Val loss: 0.360371 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.25it/s]\n",
      "Epoch: 011 | Lr: 0.00095000000000000000 |Train loss: 0.287375 | Val loss: 0.367834 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.04it/s]\n",
      "Epoch: 012 | Lr: 0.00095000000000000000 |Train loss: 0.285516 | Val loss: 0.354296 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.51it/s]\n",
      "Epoch: 013 | Lr: 0.00095000000000000000 |Train loss: 0.283417 | Val loss: 0.348896 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:50<00:00, 14.89it/s]\n",
      "Epoch: 014 | Lr: 0.00095000000000000000 |Train loss: 0.282789 | Val loss: 0.332834 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.09it/s]\n",
      "Epoch: 015 | Lr: 0.00095000000000000000 |Train loss: 0.280790 | Val loss: 0.340557 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.31it/s]\n",
      "Epoch: 016 | Lr: 0.00095000000000000000 |Train loss: 0.281056 | Val loss: 0.343273 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.76it/s]\n",
      "Epoch: 017 | Lr: 0.00095000000000000000 |Train loss: 0.277992 | Val loss: 0.331450 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.61it/s]\n",
      "Epoch: 018 | Lr: 0.00095000000000000000 |Train loss: 0.275768 | Val loss: 0.331593 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.23it/s]\n",
      "Epoch: 019 | Lr: 0.00095000000000000000 |Train loss: 0.283384 | Val loss: 0.322869 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.81it/s]\n",
      "Epoch: 020 | Lr: 0.00090249999999999998 |Train loss: 0.272052 | Val loss: 0.329484 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.21it/s]\n",
      "Epoch: 021 | Lr: 0.00090249999999999998 |Train loss: 0.271123 | Val loss: 0.331689 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.23it/s]\n",
      "Epoch: 022 | Lr: 0.00090249999999999998 |Train loss: 0.270601 | Val loss: 0.329464 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.66it/s]\n",
      "Epoch: 023 | Lr: 0.00090249999999999998 |Train loss: 0.270565 | Val loss: 0.328166 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:50<00:00, 15.00it/s]\n",
      "Epoch: 024 | Lr: 0.00090249999999999998 |Train loss: 0.772377 | Val loss: 1.291781 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.02it/s]\n",
      "Epoch: 025 | Lr: 0.00090249999999999998 |Train loss: 0.977163 | Val loss: 0.913066 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.37it/s]\n",
      "Epoch: 026 | Lr: 0.00090249999999999998 |Train loss: 0.357628 | Val loss: 0.376790 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:52<00:00, 14.39it/s]\n",
      "Epoch: 027 | Lr: 0.00090249999999999998 |Train loss: 0.292845 | Val loss: 0.315193 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.38it/s]\n",
      "Epoch: 028 | Lr: 0.00090249999999999998 |Train loss: 0.273988 | Val loss: 0.323140 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.23it/s]\n",
      "Epoch: 029 | Lr: 0.00090249999999999998 |Train loss: 0.271157 | Val loss: 0.343910 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:50<00:00, 14.99it/s]\n",
      "Epoch: 030 | Lr: 0.00085737499999999996 |Train loss: 0.269147 | Val loss: 0.319531 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.02it/s]\n",
      "Epoch: 031 | Lr: 0.00085737499999999996 |Train loss: 0.265557 | Val loss: 0.317296 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.37it/s]\n",
      "Epoch: 032 | Lr: 0.00085737499999999996 |Train loss: 0.262905 | Val loss: 0.315056 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.67it/s]\n",
      "Epoch: 033 | Lr: 0.00085737499999999996 |Train loss: 0.261442 | Val loss: 0.315490 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:42<00:00, 17.44it/s]\n",
      "Epoch: 034 | Lr: 0.00085737499999999996 |Train loss: 0.260943 | Val loss: 0.318708 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:44<00:00, 16.79it/s]\n",
      "Epoch: 035 | Lr: 0.00085737499999999996 |Train loss: 0.260687 | Val loss: 0.315467 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.54it/s]\n",
      "Epoch: 036 | Lr: 0.00085737499999999996 |Train loss: 0.260027 | Val loss: 0.316355 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.64it/s]\n",
      "Epoch: 037 | Lr: 0.00085737499999999996 |Train loss: 0.306410 | Val loss: 0.313376 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.32it/s]\n",
      "Epoch: 038 | Lr: 0.00085737499999999996 |Train loss: 0.262889 | Val loss: 0.305280 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:46<00:00, 16.25it/s]\n",
      "Epoch: 039 | Lr: 0.00085737499999999996 |Train loss: 0.259037 | Val loss: 0.303666 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.72it/s]\n",
      "Epoch: 040 | Lr: 0.00081450624999999987 |Train loss: 0.257100 | Val loss: 0.307891 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.32it/s]\n",
      "Epoch: 041 | Lr: 0.00081450624999999987 |Train loss: 0.256274 | Val loss: 0.308609 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:50<00:00, 14.95it/s]\n",
      "Epoch: 042 | Lr: 0.00081450624999999987 |Train loss: 0.257875 | Val loss: 0.309494 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.03it/s]\n",
      "Epoch: 043 | Lr: 0.00081450624999999987 |Train loss: 0.256123 | Val loss: 0.307422 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.46it/s]\n",
      "Epoch: 044 | Lr: 0.00081450624999999987 |Train loss: 0.256768 | Val loss: 0.315333 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:50<00:00, 14.97it/s]\n",
      "Epoch: 045 | Lr: 0.00081450624999999987 |Train loss: 0.257870 | Val loss: 0.315903 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:51<00:00, 14.68it/s]\n",
      "Epoch: 046 | Lr: 0.00081450624999999987 |Train loss: 0.255580 | Val loss: 0.311894 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.10it/s]\n",
      "Epoch: 047 | Lr: 0.00081450624999999987 |Train loss: 0.256846 | Val loss: 0.311377 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.74it/s]\n",
      "Epoch: 048 | Lr: 0.00081450624999999987 |Train loss: 0.255632 | Val loss: 0.308038 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.03it/s]\n",
      "Epoch: 049 | Lr: 0.00081450624999999987 |Train loss: 0.255283 | Val loss: 0.310120 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.53it/s]\n",
      "Epoch: 050 | Lr: 0.00077378093749999979 |Train loss: 0.255758 | Val loss: 0.314397 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.14it/s]\n",
      "Epoch: 051 | Lr: 0.00077378093749999979 |Train loss: 0.254303 | Val loss: 0.306822 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.56it/s]\n",
      "Epoch: 052 | Lr: 0.00077378093749999979 |Train loss: 0.254016 | Val loss: 0.305357 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.05it/s]\n",
      "Epoch: 053 | Lr: 0.00077378093749999979 |Train loss: 0.300707 | Val loss: 0.298125 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.36it/s]\n",
      "Epoch: 054 | Lr: 0.00077378093749999979 |Train loss: 0.252883 | Val loss: 0.290836 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.75it/s]\n",
      "Epoch: 055 | Lr: 0.00077378093749999979 |Train loss: 0.250301 | Val loss: 0.302234 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.65it/s]\n",
      "Epoch: 056 | Lr: 0.00077378093749999979 |Train loss: 0.253201 | Val loss: 0.303627 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.10it/s]\n",
      "Epoch: 057 | Lr: 0.00077378093749999979 |Train loss: 0.253260 | Val loss: 0.303128 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.63it/s]\n",
      "Epoch: 058 | Lr: 0.00077378093749999979 |Train loss: 0.253206 | Val loss: 0.309495 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.42it/s]\n",
      "Epoch: 059 | Lr: 0.00077378093749999979 |Train loss: 0.254817 | Val loss: 0.309092 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.54it/s]\n",
      "Epoch: 060 | Lr: 0.00073509189062499975 |Train loss: 0.253313 | Val loss: 0.305798 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.17it/s]\n",
      "Epoch: 061 | Lr: 0.00073509189062499975 |Train loss: 0.251743 | Val loss: 0.308637 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.27it/s]\n",
      "Epoch: 062 | Lr: 0.00073509189062499975 |Train loss: 0.252701 | Val loss: 0.304457 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.91it/s]\n",
      "Epoch: 063 | Lr: 0.00073509189062499975 |Train loss: 0.251887 | Val loss: 0.306733 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.22it/s]\n",
      "Epoch: 064 | Lr: 0.00073509189062499975 |Train loss: 0.252790 | Val loss: 0.303547 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.37it/s]\n",
      "Epoch: 065 | Lr: 0.00073509189062499975 |Train loss: 0.252156 | Val loss: 0.303687 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.24it/s]\n",
      "Epoch: 066 | Lr: 0.00073509189062499975 |Train loss: 0.251921 | Val loss: 0.305337 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.88it/s]\n",
      "Epoch: 067 | Lr: 0.00073509189062499975 |Train loss: 0.251876 | Val loss: 0.310077 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.37it/s]\n",
      "Epoch: 068 | Lr: 0.00073509189062499975 |Train loss: 0.252483 | Val loss: 0.305938 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.29it/s]\n",
      "Epoch: 069 | Lr: 0.00073509189062499975 |Train loss: 0.251630 | Val loss: 0.308486 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:50<00:00, 14.79it/s]\n",
      "Epoch: 070 | Lr: 0.00069833729609374972 |Train loss: 0.252895 | Val loss: 0.308117 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:51<00:00, 14.67it/s]\n",
      "Epoch: 071 | Lr: 0.00069833729609374972 |Train loss: 0.251519 | Val loss: 0.304575 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.68it/s]\n",
      "Epoch: 072 | Lr: 0.00069833729609374972 |Train loss: 0.251416 | Val loss: 0.304806 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.34it/s]\n",
      "Epoch: 073 | Lr: 0.00069833729609374972 |Train loss: 0.252194 | Val loss: 0.302199 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.23it/s]\n",
      "Epoch: 074 | Lr: 0.00069833729609374972 |Train loss: 0.250776 | Val loss: 0.302921 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.17it/s]\n",
      "Epoch: 075 | Lr: 0.00069833729609374972 |Train loss: 0.251423 | Val loss: 0.302734 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.36it/s]\n",
      "Epoch: 076 | Lr: 0.00069833729609374972 |Train loss: 0.251447 | Val loss: 0.302417 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.33it/s]\n",
      "Epoch: 077 | Lr: 0.00069833729609374972 |Train loss: 0.251056 | Val loss: 0.300531 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.46it/s]\n",
      "Epoch: 078 | Lr: 0.00069833729609374972 |Train loss: 0.251251 | Val loss: 0.292687 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.62it/s]\n",
      "Epoch: 079 | Lr: 0.00069833729609374972 |Train loss: 0.252963 | Val loss: 0.300185 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:50<00:00, 14.92it/s]\n",
      "Epoch: 080 | Lr: 0.00066342043128906215 |Train loss: 0.250966 | Val loss: 0.299443 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.05it/s]\n",
      "Epoch: 081 | Lr: 0.00066342043128906215 |Train loss: 0.254837 | Val loss: 0.289476 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:51<00:00, 14.45it/s]\n",
      "Epoch: 082 | Lr: 0.00066342043128906215 |Train loss: 0.247812 | Val loss: 0.300623 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.43it/s]\n",
      "Epoch: 083 | Lr: 0.00066342043128906215 |Train loss: 0.249672 | Val loss: 0.299559 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.11it/s]\n",
      "Epoch: 084 | Lr: 0.00066342043128906215 |Train loss: 0.249454 | Val loss: 0.299998 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.68it/s]\n",
      "Epoch: 085 | Lr: 0.00066342043128906215 |Train loss: 0.250190 | Val loss: 0.301279 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:51<00:00, 14.68it/s]\n",
      "Epoch: 086 | Lr: 0.00066342043128906215 |Train loss: 0.250713 | Val loss: 0.297335 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.29it/s]\n",
      "Epoch: 087 | Lr: 0.00066342043128906215 |Train loss: 0.249637 | Val loss: 0.297698 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.41it/s]\n",
      "Epoch: 088 | Lr: 0.00066342043128906215 |Train loss: 0.249602 | Val loss: 0.301002 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:45<00:00, 16.47it/s]\n",
      "Epoch: 089 | Lr: 0.00066342043128906215 |Train loss: 0.250207 | Val loss: 0.295976 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.61it/s]\n",
      "Epoch: 090 | Lr: 0.00063024940972460899 |Train loss: 0.249792 | Val loss: 0.299792 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.11it/s]\n",
      "Epoch: 091 | Lr: 0.00063024940972460899 |Train loss: 0.249447 | Val loss: 0.295892 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.71it/s]\n",
      "Epoch: 092 | Lr: 0.00063024940972460899 |Train loss: 0.249694 | Val loss: 0.292869 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.55it/s]\n",
      "Epoch: 093 | Lr: 0.00063024940972460899 |Train loss: 0.248608 | Val loss: 0.294622 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.18it/s]\n",
      "Epoch: 094 | Lr: 0.00063024940972460899 |Train loss: 0.249347 | Val loss: 0.293715 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.82it/s]\n",
      "Epoch: 095 | Lr: 0.00063024940972460899 |Train loss: 0.248878 | Val loss: 0.294636 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:48<00:00, 15.59it/s]\n",
      "Epoch: 096 | Lr: 0.00063024940972460899 |Train loss: 0.248343 | Val loss: 0.297204 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:47<00:00, 15.93it/s]\n",
      "Epoch: 097 | Lr: 0.00063024940972460899 |Train loss: 0.249111 | Val loss: 0.293322 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.10it/s]\n",
      "Epoch: 098 | Lr: 0.00063024940972460899 |Train loss: 0.248629 | Val loss: 0.291403 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.18it/s]\n",
      "Epoch: 099 | Lr: 0.00063024940972460899 |Train loss: 0.248624 | Val loss: 0.295198 | GPU occupy: 1094.285312 MiB\n",
      "100%|█████████████████████████████████████████| 750/750 [00:49<00:00, 15.27it/s]\n",
      "Epoch: 100 | Lr: 0.00059873693923837847 |Train loss: 0.248871 | Val loss: 0.295650 | GPU occupy: 1094.285312 MiB\n",
      "Dataset metr-la | Test loss 0.305803 | MAE 5.531188 | RMSE 10.064379 | WMAPE 0.10888409\n"
     ]
    }
   ],
   "source": [
    "#9: 2 middle layer + third order\n",
    "\n",
    "!python main.py --stblock_num=3 --Kt=2 --Ks=4 --middle_layer=True --epoch=100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
